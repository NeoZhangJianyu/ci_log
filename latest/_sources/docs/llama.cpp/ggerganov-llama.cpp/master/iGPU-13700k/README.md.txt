# [ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp/tree/master) CI for iGPU-13700k by SYCL Backend

## Summary

Figure

![Performance](./perf.png)
## Detail

**GGUF res** is verified by script ./example/sycl/run.sh with llama2-7b-Q4 for correction

**GGUF Perf** is the performance data by script ./example/sycl/run.sh with llama2-7b-Q4

**Bench Perf** is the performance data by llama-bench with llama2-7b-Q4

|Commit Info|UT PassRate<br>Detail|GGUF Perf<br>(token/s)|Bench Perf<br>(token/s)|<div style="width:100px">GGUF res</div>|Warn/Err<br>oneAPI|
|-|-|-|-|-|-|
|[2a1507c1629975d9d20a503d6a14f44eff292c25](https://github.com/ggerganov/llama.cpp/commit/2a1507c1629975d9d20a503d6a14f44eff292c25)<br>2024-11-19 09:02:23<br>sycl : Add option to set the SYCL archit<br>ecture for all targets<br>Romain Biessy  Log: [log](./log/2a1507c1629975d9d20a503d6a14f44eff292c25)|93.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|598/0<br>2025.0.0|
|[557924f22237c76387a39c4db5abae154d57e754](https://github.com/ggerganov/llama.cpp/commit/557924f22237c76387a39c4db5abae154d57e754)<br>2024-11-19 00:50:04<br>sycl: Revert MUL_MAT_OP support changes<br>Alberto Cabrera Pérez  Log: [log](./log/557924f22237c76387a39c4db5abae154d57e754)|93.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|598/0<br>2025.0.0|
|[57f8355b29a8c7dfcd1fb6094758ad85644f8535](https://github.com/ggerganov/llama.cpp/commit/57f8355b29a8c7dfcd1fb6094758ad85644f8535)<br>2024-11-15 12:10:45<br>sycl: Update Intel docker images to use <br>DPC++ 2025.0<br>Romain Biessy  Log: [log](./log/57f8355b29a8c7dfcd1fb6094758ad85644f8535)|96.0%<br>NA|NA|tg=NA<br>pp=NA|('ok', 'pass', 0)|598/0<br>2025.0.0|
|[5a54af4d4f588f109f31e456483fdf77096399d9](https://github.com/ggerganov/llama.cpp/commit/5a54af4d4f588f109f31e456483fdf77096399d9)<br>2024-11-15 04:09:12<br>sycl: Use syclcompat::dp4a<br>Romain Biessy  Log: [log](./log/5a54af4d4f588f109f31e456483fdf77096399d9)|96.0%<br>NA|2.02|tg=NA<br>pp=NA|('ok', 'pass', 0)|598/0<br>2025.0.0|
|[ae8de6d50a09d49545e0afab2e50cc4acfb280e2](https://github.com/ggerganov/llama.cpp/commit/ae8de6d50a09d49545e0afab2e50cc4acfb280e2)<br>2024-11-14 18:04:35<br>ggml : build backends as libraries<br>Diego Devesa  Log: [log](./log/ae8de6d50a09d49545e0afab2e50cc4acfb280e2)|96.0%<br>NA|2.03|tg=NA<br>pp=NA|('ok', 'pass', 0)|614/0<br>2025.0.0|
|[2e82ffa4af29f87e7d3d6dff8060a2a79613b72f](https://github.com/ggerganov/llama.cpp/commit/2e82ffa4af29f87e7d3d6dff8060a2a79613b72f)<br>2024-11-13 09:40:57<br>sycl : Fixes to broken builds and test-b<br>ackend-ops<br>Alberto Cabrera Pérez  Log: [log](./log/2e82ffa4af29f87e7d3d6dff8060a2a79613b72f)|96.0%<br>NA|2.03|tg=NA<br>pp=NA|('ok', 'pass', 0)|614/0<br>2025.0.0|
|[3bcd40b3c593d14261fb2abfabad3c0fb5b9e318](https://github.com/ggerganov/llama.cpp/commit/3bcd40b3c593d14261fb2abfabad3c0fb5b9e318)<br>2024-11-07 18:19:10<br>Optimize RWKV6 Operator Naming and Imple<br>ment Multi-core CPU/ SYCL Acceleration<br>Zhiyuan Li  Log: [log](./log/3bcd40b3c593d14261fb2abfabad3c0fb5b9e318)|93.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|614/0<br>2025.0.0|
|[c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc](https://github.com/ggerganov/llama.cpp/commit/c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc)<br>2024-10-30 02:01:23<br>llama : refactor model loader with backe<br>nd registry<br>Diego Devesa  Log: [log](./log/c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc)|93.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|514/0<br>2025.0.0|
|[40f2555797f97314de749873cdc29dc102be66e2](https://github.com/ggerganov/llama.cpp/commit/40f2555797f97314de749873cdc29dc102be66e2)<br>2024-10-24 21:23:33<br>ci : fix cmake flags for SYCL<br>Georgi Gerganov  Log: [log](./log/40f2555797f97314de749873cdc29dc102be66e2)|93.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2025.0.0|
|[1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31](https://github.com/ggerganov/llama.cpp/commit/1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31)<br>2024-10-21 14:26:09<br>fix mul_mat_vec_q and *_vec_q error<br>Neo Zhang Jianyu  Log: [log](./log/1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2025.0.0|
|[87421a23e8c60e00a7b227d501e8aab2a1aff7ce](https://github.com/ggerganov/llama.cpp/commit/87421a23e8c60e00a7b227d501e8aab2a1aff7ce)<br>2024-10-18 06:46:16<br>[SYCL] Add SYCL Backend registry, device<br> and Event Interfaces<br>Ouadie EL FAROUKI  Log: [log](./log/87421a23e8c60e00a7b227d501e8aab2a1aff7ce)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2025.0.0|
|[5639971466ed74386a1811938022f0c333007b55](https://github.com/ggerganov/llama.cpp/commit/5639971466ed74386a1811938022f0c333007b55)<br>2024-10-03 07:50:44<br>Fixed dequant precision issues in Q4_1 a<br>nd Q5_1<br>Ouadie EL FAROUKI  Log: [log](./log/5639971466ed74386a1811938022f0c333007b55)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6](https://github.com/ggerganov/llama.cpp/commit/c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6)<br>2024-10-03 01:49:47<br>ggml-backend : add device and backend re<br>g interfaces<br>Diego Devesa  Log: [log](./log/c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[f536f4c4391bec74c432a924625c04e8c484d3ee](https://github.com/ggerganov/llama.cpp/commit/f536f4c4391bec74c432a924625c04e8c484d3ee)<br>2024-10-02 13:57:18<br>[SYCL] Initial cmake support of SYCL for<br> AMD GPUs<br>Alberto Cabrera Pérez  Log: [log](./log/f536f4c4391bec74c432a924625c04e8c484d3ee)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[95bc82fbc0df6d48cf66c857a4dda3d044f45ca2](https://github.com/ggerganov/llama.cpp/commit/95bc82fbc0df6d48cf66c857a4dda3d044f45ca2)<br>2024-09-26 17:38:31<br>[SYCL] add missed dll file in package<br>Neo Zhang Jianyu  Log: [log](./log/95bc82fbc0df6d48cf66c857a4dda3d044f45ca2)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[e62e9789cda3bf5573a747e55ec2a7ee32908f56](https://github.com/ggerganov/llama.cpp/commit/e62e9789cda3bf5573a747e55ec2a7ee32908f56)<br>2024-09-23 08:58:06<br>Revert "[SYCL] fallback mmvq<br>Akarshan Biswas  Log: [log](./log/e62e9789cda3bf5573a747e55ec2a7ee32908f56)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[d13edb17ed1ce3b961016cbdb616b1c8d161c026](https://github.com/ggerganov/llama.cpp/commit/d13edb17ed1ce3b961016cbdb616b1c8d161c026)<br>2024-09-20 20:12:52<br>ggml : fix builds<br>Georgi Gerganov  Log: [log](./log/d13edb17ed1ce3b961016cbdb616b1c8d161c026)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[424c5d00a9b97dd5559635872db9b57f87c23b02](https://github.com/ggerganov/llama.cpp/commit/424c5d00a9b97dd5559635872db9b57f87c23b02)<br>2024-09-20 19:04:44<br>ggml/examples: add backend support for n<br>umerical optimization<br>Johannes Gäßler  Log: [log](./log/424c5d00a9b97dd5559635872db9b57f87c23b02)|Build Err<br>NA|NA|tg=NA<br>pp=NA|NA|77/3<br>2025.0.0|
|[faf67b3de4688f47c3b1019c89df255df2fd59b4](https://github.com/ggerganov/llama.cpp/commit/faf67b3de4688f47c3b1019c89df255df2fd59b4)<br>2024-09-18 08:30:31<br>[SYCL]set context default value to avoid<br> memory issue, update guide<br>Neo Zhang Jianyu  Log: [log](./log/faf67b3de4688f47c3b1019c89df255df2fd59b4)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|510/0<br>2025.0.0|
|[6988da94a261444859f78595899212eeedc5ff9d](https://github.com/ggerganov/llama.cpp/commit/6988da94a261444859f78595899212eeedc5ff9d)<br>2024-09-15 18:55:52<br>cmake : correct order of sycl flags<br>Michael Podvitskiy  Log: [log](./log/6988da94a261444859f78595899212eeedc5ff9d)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[7596487bebd58eade3cd0133d42a9008aaaf9d09](https://github.com/ggerganov/llama.cpp/commit/7596487bebd58eade3cd0133d42a9008aaaf9d09)<br>2024-09-15 09:06:38<br>cmake : try to fix sycl+intel build<br>Michael Podvitskiy  Log: [log](./log/7596487bebd58eade3cd0133d42a9008aaaf9d09)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[c9c8575a1a8a170329afca4c4df4c005806efb1d](https://github.com/ggerganov/llama.cpp/commit/c9c8575a1a8a170329afca4c4df4c005806efb1d)<br>2024-09-12 17:44:17<br>enhance run script to be easy to change <br>the parameters<br>Neo Zhang Jianyu  Log: [log](./log/c9c8575a1a8a170329afca4c4df4c005806efb1d)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[d6a04f872dea8ade92527bb1488d4b0b90cc49f0](https://github.com/ggerganov/llama.cpp/commit/d6a04f872dea8ade92527bb1488d4b0b90cc49f0)<br>2024-09-12 14:23:49<br>ggml : hide ggml_object, ggml_cgraph, gg<br>ml_hash_set<br>Georgi Gerganov  Log: [log](./log/d6a04f872dea8ade92527bb1488d4b0b90cc49f0)|96.0%<br>NA|2.57|tg=NA<br>pp=NA|('ok', 'pass', 0)|510/0<br>2025.0.0|
|[51b603863627c4074e77b7e556e18ece86bdf9a3](https://github.com/ggerganov/llama.cpp/commit/51b603863627c4074e77b7e556e18ece86bdf9a3)<br>2024-09-11 01:53:42<br>sycl : update support conditions<br>Alberto Cabrera Pérez  Log: [log](./log/51b603863627c4074e77b7e556e18ece86bdf9a3)|96.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2024.2.1|
|[2a358fb0c4b6e917ac852aa17444cc94dd28a2a6](https://github.com/ggerganov/llama.cpp/commit/2a358fb0c4b6e917ac852aa17444cc94dd28a2a6)<br>2024-09-08 19:05:29<br>[SYCL] add check malloc result on device<br><br>Neo Zhang Jianyu  Log: [log](./log/2a358fb0c4b6e917ac852aa17444cc94dd28a2a6)|92.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2024.2.1|
|[5910ea942772ab6cbc21d0ad2d1208750ba39e1d](https://github.com/ggerganov/llama.cpp/commit/5910ea942772ab6cbc21d0ad2d1208750ba39e1d)<br>2024-09-04 16:26:33<br>[SYCL] Fix DMMV dequantization<br>Ouadie EL FAROUKI  Log: [log](./log/5910ea942772ab6cbc21d0ad2d1208750ba39e1d)|96.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2024.2.1|
|[cddae4884c853b1a7ab420458236d666e2e34423](https://github.com/ggerganov/llama.cpp/commit/cddae4884c853b1a7ab420458236d666e2e34423)<br>2024-08-30 20:10:01<br>Correct typo run_llama2.sh > run-llama2.<br>sh<br>蕭澧邦  Log: [log](./log/cddae4884c853b1a7ab420458236d666e2e34423)|92.0%<br>1417/1421|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2024.2.1|
|[11b84eb4578864827afcf956db5b571003f18180](https://github.com/ggerganov/llama.cpp/commit/11b84eb4578864827afcf956db5b571003f18180)<br>2024-08-22 19:39:47<br>[SYCL] Add a space to supress a cmake wa<br>rning<br>Akarshan Biswas  Log: [log](./log/11b84eb4578864827afcf956db5b571003f18180)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2024.2.1|
|[1731d4238f9e4f925a750810e7f5480827c66dcf](https://github.com/ggerganov/llama.cpp/commit/1731d4238f9e4f925a750810e7f5480827c66dcf)<br>2024-08-22 12:50:10<br>[SYCL] Add oneDNN primitive support<br>luoyu-intel  Log: [log](./log/1731d4238f9e4f925a750810e7f5480827c66dcf)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|512/0<br>2024.2.1|
|[50addec9a532a6518146ab837a85504850627316](https://github.com/ggerganov/llama.cpp/commit/50addec9a532a6518146ab837a85504850627316)<br>2024-08-20 23:50:17<br>[SYCL] fallback mmvq<br>Meng, Hengyu  Log: [log](./log/50addec9a532a6518146ab837a85504850627316)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|494/0<br>2024.2.1|
|[4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b](https://github.com/ggerganov/llama.cpp/commit/4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b)<br>2024-08-20 23:06:51<br>[SYCL] Fix SYCL `im2col` and `convert` O<br>verflow with Large Dims<br>zhentaoyu  Log: [log](./log/4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|494/0<br>2024.2.1|
|[06943a69f678fb32829ff06d9c18367b17d4b361](https://github.com/ggerganov/llama.cpp/commit/06943a69f678fb32829ff06d9c18367b17d4b361)<br>2024-08-13 21:13:15<br>ggml : move rope type enum to ggml.h<br>Daniel Bevenius  Log: [log](./log/06943a69f678fb32829ff06d9c18367b17d4b361)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[a21c6fd45032a20180e026773582d21294c85619](https://github.com/ggerganov/llama.cpp/commit/a21c6fd45032a20180e026773582d21294c85619)<br>2024-08-11 16:37:43<br>update guide<br>Neo Zhang  Log: [log](./log/a21c6fd45032a20180e026773582d21294c85619)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[0478174d5959b66096ae6609fcb0df14cab66b51](https://github.com/ggerganov/llama.cpp/commit/0478174d5959b66096ae6609fcb0df14cab66b51)<br>2024-08-07 11:25:36<br>[SYCL] Updated SYCL device filtering<br>Ouadie EL FAROUKI  Log: [log](./log/0478174d5959b66096ae6609fcb0df14cab66b51)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf](https://github.com/ggerganov/llama.cpp/commit/2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf)<br>2024-08-06 15:26:46<br>ggml : add epsilon as a parameter for gr<br>oup_norm<br>Molly Sophia  Log: [log](./log/2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[d4ff847153e9cf7220d1b39aa21172069e6e8cea](https://github.com/ggerganov/llama.cpp/commit/d4ff847153e9cf7220d1b39aa21172069e6e8cea)<br>2024-08-06 09:09:12<br>[SYCL] correct .html name<br>Neo Zhang  Log: [log](./log/d4ff847153e9cf7220d1b39aa21172069e6e8cea)|92.0%<br>1338/1342|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[0fbbd884589d585c3b43cae8c16938ffffb863b9](https://github.com/ggerganov/llama.cpp/commit/0fbbd884589d585c3b43cae8c16938ffffb863b9)<br>2024-08-02 01:55:17<br>[SYCL] Fixing wrong VDR iq4nl value<br>Ouadie EL FAROUKI  Log: [log](./log/0fbbd884589d585c3b43cae8c16938ffffb863b9)|92.0%<br>1347/1351|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[c887d8b01726b11ea03dbcaa9d44fa74422d0076](https://github.com/ggerganov/llama.cpp/commit/c887d8b01726b11ea03dbcaa9d44fa74422d0076)<br>2024-07-30 14:56:51<br>[SYCL] Add `TIMESTEP_EMBEDDING` OP<br>zhentaoyu  Log: [log](./log/c887d8b01726b11ea03dbcaa9d44fa74422d0076)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[0832de723695ab400316a6c49b9f712380e3a731](https://github.com/ggerganov/llama.cpp/commit/0832de723695ab400316a6c49b9f712380e3a731)<br>2024-07-29 10:50:27<br>[SYCL] add conv support<br>Meng, Hengyu  Log: [log](./log/0832de723695ab400316a6c49b9f712380e3a731)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|464/0<br>2024.2.1|
|[2b1f616b208a4a21c4ee7a7eb85d822ff1d787af](https://github.com/ggerganov/llama.cpp/commit/2b1f616b208a4a21c4ee7a7eb85d822ff1d787af)<br>2024-07-27 04:41:55<br>ggml : reduce hash table reset cost<br>slaren  Log: [log](./log/2b1f616b208a4a21c4ee7a7eb85d822ff1d787af)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|450/0<br>2024.2.1|
|[ed67bcb24f2d6ac0072cae72620b2bd971741b98](https://github.com/ggerganov/llama.cpp/commit/ed67bcb24f2d6ac0072cae72620b2bd971741b98)<br>2024-07-25 11:45:18<br>[SYCL] fix multi-gpu issue on sycl<br>Chen Xi  Log: [log](./log/ed67bcb24f2d6ac0072cae72620b2bd971741b98)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|454/0<br>2024.2.1|
|[f19bf99c015d3d745143e8bb4f056e0ea015ad40](https://github.com/ggerganov/llama.cpp/commit/f19bf99c015d3d745143e8bb4f056e0ea015ad40)<br>2024-07-24 14:36:00<br>Build Llama SYCL Intel with static libs<br>Joe Todd  Log: [log](./log/f19bf99c015d3d745143e8bb4f056e0ea015ad40)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[79167d9e49aef9caa98e13ee7ca067ec9f88b4b5](https://github.com/ggerganov/llama.cpp/commit/79167d9e49aef9caa98e13ee7ca067ec9f88b4b5)<br>2024-07-24 11:55:26<br>Re-add erroneously removed -fsycl from G<br>GML_EXTRA_LIBS<br>Joe Todd  Log: [log](./log/79167d9e49aef9caa98e13ee7ca067ec9f88b4b5)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|472/0<br>2024.2.1|
|[64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e](https://github.com/ggerganov/llama.cpp/commit/64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e)<br>2024-07-23 14:58:37<br>sycl : Add support for non-release DPC++<br> & oneMKL<br>Joe Todd  Log: [log](./log/64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|472/0<br>2024.2.1|
|[063d99ad11f1295046610ce5b97e105849a4b573](https://github.com/ggerganov/llama.cpp/commit/063d99ad11f1295046610ce5b97e105849a4b573)<br>2024-07-23 07:43:28<br>[SYCL] fix scratch size of softmax<br>luoyu-intel  Log: [log](./log/063d99ad11f1295046610ce5b97e105849a4b573)|92.0%<br>1332/1334|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[16bdfa42acb09175e88cf97e9d9e4e48f616d120](https://github.com/ggerganov/llama.cpp/commit/16bdfa42acb09175e88cf97e9d9e4e48f616d120)<br>2024-07-15 19:32:15<br>[SYCL] add concat through dim 1/2<br>Meng, Hengyu  Log: [log](./log/16bdfa42acb09175e88cf97e9d9e4e48f616d120)|91.0%<br>1279/1281|2.59|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[b549a1bbefb2f1fbb8b558bac1f2ae7967e60964](https://github.com/ggerganov/llama.cpp/commit/b549a1bbefb2f1fbb8b558bac1f2ae7967e60964)<br>2024-07-12 00:52:04<br>[SYCL] fix the mul_mat_id ut issues<br>Chen Xi  Log: [log](./log/b549a1bbefb2f1fbb8b558bac1f2ae7967e60964)|91.0%<br>1279/1281|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|464/0<br>2024.2.0|
|[f4444d992c16b6b9442f4770c7c3a10b19a08343](https://github.com/ggerganov/llama.cpp/commit/f4444d992c16b6b9442f4770c7c3a10b19a08343)<br>2024-07-10 16:10:49<br>[SYCL] Use multi_ptr to clean up depreca<br>ted warnings<br>AidanBeltonS  Log: [log](./log/f4444d992c16b6b9442f4770c7c3a10b19a08343)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.0|
|[5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b](https://github.com/ggerganov/llama.cpp/commit/5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b)<br>2024-07-09 15:03:15<br>sycl : Reenabled mmvq path for the SYCL <br>Nvidia Backend<br>Alberto Cabrera Pérez  Log: [log](./log/5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|692/0<br>2024.2.0|
|[a130eccef42b75a84da270411cefeed45c153e30](https://github.com/ggerganov/llama.cpp/commit/a130eccef42b75a84da270411cefeed45c153e30)<br>2024-07-08 21:35:17<br>labeler : updated sycl to match docs and<br> code refactor<br>Alberto Cabrera Pérez  Log: [log](./log/a130eccef42b75a84da270411cefeed45c153e30)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|692/0<br>2024.2.0|
|[2ec846d558f6385ea647f7b8e665eb249c1ebce7](https://github.com/ggerganov/llama.cpp/commit/2ec846d558f6385ea647f7b8e665eb249c1ebce7)<br>2024-07-08 14:22:41<br>sycl : fix powf call in device code<br>Alberto Cabrera Pérez  Log: [log](./log/2ec846d558f6385ea647f7b8e665eb249c1ebce7)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|692/0<br>2024.2.0|
|[3f2d538b817112ad8429341c7e8657dcd660f4d3](https://github.com/ggerganov/llama.cpp/commit/3f2d538b817112ad8429341c7e8657dcd660f4d3)<br>2024-07-08 13:51:31<br>scripts : fix sync for sycl<br>Georgi Gerganov  Log: [log](./log/3f2d538b817112ad8429341c7e8657dcd660f4d3)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|692/0<br>2024.2.0|
|[be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d](https://github.com/ggerganov/llama.cpp/commit/be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d)<br>2024-07-05 18:08:32<br>Reorganize documentation pages<br>Xuan Son Nguyen  Log: [log](./log/be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|692/0<br>2024.2.0|
|[1f3e1b66e21310ed78b964f72f19766549633f0e](https://github.com/ggerganov/llama.cpp/commit/1f3e1b66e21310ed78b964f72f19766549633f0e)<br>2024-07-05 13:23:25<br>Enabled more data types for oneMKL gemm_<br>batch<br>Ouadie EL FAROUKI  Log: [log](./log/1f3e1b66e21310ed78b964f72f19766549633f0e)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|692/0<br>2024.2.0|
|[f09b7cb609d80b8031803f89255991dc8b35db69](https://github.com/ggerganov/llama.cpp/commit/f09b7cb609d80b8031803f89255991dc8b35db69)<br>2024-07-05 10:32:29<br>rm get_work_group_size<br>Neo Zhang Jianyu  Log: [log](./log/f09b7cb609d80b8031803f89255991dc8b35db69)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|548/0<br>2024.2.0|
|[a9554e20b66546b0549aebe2e1034bc8afe9d809](https://github.com/ggerganov/llama.cpp/commit/a9554e20b66546b0549aebe2e1034bc8afe9d809)<br>2024-07-05 05:06:13<br>[SYCL] Fix WARP_SIZE=16 bug of Intel GPU<br><br>luoyu-intel  Log: [log](./log/a9554e20b66546b0549aebe2e1034bc8afe9d809)|91.0%<br>NA|2.6|tg=NA<br>pp=NA|('ok', 'pass', 0)|690/0<br>2024.2.0|
|[f619024764e72261f14d7c31d892b8fb976603b4](https://github.com/ggerganov/llama.cpp/commit/f619024764e72261f14d7c31d892b8fb976603b4)<br>2024-07-04 02:07:19<br>[SYCL] Remove unneeded semicolons<br>AidanBeltonS  Log: [log](./log/f619024764e72261f14d7c31d892b8fb976603b4)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|556/0<br>2024.2.0|
|[fadde6713506d9e6c124f5680ab8c7abebe31837](https://github.com/ggerganov/llama.cpp/commit/fadde6713506d9e6c124f5680ab8c7abebe31837)<br>2024-07-03 02:55:34<br>Dequant improvements rebase<br>AidanBeltonS  Log: [log](./log/fadde6713506d9e6c124f5680ab8c7abebe31837)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|556/0<br>2024.2.0|
|[07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81](https://github.com/ggerganov/llama.cpp/commit/07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81)<br>2024-07-02 12:18:10<br>Removes multiple newlines at the end of <br>files that is breaking the editorconfig <br>step of CI.<br>Clint Herron  Log: [log](./log/07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|550/0<br>2024.2.0|
|[a9f3b102157ba992cfe058909b7f6e1906d2d647](https://github.com/ggerganov/llama.cpp/commit/a9f3b102157ba992cfe058909b7f6e1906d2d647)<br>2024-07-02 04:50:07<br>[SYCL] Fix win build conflict of math li<br>brary<br>luoyu-intel  Log: [log](./log/a9f3b102157ba992cfe058909b7f6e1906d2d647)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|550/0<br>2024.2.0|
|[d08c20eddedb24515a3212e2de66bdff41a26b8c](https://github.com/ggerganov/llama.cpp/commit/d08c20eddedb24515a3212e2de66bdff41a26b8c)<br>2024-07-02 02:16:00<br>[SYCL] Fix the sub group size of Intel<br>luoyu-intel  Log: [log](./log/d08c20eddedb24515a3212e2de66bdff41a26b8c)|91.0%<br>NA|2.63|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: The original copy text needed sh<br>ould describe the products/ services.', <br>0)|586/0<br>2024.2.0|
|[cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846](https://github.com/ggerganov/llama.cpp/commit/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846)<br>2024-07-01 20:39:06<br>CUDA: refactor and optimize IQ MMVQ<br>Johannes Gäßler  Log: [log](./log/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|530/0<br>2024.2.0|
|[197fe6c1d7bec6718ce901f0141b2725240f298c](https://github.com/ggerganov/llama.cpp/commit/197fe6c1d7bec6718ce901f0141b2725240f298c)<br>2024-07-01 19:39:06<br>[SYCL] Update SYCL-Rope op and Refactor<br>zhentaoyu  Log: [log](./log/197fe6c1d7bec6718ce901f0141b2725240f298c)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|530/0<br>2024.2.0|
|[f3f65429c44bb195a9195bfdc19a30a79709db7b](https://github.com/ggerganov/llama.cpp/commit/f3f65429c44bb195a9195bfdc19a30a79709db7b)<br>2024-06-26 18:33:02<br>llama : reorganize source code + improve<br> CMake<br>Georgi Gerganov  Log: [log](./log/f3f65429c44bb195a9195bfdc19a30a79709db7b)|95.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|520/0<br>2024.2.0|
|[083bacce14c1aaf9976aa40e8266cdc25ac749d3](https://github.com/ggerganov/llama.cpp/commit/083bacce14c1aaf9976aa40e8266cdc25ac749d3)<br>2024-06-25 10:19:20<br>[SYCL] Re-enabled mul_mat_batched_sycl<br>Meng, Hengyu  Log: [log](./log/083bacce14c1aaf9976aa40e8266cdc25ac749d3)|91.0%<br>NA|3.29|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:#################################<br>########################################<br>', 0)|524/0<br>2024.2.0|
|[de391e4c803383bbea054b6edd016e78c024a74d](https://github.com/ggerganov/llama.cpp/commit/de391e4c803383bbea054b6edd016e78c024a74d)<br>2024-06-20 13:19:05<br>[SYCL] Fix windows build and inference<br>luoyu-intel  Log: [log](./log/de391e4c803383bbea054b6edd016e78c024a74d)|91.0%<br>NA|3.28|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Customize your site', 6)|524/0<br>2024.2.0|
|[623494a478134432fd2d7ee40135770a3340674f](https://github.com/ggerganov/llama.cpp/commit/623494a478134432fd2d7ee40135770a3340674f)<br>2024-06-19 09:11:51<br>[SYCL] refactor<br>Meng, Hengyu  Log: [log](./log/623494a478134432fd2d7ee40135770a3340674f)|91.0%<br>NA|3.28|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Customize your site', 6)|512/0<br>2024.2.0|
|[df68d4fa5dc929217d3e64d673e099d7a417b206](https://github.com/ggerganov/llama.cpp/commit/df68d4fa5dc929217d3e64d673e099d7a417b206)<br>2024-06-17 11:17:07<br>[SYCL] Update README-sycl.html for Chapter<br> "Recommended release" and "News"<br>Neo Zhang  Log: [log](./log/df68d4fa5dc929217d3e64d673e099d7a417b206)|91.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>The number of work-items in each dimensi<br>on of a work-group cannot exceed {512, 5<br>', 0)|450/0<br>2024.2.0|
|[7b2f4a7d193ef2475259bbe7656fcccfab4b1217](https://github.com/ggerganov/llama.cpp/commit/7b2f4a7d193ef2475259bbe7656fcccfab4b1217)<br>2024-06-15 14:05:10<br>[SYCL] remove global variables<br>Meng, Hengyu  Log: [log](./log/7b2f4a7d193ef2475259bbe7656fcccfab4b1217)|91.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>The number of work-items in each dimensi<br>on of a work-group cannot exceed {512, 5<br>', 0)|450/0<br>2024.2.0|
|[f578b86b2123d0f92afbaa98a031df4d4464e582](https://github.com/ggerganov/llama.cpp/commit/f578b86b2123d0f92afbaa98a031df4d4464e582)<br>2024-06-13 03:11:35<br>move BLAS to a separate backend<br>slaren  Log: [log](./log/f578b86b2123d0f92afbaa98a031df4d4464e582)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’4Cin2? TheCre or 2-over - components<br>', 6)|463/0<br>2024.2.0|
|[1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7](https://github.com/ggerganov/llama.cpp/commit/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7)<br>2024-06-13 00:41:52<br>`build`: rename main → llama-cli, server<br> → llama-server, llava-cli → llama-llava<br>-cli, etc...<br>Olivier Chafik  Log: [log](./log/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|463/0<br>2024.2.0|
|[a9cae48003dfc4fe95b8f5c81682fc6e63425235](https://github.com/ggerganov/llama.cpp/commit/a9cae48003dfc4fe95b8f5c81682fc6e63425235)<br>2024-06-12 16:00:22<br>tests : add non-cont unary tests<br>Georgi Gerganov  Log: [log](./log/a9cae48003dfc4fe95b8f5c81682fc6e63425235)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|463/0<br>2024.2.0|
|[af4ae502ddaeb03cd5861273ca2e9a5ae4551db7](https://github.com/ggerganov/llama.cpp/commit/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7)<br>2024-06-10 02:21:31<br>use the correct SYCL context for host US<br>M allocations<br>Ben Ashbaugh  Log: [log](./log/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’4Cin2? TheCre or 2-over - components<br>', 6)|463/0<br>2024.2.0|
|[fe1e3917cfa0f9397a765cfd0aef880674d938d5](https://github.com/ggerganov/llama.cpp/commit/fe1e3917cfa0f9397a765cfd0aef880674d938d5)<br>2024-06-09 01:43:39<br>Revert "[SYCL] Update rpc-server.cpp to <br>include SYCL backend<br>slaren  Log: [log](./log/fe1e3917cfa0f9397a765cfd0aef880674d938d5)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|463/0<br>2024.2.0|
|[d5c938cd7716b9a2ace49a43a469dfbffcff4d28](https://github.com/ggerganov/llama.cpp/commit/d5c938cd7716b9a2ace49a43a469dfbffcff4d28)<br>2024-06-07 14:28:26<br>[SYCL] fix softmax r2r result wrong issu<br>e<br>pengxin99  Log: [log](./log/d5c938cd7716b9a2ace49a43a469dfbffcff4d28)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|463/0<br>2024.2.0|
|[2b3389677a833cee0880226533a1768b1a9508d2](https://github.com/ggerganov/llama.cpp/commit/2b3389677a833cee0880226533a1768b1a9508d2)<br>2024-06-05 11:29:20<br>ggml : refactor rope norm/neox<br>Georgi Gerganov  Log: [log](./log/2b3389677a833cee0880226533a1768b1a9508d2)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|463/0<br>2024.2.0|
|[554c247caffed64465f372661f2826640cb10430](https://github.com/ggerganov/llama.cpp/commit/554c247caffed64465f372661f2826640cb10430)<br>2024-06-04 21:23:20<br>ggml : remove OpenCL<br>Georgi Gerganov  Log: [log](./log/554c247caffed64465f372661f2826640cb10430)|91.0%<br>NA|3.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make report (v has have has got <br>(pay( Big and (c gu in to The(Col U +C C<br>', 6)|457/0<br>2024.2.0|
|[9422c5e34bbd302493b77a8f6d546154a1f4fe82](https://github.com/ggerganov/llama.cpp/commit/9422c5e34bbd302493b77a8f6d546154a1f4fe82)<br>2024-06-02 19:13:54<br>[SYCL] Update rpc-server.cpp to include <br>SYCL backend<br>nickp27  Log: [log](./log/9422c5e34bbd302493b77a8f6d546154a1f4fe82)|91.0%<br>NA|3.26|tg=NA<br>pp=NA|('ok', 'pass', 0)|457/0<br>2024.2.0|
