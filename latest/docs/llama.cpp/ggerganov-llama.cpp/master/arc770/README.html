<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ggerganov/llama.cpp CI for arc770 by SYCL Backend &mdash; Neo Zhang Jianyu CI log latest documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/custom.css?v=2e2c8cb8" />

  
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../../../_static/documentation_options.js?v=c6e86fd7"></script>
        <script src="../../../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            Neo Zhang Jianyu CI log
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../README.html">llama.cpp</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/NeoZhangJianyu/ci_log">Repo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">Neo Zhang Jianyu CI log</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ggerganov/llama.cpp CI for arc770 by SYCL Backend</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/docs/llama.cpp/ggerganov-llama.cpp/master/arc770/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ggerganov-llama-cpp-ci-for-arc770-by-sycl-backend">
<h1><a class="reference external" href="https://github.com/ggerganov/llama.cpp/tree/master">ggerganov/llama.cpp</a> CI for arc770 by SYCL Backend<a class="headerlink" href="#ggerganov-llama-cpp-ci-for-arc770-by-sycl-backend" title="Link to this heading"></a></h1>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<p>Figure</p>
<p><img alt="Performance" src="../../../../../_images/perf4.png" /></p>
</section>
<section id="detail">
<h2>Detail<a class="headerlink" href="#detail" title="Link to this heading"></a></h2>
<p><strong>GGUF res</strong> is verified by script ./example/sycl/run.sh with llama2-7b-Q4 for correction</p>
<p><strong>GGUF Perf</strong> is the performance data by script ./example/sycl/run.sh with llama2-7b-Q4</p>
<p><strong>Bench Perf</strong> is the performance data by llama-bench with llama2-7b-Q4</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Commit Info</th>
<th>UT PassRate<br>Detail</th>
<th>GGUF Perf<br>(token/s)</th>
<th>Bench Perf<br>(token/s)</th>
<th><div style="width:100px">GGUF res</div></th>
<th>Warn/Err<br>oneAPI</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/98bd9ab1e4fdef1497da628574bb90d0890539e7">98bd9ab1e4fdef1497da628574bb90d0890539e7</a><br>2025-12-02 08:56:46<br>enhance argsort for UT<br>Neo Zhang Jianyu  Log: <a href="./log/98bd9ab1e4fdef1497da628574bb90d0890539e7">log</a></td>
<td>95.0%<br>NA</td>
<td>NA</td>
<td>tg=40.56<br>pp=891.95</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>11/0<br>2025.3.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2ba719519d950c5a62c00cdb8b119cc0914c1fa3">2ba719519d950c5a62c00cdb8b119cc0914c1fa3</a><br>2025-11-30 21:57:31<br>model: LFM2-VL fixes<br>Tarek Dakhran  Log: <a href="./log/2ba719519d950c5a62c00cdb8b119cc0914c1fa3">log</a></td>
<td>89.0%<br>NA</td>
<td>NA</td>
<td>tg=40.48<br>pp=892.07</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>11/0<br>2025.3.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7d2add51d8e3759020d70f2ff3a76b5795ff67bc">7d2add51d8e3759020d70f2ff3a76b5795ff67bc</a><br>2025-11-29 20:59:44<br>sycl : support to malloc memory on devic<br>e more than 4GB, update the doc and scri<br>pt<br>Neo Zhang  Log: <a href="./log/7d2add51d8e3759020d70f2ff3a76b5795ff67bc">log</a></td>
<td>92.0%<br>NA</td>
<td>NA</td>
<td>tg=40.59<br>pp=892.9</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>11/0<br>2025.3.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/efaaccdd69cd9db777584c2a062f70c0526a6fb5">efaaccdd69cd9db777584c2a062f70c0526a6fb5</a><br>2025-11-28 08:50:56<br>refactor pad_reflect_1d to make the UT c<br>ase pass<br>Neo Zhang Jianyu  Log: <a href="./log/efaaccdd69cd9db777584c2a062f70c0526a6fb5">log</a></td>
<td>92.0%<br>NA</td>
<td>NA</td>
<td>tg=45.59<br>pp=906.99</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>11/0<br>2025.3.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/72bd7321a7d7465d371eb2ae46cd5518842c8f44">72bd7321a7d7465d371eb2ae46cd5518842c8f44</a><br>2025-11-16 01:52:42<br>sycl : unify unary kernels with a generi<br>c implementation and enable wide operato<br>r support<br>shani-f  Log: <a href="./log/72bd7321a7d7465d371eb2ae46cd5518842c8f44">log</a></td>
<td>92.0%<br>3174/3176</td>
<td>34.73</td>
<td>tg=45.48<br>pp=872.62</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/07751f8d446e2d05d069e8d77d984dd64c1a5878">07751f8d446e2d05d069e8d77d984dd64c1a5878</a><br>2025-11-13 08:42:23<br>update SYCL support OPs<br>Neo Zhang Jianyu  Log: <a href="./log/07751f8d446e2d05d069e8d77d984dd64c1a5878">log</a></td>
<td>92.0%<br>3041/3043</td>
<td>34.79</td>
<td>tg=45.62<br>pp=872.08</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5da7664960f93a5602d166326f6375dd7cc112ad">5da7664960f93a5602d166326f6375dd7cc112ad</a><br>2025-11-12 14:44:29<br>[SYCL]fix ci crash about SSM_CONV<br>Neo Zhang Jianyu  Log: <a href="./log/5da7664960f93a5602d166326f6375dd7cc112ad">log</a></td>
<td>92.0%<br>3041/3043</td>
<td>34.68</td>
<td>tg=45.52<br>pp=871.72</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9d7c518d642db8657e2a53a9793c5f039ed8ea5a">9d7c518d642db8657e2a53a9793c5f039ed8ea5a</a><br>2025-11-06 12:02:33<br>sycl: add CONCAT operator support<br>YehuditE  Log: <a href="./log/9d7c518d642db8657e2a53a9793c5f039ed8ea5a">log</a></td>
<td>89.0%<br>NA</td>
<td>34.75</td>
<td>tg=46.13<br>pp=869.49</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7e994168b1ccc12337ba8de939c4fd466107c1fb">7e994168b1ccc12337ba8de939c4fd466107c1fb</a><br>2025-11-03 03:35:33<br>SYCL: optimized repeat_back kernel<br>shani-f  Log: <a href="./log/7e994168b1ccc12337ba8de939c4fd466107c1fb">log</a></td>
<td>92.0%<br>NA</td>
<td>34.71</td>
<td>tg=38.76<br>pp=873.42</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d261223d24e97f2df50220e4a5b7f0adb69bba81">d261223d24e97f2df50220e4a5b7f0adb69bba81</a><br>2025-10-30 23:19:14<br>model: add support for qwen3vl series<br>JJJYmmm  Log: <a href="./log/d261223d24e97f2df50220e4a5b7f0adb69bba81">log</a></td>
<td>92.0%<br>NA</td>
<td>34.75</td>
<td>tg=46.06<br>pp=872.09</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/338074c383c81366320d176d83b94b0a567ee0c2">338074c383c81366320d176d83b94b0a567ee0c2</a><br>2025-10-29 08:14:39<br>sycl: add RMS_NORM_BACK operation suppor<br>t<br>YaelLogic  Log: <a href="./log/338074c383c81366320d176d83b94b0a567ee0c2">log</a></td>
<td>92.0%<br>NA</td>
<td>34.75</td>
<td>tg=46.13<br>pp=872.39</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ad8d36beffd791db10c94eb9e964afb891e3ca55">ad8d36beffd791db10c94eb9e964afb891e3ca55</a><br>2025-10-28 03:50:33<br>sycl: add SSM_CONV operation support<br>tamarPal  Log: <a href="./log/ad8d36beffd791db10c94eb9e964afb891e3ca55">log</a></td>
<td>92.0%<br>NA</td>
<td>34.75</td>
<td>tg=51.0<br>pp=871.84</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2b9bd9bf4e759c05db629ec1c391dc8aeaa71887">2b9bd9bf4e759c05db629ec1c391dc8aeaa71887</a><br>2025-10-27 03:20:24<br>sycl: add ROLL operation support<br>tamarPal  Log: <a href="./log/2b9bd9bf4e759c05db629ec1c391dc8aeaa71887">log</a></td>
<td>89.0%<br>17819/17824</td>
<td>34.74</td>
<td>tg=51.24<br>pp=872.76</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/59fc1ec8e83b14354c1a3a8acf8c5c2cbf9af42f">59fc1ec8e83b14354c1a3a8acf8c5c2cbf9af42f</a><br>2025-10-27 03:19:50<br>sycl: add REPEAT_BACK operation support<br>shani-f  Log: <a href="./log/59fc1ec8e83b14354c1a3a8acf8c5c2cbf9af42f">log</a></td>
<td>92.0%<br>17819/17824</td>
<td>34.87</td>
<td>tg=51.4<br>pp=872.44</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9de9672adb0f4ca4e39483ac3ffed52b3f70a55d">9de9672adb0f4ca4e39483ac3ffed52b3f70a55d</a><br>2025-10-22 20:05:15<br>sycl: use async memory allocation to fix<br> crashes during graph recording<br>Matthew Michel  Log: <a href="./log/9de9672adb0f4ca4e39483ac3ffed52b3f70a55d">log</a></td>
<td>92.0%<br>17678/17680</td>
<td>34.93</td>
<td>tg=51.22<br>pp=873.1</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2">6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2</a><br>2025-10-21 01:21:12<br>sycl : add PAD_REFLECT_D1 operator suppo<br>rt<br>YehuditE  Log: <a href="./log/6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2">log</a></td>
<td>89.0%<br>17676/17678</td>
<td>32.33</td>
<td>tg=50.96<br>pp=871.87</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2330de7b847ca84eac766df372c604c26db72747">2330de7b847ca84eac766df372c604c26db72747</a><br>2025-10-20 11:08:32<br>SYCL: Add support for FLOOR,CEIL,ROUND a<br>nd TRUNC unary operators<br>safranowith  Log: <a href="./log/2330de7b847ca84eac766df372c604c26db72747">log</a></td>
<td>92.0%<br>NA</td>
<td>32.27</td>
<td>tg=50.97<br>pp=873.09</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ceff6bb253dd306f5404d7ccb3f11fadafe71b52">ceff6bb253dd306f5404d7ccb3f11fadafe71b52</a><br>2025-10-17 05:36:40<br>SYCL SET operator optimized for F32 tens<br>ors<br>GittyBurstein  Log: <a href="./log/ceff6bb253dd306f5404d7ccb3f11fadafe71b52">log</a></td>
<td>95.0%<br>NA</td>
<td>32.32</td>
<td>tg=51.06<br>pp=873.52</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b22572e97dc51757d3ebe917a5a283385010ec68">b22572e97dc51757d3ebe917a5a283385010ec68</a><br>2025-10-16 16:26:21<br>sycl : add ARANGE operator<br>GittyBurstein  Log: <a href="./log/b22572e97dc51757d3ebe917a5a283385010ec68">log</a></td>
<td>92.0%<br>NA</td>
<td>32.38</td>
<td>tg=51.13<br>pp=872.5</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ee50ee1eadff58777ae746827b04de7ba0befc55">ee50ee1eadff58777ae746827b04de7ba0befc55</a><br>2025-10-16 07:21:28<br>SYCL: Add GGML_OP_MEAN operator support<br>yael-works  Log: <a href="./log/ee50ee1eadff58777ae746827b04de7ba0befc55">log</a></td>
<td>95.0%<br>NA</td>
<td>30.39</td>
<td>tg=51.22<br>pp=873.57</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c7be9febcbafa9af7d1b9443f86475c59c9c5f87">c7be9febcbafa9af7d1b9443f86475c59c9c5f87</a><br>2025-10-12 21:53:35<br>[SYCL] fix UT fault cases: count-equal, <br>argsort, pad OPs<br>Neo Zhang Jianyu  Log: <a href="./log/c7be9febcbafa9af7d1b9443f86475c59c9c5f87">log</a></td>
<td>95.0%<br>NA</td>
<td>32.26</td>
<td>tg=51.16<br>pp=871.3</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b2602137557b2b28a39e03612717d85ead9a6f5a">b2602137557b2b28a39e03612717d85ead9a6f5a</a><br>2025-10-09 15:25:11<br>[SYCL] refactor soft_max, add soft_max_b<br>ack<br>Neo Zhang Jianyu  Log: <a href="./log/b2602137557b2b28a39e03612717d85ead9a6f5a">log</a></td>
<td>89.0%<br>NA</td>
<td>32.18</td>
<td>tg=50.9<br>pp=871.81</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2be72c2b121ee99f33927149265ce6073ade9e59">2be72c2b121ee99f33927149265ce6073ade9e59</a><br>2025-10-02 15:16:25<br>SYCL: Update to oneAPI 2025.2<br>Neo Zhang Jianyu  Log: <a href="./log/2be72c2b121ee99f33927149265ce6073ade9e59">log</a></td>
<td>92.0%<br>NA</td>
<td>32.14</td>
<td>tg=51.22<br>pp=872.64</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3ecb2f671a2f49d56357f99d135a94e841759178">3ecb2f671a2f49d56357f99d135a94e841759178</a><br>2025-09-22 19:13:00<br>ggml : implement set_rows with i32 index<br><br>Sigbjørn Skjæret  Log: <a href="./log/3ecb2f671a2f49d56357f99d135a94e841759178">log</a></td>
<td>92.0%<br>NA</td>
<td>22.43</td>
<td>tg=39.37<br>pp=872.5</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c0b45097c33e2667a94444f08cc9e36bec0a5e2e">c0b45097c33e2667a94444f08cc9e36bec0a5e2e</a><br>2025-09-18 13:46:17<br>rename optimize_graph to graph_optimize<br>Jeff Bolz  Log: <a href="./log/c0b45097c33e2667a94444f08cc9e36bec0a5e2e">log</a></td>
<td>92.0%<br>NA</td>
<td>29.27</td>
<td>tg=39.17<br>pp=867.48</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3913f8730ec6d6245480affc30ae3049107956f4">3913f8730ec6d6245480affc30ae3049107956f4</a><br>2025-09-16 15:25:57<br>ggml : fix padding in timestep embedding<br> kernels<br>Daniel Bevenius  Log: <a href="./log/3913f8730ec6d6245480affc30ae3049107956f4">log</a></td>
<td>92.0%<br>NA</td>
<td>32.06</td>
<td>tg=42.49<br>pp=862.83</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b907255f4bd169b0dc7dca9553b4c54af5170865">b907255f4bd169b0dc7dca9553b4c54af5170865</a><br>2025-09-15 19:51:35<br>SYCL: Add COUNT_EQUAL operator support<br>yael-works  Log: <a href="./log/b907255f4bd169b0dc7dca9553b4c54af5170865">log</a></td>
<td>92.0%<br>NA</td>
<td>22.24</td>
<td>tg=39.41<br>pp=868.15</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/704d90c987cdf00751567b2088c4e54742aa2d3f">704d90c987cdf00751567b2088c4e54742aa2d3f</a><br>2025-09-12 09:15:12<br>Revert "sycl: add usage of enqueue_funct<br>ions extension<br>Neo Zhang Jianyu  Log: <a href="./log/704d90c987cdf00751567b2088c4e54742aa2d3f">log</a></td>
<td>92.0%<br>14470/14471</td>
<td>16.55</td>
<td>tg=25.43<br>pp=414.57</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e68aa10d8f3d26fdad5b912540362d79de5460e3">e68aa10d8f3d26fdad5b912540362d79de5460e3</a><br>2025-09-08 13:10:07<br>vulkan: sort graph to allow more paralle<br>l execution<br>Jeff Bolz  Log: <a href="./log/e68aa10d8f3d26fdad5b912540362d79de5460e3">log</a></td>
<td>92.0%<br>14254/14255</td>
<td>17.36</td>
<td>tg=27.06<br>pp=418.46</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0a1b3982cd0bd18730d50a693053b88c13fd04a6">0a1b3982cd0bd18730d50a693053b88c13fd04a6</a><br>2025-09-04 16:38:49<br>ggml: add ops for WAN video model<br>leejet  Log: <a href="./log/0a1b3982cd0bd18730d50a693053b88c13fd04a6">log</a></td>
<td>94.0%<br>NA</td>
<td>17.83</td>
<td>tg=27.26<br>pp=596.51</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the platform for your web<br>site', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8b696861364360770e9f61a3422d32941a477824">8b696861364360770e9f61a3422d32941a477824</a><br>2025-08-27 00:27:49<br>SYCL: fix rms_norm_mul_add for tensor di<br>m not a multiple of sg_size<br>Akarshan Biswas  Log: <a href="./log/8b696861364360770e9f61a3422d32941a477824">log</a></td>
<td>94.0%<br>NA</td>
<td>22.0</td>
<td>tg=26.53<br>pp=606.45</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0a9b43e507a359ca392c037cf341f55137ad0b69">0a9b43e507a359ca392c037cf341f55137ad0b69</a><br>2025-08-23 08:35:21<br>vulkan : support ggml_mean<br>Acly  Log: <a href="./log/0a9b43e507a359ca392c037cf341f55137ad0b69">log</a></td>
<td>94.0%<br>NA</td>
<td>21.48</td>
<td>tg=27.36<br>pp=599.65</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/29f538ac630d6544406a0702476e36808a6bd1b3">29f538ac630d6544406a0702476e36808a6bd1b3</a><br>2025-08-21 06:12:28<br>examples : remove references to <code>make</code> i<br>n examples [no ci]<br>Daniel Bevenius  Log: <a href="./log/29f538ac630d6544406a0702476e36808a6bd1b3">log</a></td>
<td>94.0%<br>NA</td>
<td>19.7</td>
<td>tg=27.02<br>pp=415.42</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f4586ee5986d6f965becb37876d6f3666478a961">f4586ee5986d6f965becb37876d6f3666478a961</a><br>2025-08-12 13:58:22<br>sycl: Fix and disable more configuration<br>s of mul_mat<br>Romain Biessy  Log: <a href="./log/f4586ee5986d6f965becb37876d6f3666478a961">log</a></td>
<td>94.0%<br>NA</td>
<td>19.63</td>
<td>tg=26.96<br>pp=442.52</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/cd6983d56d2cce94ecb86bb114ae8379a609073c">cd6983d56d2cce94ecb86bb114ae8379a609073c</a><br>2025-08-08 21:37:22<br>ggml : fix field name when new ggml_back<br>end<br>AN Long  Log: <a href="./log/cd6983d56d2cce94ecb86bb114ae8379a609073c">log</a></td>
<td>91.0%<br>10822/10829</td>
<td>19.66</td>
<td>tg=27.0<br>pp=441.96</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>6/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/fd1234cb468935ea087d6929b2487926c3afff4b">fd1234cb468935ea087d6929b2487926c3afff4b</a><br>2025-08-05 22:10:36<br>llama : add gpt-oss<br>Georgi Gerganov  Log: <a href="./log/fd1234cb468935ea087d6929b2487926c3afff4b">log</a></td>
<td>91.0%<br>10822/10829</td>
<td>19.65</td>
<td>tg=26.95<br>pp=438.4</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>6/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3306ceabf02e3df66666e5851800e843c7ca207e">3306ceabf02e3df66666e5851800e843c7ca207e</a><br>2025-08-05 18:39:55<br>sycl: fix mul_mat selection<br>Romain Biessy  Log: <a href="./log/3306ceabf02e3df66666e5851800e843c7ca207e">log</a></td>
<td>91.0%<br>8318/8325</td>
<td>19.65</td>
<td>tg=26.96<br>pp=437.69</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>6/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/15e92fd33791e60a4ddb5970b47242a855c27117">15e92fd33791e60a4ddb5970b47242a855c27117</a><br>2025-08-02 17:13:05<br>cuda, sycl : fix batched gemm when ne02 <br>== 1 &amp;&amp; ne03 &gt; 1<br>Georgi Gerganov  Log: <a href="./log/15e92fd33791e60a4ddb5970b47242a855c27117">log</a></td>
<td>91.0%<br>8286/8325</td>
<td>19.93</td>
<td>tg=27.55<br>pp=446.3</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>6/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/cd1fce6d4f9c191f1c7429cc96f61281c3b63ffc">cd1fce6d4f9c191f1c7429cc96f61281c3b63ffc</a><br>2025-07-28 20:32:15<br>SYCL: Add set_rows support for quantized<br> types<br>Akarshan Biswas  Log: <a href="./log/cd1fce6d4f9c191f1c7429cc96f61281c3b63ffc">log</a></td>
<td>94.0%<br>NA</td>
<td>19.95</td>
<td>tg=27.48<br>pp=444.63</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>6/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/afc0e8969896ada62238da07b98731e5a4b12ba4">afc0e8969896ada62238da07b98731e5a4b12ba4</a><br>2025-07-28 11:05:53<br>sycl: refactor quantization to q8_1<br>Alberto Cabrera Pérez  Log: <a href="./log/afc0e8969896ada62238da07b98731e5a4b12ba4">log</a></td>
<td>94.0%<br>NA</td>
<td>19.92</td>
<td>tg=27.5<br>pp=441.68</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/bbfc84927481d1e59d8af6939b93b76850f0ab53">bbfc84927481d1e59d8af6939b93b76850f0ab53</a><br>2025-07-27 17:52:58<br>SYCL: add ops doc<br>Akarshan Biswas  Log: <a href="./log/bbfc84927481d1e59d8af6939b93b76850f0ab53">log</a></td>
<td>94.0%<br>NA</td>
<td>20.54</td>
<td>tg=28.96<br>pp=629.17</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/4ec6291a2407404de52239c1f9ca66c07e7fb28b">4ec6291a2407404de52239c1f9ca66c07e7fb28b</a><br>2025-07-24 13:50:41<br>sycl: fix undefined variable in work gro<br>up size check<br>Donghyeon Jeong  Log: <a href="./log/4ec6291a2407404de52239c1f9ca66c07e7fb28b">log</a></td>
<td>94.0%<br>NA</td>
<td>19.51</td>
<td>tg=33.25<br>pp=584.77</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/cb4a63aad6650c2b536a7578403935388cb2920e">cb4a63aad6650c2b536a7578403935388cb2920e</a><br>2025-07-24 11:09:57<br>sycl: fixed semantics of block offset ca<br>lculation<br>Alberto Cabrera Pérez  Log: <a href="./log/cb4a63aad6650c2b536a7578403935388cb2920e">log</a></td>
<td>94.0%<br>NA</td>
<td>20.62</td>
<td>tg=27.37<br>pp=445.56</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/cd465d823c378853f1f6570eebfb77f69c7e1d39">cd465d823c378853f1f6570eebfb77f69c7e1d39</a><br>2025-07-21 18:39:29<br>sycl: Fix im2col<br>Romain Biessy  Log: <a href="./log/cd465d823c378853f1f6570eebfb77f69c7e1d39">log</a></td>
<td>94.0%<br>NA</td>
<td>19.73</td>
<td>tg=27.26<br>pp=445.02</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/349ea79fcebc75b0c55bf61594a47736966d4f95">349ea79fcebc75b0c55bf61594a47736966d4f95</a><br>2025-07-18 10:23:14<br>use max work group size for device to re<br>place the magic number<br>Neo Zhang Jianyu  Log: <a href="./log/349ea79fcebc75b0c55bf61594a47736966d4f95">log</a></td>
<td>94.0%<br>NA</td>
<td>22.66</td>
<td>tg=27.1<br>pp=581.01</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/bdca38376f7e8dd928defe01ce6a16218a64b040">bdca38376f7e8dd928defe01ce6a16218a64b040</a><br>2025-07-14 18:12:42<br>sycl: Hotfix for non dnnl codepath<br>Anton Mitkov  Log: <a href="./log/bdca38376f7e8dd928defe01ce6a16218a64b040">log</a></td>
<td>94.0%<br>NA</td>
<td>19.7</td>
<td>tg=27.27<br>pp=440.92</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0f4c6ec0f1a9607ba67071f8a02c69b0afc2f91e">0f4c6ec0f1a9607ba67071f8a02c69b0afc2f91e</a><br>2025-07-14 15:07:55<br>SYCL: use 1D kernel for set_rows<br>Akarshan Biswas  Log: <a href="./log/0f4c6ec0f1a9607ba67071f8a02c69b0afc2f91e">log</a></td>
<td>94.0%<br>NA</td>
<td>20.34</td>
<td>tg=28.25<br>pp=564.01</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/65a3ebb0aa56d6c501466e0f950ad15105fd32d8">65a3ebb0aa56d6c501466e0f950ad15105fd32d8</a><br>2025-07-14 10:37:35<br>sycl: Batched mulmat rework for oneDNN d<br>ispatch<br>Anton Mitkov  Log: <a href="./log/65a3ebb0aa56d6c501466e0f950ad15105fd32d8">log</a></td>
<td>94.0%<br>NA</td>
<td>19.72</td>
<td>tg=27.25<br>pp=440.42</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>8/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/05fec5bd298d3c0243cbb9336e59b8b6aff75a81">05fec5bd298d3c0243cbb9336e59b8b6aff75a81</a><br>2025-07-13 10:36:33<br>ggml : add build-time message to remind <br>about ggml_set_rows<br>Georgi Gerganov  Log: <a href="./log/05fec5bd298d3c0243cbb9336e59b8b6aff75a81">log</a></td>
<td>94.0%<br>NA</td>
<td>19.46</td>
<td>tg=33.27<br>pp=587.37</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/704bb7a71c01dc07c1478b85f6322bf5dfde1eaf">704bb7a71c01dc07c1478b85f6322bf5dfde1eaf</a><br>2025-07-10 13:59:38<br>SYCL: Initial set_rows kernel implementa<br>tion<br>Akarshan Biswas  Log: <a href="./log/704bb7a71c01dc07c1478b85f6322bf5dfde1eaf">log</a></td>
<td>94.0%<br>NA</td>
<td>19.7</td>
<td>tg=27.24<br>pp=445.12</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/98bab638fb28cf95a5a66dd2d51b40d6c8f6d69a">98bab638fb28cf95a5a66dd2d51b40d6c8f6d69a</a><br>2025-07-09 18:16:12<br>ggml : add ggml_scale_bias<br>Xuan-Son Nguyen  Log: <a href="./log/98bab638fb28cf95a5a66dd2d51b40d6c8f6d69a">log</a></td>
<td>94.0%<br>NA</td>
<td>20.62</td>
<td>tg=28.72<br>pp=598.8</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/4d0dcd4a06080e796e6742a88f2ffa7fc41b28b8">4d0dcd4a06080e796e6742a88f2ffa7fc41b28b8</a><br>2025-07-08 10:15:21<br>cuda : fix rope with partial rotation an<br>d non-cont src<br>Georgi Gerganov  Log: <a href="./log/4d0dcd4a06080e796e6742a88f2ffa7fc41b28b8">log</a></td>
<td>94.0%<br>NA</td>
<td>19.68</td>
<td>tg=27.28<br>pp=444.8</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/28657a8229b5adc6028cf1c4ed62191792d2fdb0">28657a8229b5adc6028cf1c4ed62191792d2fdb0</a><br>2025-07-03 23:07:22<br>ggml : implement GEGLU_ERF and GEGLU_QUI<br>CK ops<br>Sigbjørn Skjæret  Log: <a href="./log/28657a8229b5adc6028cf1c4ed62191792d2fdb0">log</a></td>
<td>94.0%<br>NA</td>
<td>19.7</td>
<td>tg=27.26<br>pp=440.68</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7b63a71a6b0f54effe9b94073d4d0519dcf53676">7b63a71a6b0f54effe9b94073d4d0519dcf53676</a><br>2025-07-03 11:00:03<br>Fix conditional enabling following arch <br>checks for ggml-sycl<br>Nicolò Scipione  Log: <a href="./log/7b63a71a6b0f54effe9b94073d4d0519dcf53676">log</a></td>
<td>94.0%<br>NA</td>
<td>23.96</td>
<td>tg=26.79<br>pp=626.25</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a70c8a0c4b4c1606cd9a0ba889ce61aa88610095">a70c8a0c4b4c1606cd9a0ba889ce61aa88610095</a><br>2025-07-03 10:53:35<br>kv-cache : use ggml_set_rows<br>Georgi Gerganov  Log: <a href="./log/a70c8a0c4b4c1606cd9a0ba889ce61aa88610095">log</a></td>
<td>91.0%<br>6435/6436</td>
<td>24.95</td>
<td>tg=24.77<br>pp=443.23</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a7417f55945eb7c7a5ea6807e66564b8066a4e50">a7417f55945eb7c7a5ea6807e66564b8066a4e50</a><br>2025-06-30 14:52:02<br>ggml-cpu: sycl: Re-enable exp f16<br>Romain Biessy  Log: <a href="./log/a7417f55945eb7c7a5ea6807e66564b8066a4e50">log</a></td>
<td>94.0%<br>NA</td>
<td>24.21</td>
<td>tg=37.42<br>pp=560.28</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e9b6350e61d592634263a14b3d77ecbf6c1fb096">e9b6350e61d592634263a14b3d77ecbf6c1fb096</a><br>2025-06-30 10:17:18<br>scripts : make the shell scripts cross-p<br>latform<br>Vedran Miletić  Log: <a href="./log/e9b6350e61d592634263a14b3d77ecbf6c1fb096">log</a></td>
<td>91.0%<br>6238/6239</td>
<td>25.49</td>
<td>tg=24.97<br>pp=456.49</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f47c1d7106e49062279bcc57fc1077c0db61e278">f47c1d7106e49062279bcc57fc1077c0db61e278</a><br>2025-06-29 21:07:58<br>SYCL: disable faulty fp16 exp kernel<br>Akarshan Biswas  Log: <a href="./log/f47c1d7106e49062279bcc57fc1077c0db61e278">log</a></td>
<td>91.0%<br>6238/6239</td>
<td>24.84</td>
<td>tg=28.79<br>pp=564.84</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a0535ffa0d35fccfec3e1a0a3bfc9dbb6054d7c0">a0535ffa0d35fccfec3e1a0a3bfc9dbb6054d7c0</a><br>2025-06-29 11:04:10<br>ggml : implement REGLU/GEGLU/SWIGLU ops<br>Sigbjørn Skjæret  Log: <a href="./log/a0535ffa0d35fccfec3e1a0a3bfc9dbb6054d7c0">log</a></td>
<td>91.0%<br>6237/6239</td>
<td>24.03</td>
<td>tg=33.4<br>pp=566.94</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ec68e84c32325a3417fbcd2e60d4bda6adb4e4bc">ec68e84c32325a3417fbcd2e60d4bda6adb4e4bc</a><br>2025-06-27 21:50:57<br>ggml : support bcast ggml_soft_max_ext, <br>ggml_flash_attn_ext<br>Georgi Gerganov  Log: <a href="./log/ec68e84c32325a3417fbcd2e60d4bda6adb4e4bc">log</a></td>
<td>94.0%<br>NA</td>
<td>25.02</td>
<td>tg=47.88<br>pp=566.92</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2bf9d539dd158345e3a3b096e16474af535265b4">2bf9d539dd158345e3a3b096e16474af535265b4</a><br>2025-06-25 17:09:55<br>sycl: GGML_SYCL_DISABLE_OPT on by defaul<br>t for all Intel Devices<br>Anton Mitkov  Log: <a href="./log/2bf9d539dd158345e3a3b096e16474af535265b4">log</a></td>
<td>94.0%<br>NA</td>
<td>50.2</td>
<td>tg=49.51<br>pp=924.61</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8308f98c7fb778e54bf75538f5234d8bd20915e9">8308f98c7fb778e54bf75538f5234d8bd20915e9</a><br>2025-06-20 15:07:21<br>sycl: add usage of enqueue_functions ext<br>ension<br>Nicolò Scipione  Log: <a href="./log/8308f98c7fb778e54bf75538f5234d8bd20915e9">log</a></td>
<td>94.0%<br>NA</td>
<td>50.18</td>
<td>tg=49.75<br>pp=924.33</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/600e3e9b50c1f0c9fc4a70356241fd87f00e8e14">600e3e9b50c1f0c9fc4a70356241fd87f00e8e14</a><br>2025-06-19 11:40:21<br>sycl: Cleanup codepaths in Get Rows in s<br>ycl backend<br>Anton Mitkov  Log: <a href="./log/600e3e9b50c1f0c9fc4a70356241fd87f00e8e14">log</a></td>
<td>91.0%<br>5634/5635</td>
<td>42.96</td>
<td>tg=42.87<br>pp=913.76</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/40643edb86eb10b471b0f57d4f3f7eb0e06a0df7">40643edb86eb10b471b0f57d4f3f7eb0e06a0df7</a><br>2025-06-13 17:32:56<br>sycl: fix docker image<br>Svetlozar Georgiev  Log: <a href="./log/40643edb86eb10b471b0f57d4f3f7eb0e06a0df7">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0889eba570126f8a2f5a0e88fde776bbc91cca66">0889eba570126f8a2f5a0e88fde776bbc91cca66</a><br>2025-06-13 08:51:39<br>sycl: Adding additional cpy dbg print ou<br>tput<br>Anton Mitkov  Log: <a href="./log/0889eba570126f8a2f5a0e88fde776bbc91cca66">log</a></td>
<td>97.0%<br>NA</td>
<td>21.04</td>
<td>tg=20.98<br>pp=436.49</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c61285e7396c8e526fe7794c19e8d4f1c99bfc51">c61285e7396c8e526fe7794c19e8d4f1c99bfc51</a><br>2025-06-13 08:45:37<br>SYCL: Bump oneMath commit<br>Ewan Crawford  Log: <a href="./log/c61285e7396c8e526fe7794c19e8d4f1c99bfc51">log</a></td>
<td>97.0%<br>NA</td>
<td>21.08</td>
<td>tg=21.03<br>pp=430.73</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ed52f3668e633423054a4eab61bb7efee47025ab">ed52f3668e633423054a4eab61bb7efee47025ab</a><br>2025-06-12 14:15:11<br>sycl: Remove not needed copy f16-&gt;f32 fo<br>r dnnl mul mat<br>Anton Mitkov  Log: <a href="./log/ed52f3668e633423054a4eab61bb7efee47025ab">log</a></td>
<td>97.0%<br>NA</td>
<td>21.09</td>
<td>tg=20.92<br>pp=432.32</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f470bc36bed4d836b9de5a483fa0dfaee176d6f5">f470bc36bed4d836b9de5a483fa0dfaee176d6f5</a><br>2025-06-09 22:47:13<br>ggml-cpu : split arch-specific implement<br>ations<br>xctan  Log: <a href="./log/f470bc36bed4d836b9de5a483fa0dfaee176d6f5">log</a></td>
<td>100.0%<br>NA</td>
<td>29.2</td>
<td>tg=20.85<br>pp=554.35</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b460d16ae858c6624fd37aec316622a4060ca325">b460d16ae858c6624fd37aec316622a4060ca325</a><br>2025-06-09 11:47:07<br>sycl: Add reorder to Q6_K mmvq implement<br>ation<br>Nicolò Scipione  Log: <a href="./log/b460d16ae858c6624fd37aec316622a4060ca325">log</a></td>
<td>100.0%<br>NA</td>
<td>41.88</td>
<td>tg=20.74<br>pp=553.83</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/228f34c9ceefa3ea4f4d6933edd858121e8106cb">228f34c9ceefa3ea4f4d6933edd858121e8106cb</a><br>2025-06-07 18:58:20<br>SYCL: Implement few same quantized type <br>copy kernels<br>Akarshan Biswas  Log: <a href="./log/228f34c9ceefa3ea4f4d6933edd858121e8106cb">log</a></td>
<td>100.0%<br>NA</td>
<td>42.94</td>
<td>tg=42.89<br>pp=914.01</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/663445b0deb21fb602176da030d4154197a4fca6">663445b0deb21fb602176da030d4154197a4fca6</a><br>2025-06-02 10:12:20<br>sycl: quantize and reorder the input to <br>q8_1 when reorder is enabled<br>Atharva Dubey  Log: <a href="./log/663445b0deb21fb602176da030d4154197a4fca6">log</a></td>
<td>100.0%<br>NA</td>
<td>42.85</td>
<td>tg=42.79<br>pp=914.83</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d337252acf14a91a685c355fa4f3f599a8068207">d337252acf14a91a685c355fa4f3f599a8068207</a><br>2025-05-31 12:39:19<br>cmake : Fix broken CMake error messages<br>Kai Pastor  Log: <a href="./log/d337252acf14a91a685c355fa4f3f599a8068207">log</a></td>
<td>100.0%<br>NA</td>
<td>42.83</td>
<td>tg=42.78<br>pp=914.5</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b49a8ff96b769b8a4c36d89fb783ec0135be582b">b49a8ff96b769b8a4c36d89fb783ec0135be582b</a><br>2025-05-30 19:40:57<br>SYCL: Add mrope kernel<br>Akarshan Biswas  Log: <a href="./log/b49a8ff96b769b8a4c36d89fb783ec0135be582b">log</a></td>
<td>100.0%<br>NA</td>
<td>42.21</td>
<td>tg=42.08<br>pp=912.25</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f3101a8cc665f73217c752a10a7042889275cfbc">f3101a8cc665f73217c752a10a7042889275cfbc</a><br>2025-05-27 20:52:59<br>SYCL: add gelu_erf kernel<br>Akarshan Biswas  Log: <a href="./log/f3101a8cc665f73217c752a10a7042889275cfbc">log</a></td>
<td>100.0%<br>NA</td>
<td>42.8</td>
<td>tg=42.62<br>pp=914.62</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6f180b915c9ed9ec0c240b5dcd64644988fb5e82">6f180b915c9ed9ec0c240b5dcd64644988fb5e82</a><br>2025-05-26 21:10:36<br>SYCL: Add non contiguous support in RMS_<br>NORM and NORM kernels<br>Akarshan Biswas  Log: <a href="./log/6f180b915c9ed9ec0c240b5dcd64644988fb5e82">log</a></td>
<td>100.0%<br>NA</td>
<td>42.86</td>
<td>tg=42.76<br>pp=914.42</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9012eb9b454a82eaa4cd77ae904c0ea391e4db42">9012eb9b454a82eaa4cd77ae904c0ea391e4db42</a><br>2025-05-26 10:28:53<br>sycl: Add more debug prints<br>Romain Biessy  Log: <a href="./log/9012eb9b454a82eaa4cd77ae904c0ea391e4db42">log</a></td>
<td>100.0%<br>NA</td>
<td>42.85</td>
<td>tg=42.78<br>pp=914.52</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/515fdbf7ed839dfe6a24aeb6225936609a7f6d6d">515fdbf7ed839dfe6a24aeb6225936609a7f6d6d</a><br>2025-05-25 12:38:37<br>SYCL: revert "sycl: simplify bin_bcast_k<br>ernel<br>Akarshan Biswas  Log: <a href="./log/515fdbf7ed839dfe6a24aeb6225936609a7f6d6d">log</a></td>
<td>100.0%<br>NA</td>
<td>42.84</td>
<td>tg=42.8<br>pp=913.67</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d394a9aedc50a13b7f6373416f7c1ccabfe79c32">d394a9aedc50a13b7f6373416f7c1ccabfe79c32</a><br>2025-05-22 13:54:43<br>sycl : Remove waits from function calls<br>Nicolò Scipione  Log: <a href="./log/d394a9aedc50a13b7f6373416f7c1ccabfe79c32">log</a></td>
<td>97.0%<br>5503/5527</td>
<td>43.48</td>
<td>tg=43.42<br>pp=910.79</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6b56a64690a318fcabcd7739ac7e314d44785ea8">6b56a64690a318fcabcd7739ac7e314d44785ea8</a><br>2025-05-22 09:24:09<br>SYCL: Avoid using with SYCL-Graph for un<br>supported nodes<br>Ewan Crawford  Log: <a href="./log/6b56a64690a318fcabcd7739ac7e314d44785ea8">log</a></td>
<td>97.0%<br>5502/5527</td>
<td>43.45</td>
<td>tg=43.32<br>pp=910.67</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/4245e622e0cc3af1ca3056104e465dc4d303bd7d">4245e622e0cc3af1ca3056104e465dc4d303bd7d</a><br>2025-05-20 10:34:15<br>sycl: disable reorder for sycl mulmat<br>Svetlozar Georgiev  Log: <a href="./log/4245e622e0cc3af1ca3056104e465dc4d303bd7d">log</a></td>
<td>97.0%<br>5494/5519</td>
<td>43.47</td>
<td>tg=43.3<br>pp=911.0</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f7c9429c85748cde9599499601ba48d0057722e6">f7c9429c85748cde9599499601ba48d0057722e6</a><br>2025-05-20 02:54:43<br>sycl : Overcoming workaround for mmap<br>Nicolò Scipione  Log: <a href="./log/f7c9429c85748cde9599499601ba48d0057722e6">log</a></td>
<td>97.0%<br>5494/5519</td>
<td>43.44</td>
<td>tg=43.38<br>pp=912.44</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/725f23f1f3f0d3adf49f95d8dfa6e7c74adff149">725f23f1f3f0d3adf49f95d8dfa6e7c74adff149</a><br>2025-05-19 14:38:20<br>sycl : backend documentation review<br>Alberto Cabrera Pérez  Log: <a href="./log/725f23f1f3f0d3adf49f95d8dfa6e7c74adff149">log</a></td>
<td>97.0%<br>5495/5519</td>
<td>43.41</td>
<td>tg=43.4<br>pp=905.6</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f71f40a2847d4c9f57b86cd206e0a27b2bfb6d1c">f71f40a2847d4c9f57b86cd206e0a27b2bfb6d1c</a><br>2025-05-19 11:46:09<br>ci : upgraded oneAPI version in SYCL wor<br>kflows and dockerfile<br>Alberto Cabrera Pérez  Log: <a href="./log/f71f40a2847d4c9f57b86cd206e0a27b2bfb6d1c">log</a></td>
<td>97.0%<br>5496/5519</td>
<td>43.46</td>
<td>tg=43.39<br>pp=910.65</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0a338ed013c23aecdce6449af736a35a465fa60f">0a338ed013c23aecdce6449af736a35a465fa60f</a><br>2025-05-16 12:15:29<br>sycl : fixed compilation warnings<br>Łukasz Ślusarczyk  Log: <a href="./log/0a338ed013c23aecdce6449af736a35a465fa60f">log</a></td>
<td>97.0%<br>5493/5519</td>
<td>43.48</td>
<td>tg=43.37<br>pp=908.07</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9c404ed54c3c8d8d2aa3153313766c8286739387">9c404ed54c3c8d8d2aa3153313766c8286739387</a><br>2025-05-15 16:53:41<br>sycl: use oneDNN for matrices multiplica<br>tion<br>Łukasz Ślusarczyk  Log: <a href="./log/9c404ed54c3c8d8d2aa3153313766c8286739387">log</a></td>
<td>100.0%<br>NA</td>
<td>42.85</td>
<td>tg=42.78<br>pp=911.43</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/02cdd2d8b092b5a4bb18e013c6887ce49ba20ac5">02cdd2d8b092b5a4bb18e013c6887ce49ba20ac5</a><br>2025-05-15 16:39:52<br>sycl: simplify bin_bcast_kernel<br>Atharva Dubey  Log: <a href="./log/02cdd2d8b092b5a4bb18e013c6887ce49ba20ac5">log</a></td>
<td>97.0%<br>5494/5519</td>
<td>43.42</td>
<td>tg=43.42<br>pp=907.82</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/64bb51cf90d3eede8c150a23d59a0c718b78065b">64bb51cf90d3eede8c150a23d59a0c718b78065b</a><br>2025-05-15 16:35:44<br>sycl: reordered Q4_K MMVQ<br>Svetlozar Georgiev  Log: <a href="./log/64bb51cf90d3eede8c150a23d59a0c718b78065b">log</a></td>
<td>100.0%<br>NA</td>
<td>42.84</td>
<td>tg=42.79<br>pp=911.47</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/14492144c286bbf38bb1903128403d9e2ebad54c">14492144c286bbf38bb1903128403d9e2ebad54c</a><br>2025-05-12 06:15:32<br>enable dpcpp nightly builds with librari<br>es<br>Atharva Dubey  Log: <a href="./log/14492144c286bbf38bb1903128403d9e2ebad54c">log</a></td>
<td>100.0%<br>NA</td>
<td>42.82</td>
<td>tg=42.79<br>pp=911.77</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/17512a94d636c4b6c1332370acb3e5af3ca70918">17512a94d636c4b6c1332370acb3e5af3ca70918</a><br>2025-05-09 16:34:08<br>sycl : implementation of reordered Q4_0 <br>MMVQ for Intel GPUs<br>Alberto Cabrera Pérez  Log: <a href="./log/17512a94d636c4b6c1332370acb3e5af3ca70918">log</a></td>
<td>100.0%<br>NA</td>
<td>42.83</td>
<td>tg=42.8<br>pp=911.6</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8733e0cf6eefc7c7752297cc22d0836706f4222c">8733e0cf6eefc7c7752297cc22d0836706f4222c</a><br>2025-05-08 10:08:01<br>sycl: addressing non-contiguous src1 mul<br>_mats<br>Alberto Cabrera Pérez  Log: <a href="./log/8733e0cf6eefc7c7752297cc22d0836706f4222c">log</a></td>
<td>100.0%<br>NA</td>
<td>42.85</td>
<td>tg=42.78<br>pp=912.07</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1e333d5bba18e99bc328bb87ac1ee6a4e6260e0e">1e333d5bba18e99bc328bb87ac1ee6a4e6260e0e</a><br>2025-05-06 20:27:06<br>SYCL: Disable reorder optimize by defaul<br>t and stop setting tensor extras when op<br>timize is disabled<br>Akarshan Biswas  Log: <a href="./log/1e333d5bba18e99bc328bb87ac1ee6a4e6260e0e">log</a></td>
<td>100.0%<br>NA</td>
<td>40.17</td>
<td>tg=39.61<br>pp=391.63</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/66645a5285d8c4c5f9a3b3f360d042baac2d820a">66645a5285d8c4c5f9a3b3f360d042baac2d820a</a><br>2025-05-05 13:39:10<br>SYCL: Disable mul_mat kernels for noncon<br>tiguous tensor b<br>Akarshan Biswas  Log: <a href="./log/66645a5285d8c4c5f9a3b3f360d042baac2d820a">log</a></td>
<td>100.0%<br>NA</td>
<td>41.86</td>
<td>tg=44.33<br>pp=370.04</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/13b0a04597a4581cad4d9027a848f450c623801d">13b0a04597a4581cad4d9027a848f450c623801d</a><br>2025-05-05 13:09:35<br>whisper: remove MSVC warnings pragmas<br>Daniel Bevenius  Log: <a href="./log/13b0a04597a4581cad4d9027a848f450c623801d">log</a></td>
<td>100.0%<br>NA</td>
<td>40.13</td>
<td>tg=39.63<br>pp=396.15</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a4c340f974f9b7ac0c1aae897aabaa54549a97e5">a4c340f974f9b7ac0c1aae897aabaa54549a97e5</a><br>2025-04-28 15:03:25<br>SYCL: Add all missing unary kernels<br>Akarshan Biswas  Log: <a href="./log/a4c340f974f9b7ac0c1aae897aabaa54549a97e5">log</a></td>
<td>100.0%<br>NA</td>
<td>41.94</td>
<td>tg=44.15<br>pp=789.93</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/514c45608f93f66106a712dee1abe062099ce790">514c45608f93f66106a712dee1abe062099ce790</a><br>2025-04-25 17:37:51<br>change the reorder tensor from init to e<br>xecute OP<br>Neo Zhang Jianyu  Log: <a href="./log/514c45608f93f66106a712dee1abe062099ce790">log</a></td>
<td>100.0%<br>NA</td>
<td>42.11</td>
<td>tg=44.2<br>pp=790.07</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5368ddda7a262d195b54687a31009dcc1f8b1602">5368ddda7a262d195b54687a31009dcc1f8b1602</a><br>2025-04-21 19:13:30<br>SYCL: Add non-contiguous support in ROPE<br><br>Akarshan Biswas  Log: <a href="./log/5368ddda7a262d195b54687a31009dcc1f8b1602">log</a></td>
<td>100.0%<br>NA</td>
<td>42.77</td>
<td>tg=42.84<br>pp=912.85</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8d6600576318dfc6b091fca744b0fd36a5e5255f">8d6600576318dfc6b091fca744b0fd36a5e5255f</a><br>2025-04-18 19:27:56<br>SYCL: Refactor and enable FP16 in binary<br> broadcast OPs<br>Akarshan Biswas  Log: <a href="./log/8d6600576318dfc6b091fca744b0fd36a5e5255f">log</a></td>
<td>100.0%<br>NA</td>
<td>42.74</td>
<td>tg=42.62<br>pp=915.76</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/510676475f885ec064ff147af9f20ee7a9b12a50">510676475f885ec064ff147af9f20ee7a9b12a50</a><br>2025-04-15 14:07:42<br>SYCL: Add ROPE vision kernel<br>Akarshan Biswas  Log: <a href="./log/510676475f885ec064ff147af9f20ee7a9b12a50">log</a></td>
<td>100.0%<br>NA</td>
<td>42.56</td>
<td>tg=42.48<br>pp=917.24</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/81c7e64fc239288e91a58adad9145110e0353822">81c7e64fc239288e91a58adad9145110e0353822</a><br>2025-04-14 18:19:07<br>dsiable curl lib check, this action is m<br>issed by commit bd3f59f81289b920bcc597a2<br>08c14f55e39ed37e<br>Neo Zhang Jianyu  Log: <a href="./log/81c7e64fc239288e91a58adad9145110e0353822">log</a></td>
<td>100.0%<br>NA</td>
<td>42.22</td>
<td>tg=42.2<br>pp=914.61</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/75afa0ae31f0a51aaadcc5ff146eb7a32a7f9088">75afa0ae31f0a51aaadcc5ff146eb7a32a7f9088</a><br>2025-04-14 17:53:53<br>SYCL: Fix im2col<br>Akarshan Biswas  Log: <a href="./log/75afa0ae31f0a51aaadcc5ff146eb7a32a7f9088">log</a></td>
<td>100.0%<br>NA</td>
<td>42.82</td>
<td>tg=42.57<br>pp=916.81</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/578754b3157d662c2fdd51eaa62b6c1f43d3172c">578754b3157d662c2fdd51eaa62b6c1f43d3172c</a><br>2025-04-11 15:32:14<br>sycl: Support sycl_ext_oneapi_limited_gr<br>aph<br>Ewan Crawford  Log: <a href="./log/578754b3157d662c2fdd51eaa62b6c1f43d3172c">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/fccf9cae83e6c6cd31a0ecb403d237638e427d0a">fccf9cae83e6c6cd31a0ecb403d237638e427d0a</a><br>2025-04-11 13:33:50<br>SYCL: Add fp16 type support to unary op <br>kernels<br>Akarshan Biswas  Log: <a href="./log/fccf9cae83e6c6cd31a0ecb403d237638e427d0a">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/fe92821ea9ae53f3088cf2699a9e102448295fa0">fe92821ea9ae53f3088cf2699a9e102448295fa0</a><br>2025-04-09 12:32:13<br>ggml : add bilinear upscale support<br>Diego Devesa  Log: <a href="./log/fe92821ea9ae53f3088cf2699a9e102448295fa0">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8ed71242f464dc0a3fb3cffcfe064e55bdec72f9">8ed71242f464dc0a3fb3cffcfe064e55bdec72f9</a><br>2025-04-09 11:22:04<br>sycl: update documentation to use -no-cn<br>v<br>Romain Biessy  Log: <a href="./log/8ed71242f464dc0a3fb3cffcfe064e55bdec72f9">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/656babd6c21a3b9b3622324cfcc80a2ab78da25b">656babd6c21a3b9b3622324cfcc80a2ab78da25b</a><br>2025-04-08 15:03:21<br>Revert "sycl:remove redundant memcopy in<br> function ggml_backend_sycl_buffer_set_t<br>ensor"<br>Neo Zhang Jianyu  Log: <a href="./log/656babd6c21a3b9b3622324cfcc80a2ab78da25b">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/518a01480eb3a7c80a4951b430db9dee55428310">518a01480eb3a7c80a4951b430db9dee55428310</a><br>2025-04-07 23:22:57<br>sycl: remove redundant memcopy in functi<br>on ggml_backend_sycl_buffer_set_tensor<br>zhouwg  Log: <a href="./log/518a01480eb3a7c80a4951b430db9dee55428310">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/bd3f59f81289b920bcc597a208c14f55e39ed37e">bd3f59f81289b920bcc597a208c14f55e39ed37e</a><br>2025-04-07 13:35:19<br>cmake : enable curl by default<br>Xuan-Son Nguyen  Log: <a href="./log/bd3f59f81289b920bcc597a208c14f55e39ed37e">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/94148ba330968bbfb8d9ecc67751bdc2218486cd">94148ba330968bbfb8d9ecc67751bdc2218486cd</a><br>2025-04-04 16:00:46<br>sycl: allow ggml-sycl configuration and <br>compilation using Visual Studio project/<br>solution<br>Nicolò Scipione  Log: <a href="./log/94148ba330968bbfb8d9ecc67751bdc2218486cd">log</a></td>
<td>100.0%<br>NA</td>
<td>41.89</td>
<td>tg=42.21<br>pp=916.88</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2004644b7a5da6fe080e51861ab583480280f1d3">2004644b7a5da6fe080e51861ab583480280f1d3</a><br>2025-04-03 13:12:39<br>ci : add env variable in ggml-ci and doc<br>ument the same in SYCL.html<br>Atharva Dubey  Log: <a href="./log/2004644b7a5da6fe080e51861ab583480280f1d3">log</a></td>
<td>100.0%<br>NA</td>
<td>42.49</td>
<td>tg=42.39<br>pp=916.9</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8bbf26083d93274240a20d16cda324441c57fcc6">8bbf26083d93274240a20d16cda324441c57fcc6</a><br>2025-04-01 13:41:39<br>SYCL: switch to SYCL namespace<br>Akarshan Biswas  Log: <a href="./log/8bbf26083d93274240a20d16cda324441c57fcc6">log</a></td>
<td>100.0%<br>NA</td>
<td>41.77</td>
<td>tg=42.02<br>pp=912.77</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/82939705421f4ef27e924879fdeed6d7b5f6d769">82939705421f4ef27e924879fdeed6d7b5f6d769</a><br>2025-04-01 10:24:29<br>SYCL: Rename oneMKL to oneMath<br>Romain Biessy  Log: <a href="./log/82939705421f4ef27e924879fdeed6d7b5f6d769">log</a></td>
<td>100.0%<br>NA</td>
<td>41.97</td>
<td>tg=42.13<br>pp=917.01</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6c02a032fa21d69e881ef9a5c94ba28ebaf1d749">6c02a032fa21d69e881ef9a5c94ba28ebaf1d749</a><br>2025-03-31 14:55:24<br>SYCL: Remove misleading ggml_sycl_op_fla<br>tten function<br>Akarshan Biswas  Log: <a href="./log/6c02a032fa21d69e881ef9a5c94ba28ebaf1d749">log</a></td>
<td>100.0%<br>NA</td>
<td>42.29</td>
<td>tg=42.24<br>pp=916.62</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f17a3bb4e8b0aa24c0f86636d234aca7dc2cfa01">f17a3bb4e8b0aa24c0f86636d234aca7dc2cfa01</a><br>2025-03-27 07:16:00<br>SYCL: implement memset ggml backend buff<br>er interface<br>Akarshan Biswas  Log: <a href="./log/f17a3bb4e8b0aa24c0f86636d234aca7dc2cfa01">log</a></td>
<td>100.0%<br>NA</td>
<td>42.21</td>
<td>tg=42.11<br>pp=914.92</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e2f560175a195f63c3276972a3d1caec0bd13e05">e2f560175a195f63c3276972a3d1caec0bd13e05</a><br>2025-03-25 16:10:18<br>SYCL: disable Q4_0 reorder optimization<br>Akarshan Biswas  Log: <a href="./log/e2f560175a195f63c3276972a3d1caec0bd13e05">log</a></td>
<td>100.0%<br>NA</td>
<td>38.43</td>
<td>tg=41.55<br>pp=915.4</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c95fa362b3587d1822558f7e28414521075f254f">c95fa362b3587d1822558f7e28414521075f254f</a><br>2025-03-24 23:05:38<br>ci: [SYCL] ggml-ci Use main GPU and enab<br>le sysman<br>Akarshan Biswas  Log: <a href="./log/c95fa362b3587d1822558f7e28414521075f254f">log</a></td>
<td>100.0%<br>NA</td>
<td>54.62</td>
<td>tg=54.01<br>pp=800.56</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/48d7021c61ceda6fcf1a7294d2115b8e1a53ae95">48d7021c61ceda6fcf1a7294d2115b8e1a53ae95</a><br>2025-03-24 18:28:32<br>CI: fix SYCL build<br>Akarshan Biswas  Log: <a href="./log/48d7021c61ceda6fcf1a7294d2115b8e1a53ae95">log</a></td>
<td>100.0%<br>NA</td>
<td>54.22</td>
<td>tg=53.74<br>pp=801.31</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1aa87ee53d05505247c54612e40f6a38c680b433">1aa87ee53d05505247c54612e40f6a38c680b433</a><br>2025-03-21 14:58:47<br>[SYCL] Fix build on Windows when ccache <br>enabled<br>蕭澧邦  Log: <a href="./log/1aa87ee53d05505247c54612e40f6a38c680b433">log</a></td>
<td>100.0%<br>NA</td>
<td>54.73</td>
<td>tg=54.31<br>pp=801.62</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9ffcc9e374080f73b16b7a351e6d76e7a8a19ce3">9ffcc9e374080f73b16b7a351e6d76e7a8a19ce3</a><br>2025-03-21 02:15:56<br>sycl: cleanup oneDNN related code<br>Svetlozar Georgiev  Log: <a href="./log/9ffcc9e374080f73b16b7a351e6d76e7a8a19ce3">log</a></td>
<td>100.0%<br>NA</td>
<td>54.8</td>
<td>tg=54.32<br>pp=799.23</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/35cae5ba05a5292dc3108636a71ec59fa2f80ab7">35cae5ba05a5292dc3108636a71ec59fa2f80ab7</a><br>2025-03-18 11:16:31<br>SYCL: using graphs is configurable by en<br>vironment variable and compile option<br>Łukasz Ślusarczyk  Log: <a href="./log/35cae5ba05a5292dc3108636a71ec59fa2f80ab7">log</a></td>
<td>100.0%<br>NA</td>
<td>54.67</td>
<td>tg=54.26<br>pp=801.47</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7dfad387e3f6ac98d383ded2d175eb59736a3993">7dfad387e3f6ac98d383ded2d175eb59736a3993</a><br>2025-03-18 07:27:50<br>llama: Add support for RWKV v7 architect<br>ure<br>Molly Sophia  Log: <a href="./log/7dfad387e3f6ac98d383ded2d175eb59736a3993">log</a></td>
<td>100.0%<br>NA</td>
<td>44.71</td>
<td>tg=54.58<br>pp=799.19</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a53f7f7b8859f3e634415ab03e1e295b9861d7e6">a53f7f7b8859f3e634415ab03e1e295b9861d7e6</a><br>2025-03-18 01:51:25<br>fixed compilation warnings in ggml-sycl<br>Łukasz Ślusarczyk  Log: <a href="./log/a53f7f7b8859f3e634415ab03e1e295b9861d7e6">log</a></td>
<td>100.0%<br>NA</td>
<td>54.73</td>
<td>tg=37.42<br>pp=785.04</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b3c9a65673a63a6c9a75da24ee00d13499494e0c">b3c9a65673a63a6c9a75da24ee00d13499494e0c</a><br>2025-03-17 07:15:12<br>SYCL: set extras only on GGML_TYPE_Q4_0<br>Akarshan Biswas  Log: <a href="./log/b3c9a65673a63a6c9a75da24ee00d13499494e0c">log</a></td>
<td>100.0%<br>NA</td>
<td>54.7</td>
<td>tg=54.39<br>pp=801.46</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3d35d87b4113648e224b837bb88e6b2c4c7f29e5">3d35d87b4113648e224b837bb88e6b2c4c7f29e5</a><br>2025-03-15 22:49:03<br>SYCL: Delete redundant plus sign and spa<br>ce<br>aubreyli  Log: <a href="./log/3d35d87b4113648e224b837bb88e6b2c4c7f29e5">log</a></td>
<td>100.0%<br>NA</td>
<td>38.08</td>
<td>tg=51.21<br>pp=799.39</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b19bd064c09822cb81efe4a38abafab3e979c9ce">b19bd064c09822cb81efe4a38abafab3e979c9ce</a><br>2025-03-15 15:19:30<br>SYCL : support non-contiguous tensors in<br> binary ops<br>fairydreaming  Log: <a href="./log/b19bd064c09822cb81efe4a38abafab3e979c9ce">log</a></td>
<td>100.0%<br>NA</td>
<td>54.02</td>
<td>tg=53.85<br>pp=799.82</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/363f8c5d67dcf80e00c39580dfa86dc2774d74c2">363f8c5d67dcf80e00c39580dfa86dc2774d74c2</a><br>2025-03-12 09:57:32<br>sycl : variable sg_size support for mmvq<br> kernels<br>Alberto Cabrera Pérez  Log: <a href="./log/363f8c5d67dcf80e00c39580dfa86dc2774d74c2">log</a></td>
<td>100.0%<br>NA</td>
<td>53.29</td>
<td>tg=52.7<br>pp=801.6</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5e43f104cca1a14874e980326a506b44fde022b8">5e43f104cca1a14874e980326a506b44fde022b8</a><br>2025-03-05 21:28:23<br>SYCL: Disable f16 Unary OPs as not suppo<br>rted by the kernels<br>Akarshan Biswas  Log: <a href="./log/5e43f104cca1a14874e980326a506b44fde022b8">log</a></td>
<td>100.0%<br>NA</td>
<td>54.17</td>
<td>tg=53.78<br>pp=800.51</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ece9745bb8079b9f4af45df29b67ad0c6e50584d">ece9745bb8079b9f4af45df29b67ad0c6e50584d</a><br>2025-03-03 15:37:22<br>SYCL: Move CPY kernels to a separate fil<br>e and add few missing kernels<br>Akarshan Biswas  Log: <a href="./log/ece9745bb8079b9f4af45df29b67ad0c6e50584d">log</a></td>
<td>100.0%<br>NA</td>
<td>54.22</td>
<td>tg=53.75<br>pp=802.37</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/70680c48e5f77d2d3138712a6582bd8c1e548922">70680c48e5f77d2d3138712a6582bd8c1e548922</a><br>2025-02-28 05:41:47<br>ggml : upgrade init_tensor API to return<br> a ggml_status<br>William Tambellini  Log: <a href="./log/70680c48e5f77d2d3138712a6582bd8c1e548922">log</a></td>
<td>100.0%<br>NA</td>
<td>54.22</td>
<td>tg=53.99<br>pp=801.48</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/08d5986290cc42d2c52739e046642b8252f97e4b">08d5986290cc42d2c52739e046642b8252f97e4b</a><br>2025-02-24 22:33:23<br>[SYCL] Optimize mul_mat for Q4_0 on Inte<br>l GPU<br>Neo Zhang Jianyu  Log: <a href="./log/08d5986290cc42d2c52739e046642b8252f97e4b">log</a></td>
<td>100.0%<br>NA</td>
<td>54.2</td>
<td>tg=53.88<br>pp=801.37</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8303e8b0fb2c1e26a8edd58071f9120a5bd6930a">8303e8b0fb2c1e26a8edd58071f9120a5bd6930a</a><br>2025-02-24 15:48:25<br>SYCL: Fix GGML_SYCL_DEBUG macro<br>Akarshan Biswas  Log: <a href="./log/8303e8b0fb2c1e26a8edd58071f9120a5bd6930a">log</a></td>
<td>100.0%<br>NA</td>
<td>42.97</td>
<td>tg=42.87<br>pp=915.6</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/68ff663a04ed92044a9937bcae353e9d9733f9cd">68ff663a04ed92044a9937bcae353e9d9733f9cd</a><br>2025-02-15 16:40:57<br>repo : update links to new url<br>Georgi Gerganov  Log: <a href="./log/68ff663a04ed92044a9937bcae353e9d9733f9cd">log</a></td>
<td>100.0%<br>NA</td>
<td>42.98</td>
<td>tg=42.89<br>pp=916.3</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ec3bc8270bc67b58955748d40a3e558a05b2d8f2">ec3bc8270bc67b58955748d40a3e558a05b2d8f2</a><br>2025-02-07 14:57:53<br>SYCL: remove XMX info from print devices<br><br>Akarshan Biswas  Log: <a href="./log/ec3bc8270bc67b58955748d40a3e558a05b2d8f2">log</a></td>
<td>100.0%<br>NA</td>
<td>42.92</td>
<td>tg=42.9<br>pp=915.9</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/194b2e69f8da3a22395c74fd9acd6d5835437b96">194b2e69f8da3a22395c74fd9acd6d5835437b96</a><br>2025-02-06 17:12:35<br>SYCL: Adjust support condition for norm <br>operators<br>Akarshan Biswas  Log: <a href="./log/194b2e69f8da3a22395c74fd9acd6d5835437b96">log</a></td>
<td>100.0%<br>NA</td>
<td>42.92</td>
<td>tg=42.88<br>pp=916.17</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6e84b0ab8e10b8f6f99a32855f976ebcd35b0353">6e84b0ab8e10b8f6f99a32855f976ebcd35b0353</a><br>2025-01-28 15:26:58<br>SYCL : SOFTMAX F16 mask support and othe<br>r fixes<br>Akarshan Biswas  Log: <a href="./log/6e84b0ab8e10b8f6f99a32855f976ebcd35b0353">log</a></td>
<td>100.0%<br>NA</td>
<td>42.91</td>
<td>tg=42.83<br>pp=916.17</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a07c2c8a52464646ce13040e62c1ea04459f721e">a07c2c8a52464646ce13040e62c1ea04459f721e</a><br>2025-01-24 13:30:13<br>docs : Update readme to build targets fo<br>r local docker build<br>Jafar Uruç  Log: <a href="./log/a07c2c8a52464646ce13040e62c1ea04459f721e">log</a></td>
<td>100.0%<br>NA</td>
<td>42.91</td>
<td>tg=42.88<br>pp=916.05</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/99487b57d47e14dc342b7b89d238ca11c0345241">99487b57d47e14dc342b7b89d238ca11c0345241</a><br>2025-01-19 14:33:34<br>SYCL: Introducing memory host pool<br>Nicolò Scipione  Log: <a href="./log/99487b57d47e14dc342b7b89d238ca11c0345241">log</a></td>
<td>100.0%<br>NA</td>
<td>42.88</td>
<td>tg=42.86<br>pp=917.09</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f446c2cf6a56a750b67c967505e717a996d2f2fd">f446c2cf6a56a750b67c967505e717a996d2f2fd</a><br>2025-01-15 08:50:17<br>SYCL: Add gated linear attention kernel<br>Akarshan Biswas  Log: <a href="./log/f446c2cf6a56a750b67c967505e717a996d2f2fd">log</a></td>
<td>100.0%<br>NA</td>
<td>42.91</td>
<td>tg=42.85<br>pp=916.7</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ee7136c6d1e0ba7633294dad137b1573048031ec">ee7136c6d1e0ba7633294dad137b1573048031ec</a><br>2025-01-10 09:58:08<br>llama: add support for QRWKV6 model arch<br>itecture<br>Molly Sophia  Log: <a href="./log/ee7136c6d1e0ba7633294dad137b1573048031ec">log</a></td>
<td>100.0%<br>NA</td>
<td>42.9</td>
<td>tg=42.89<br>pp=917.1</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c6860cc7346c90219475e4467bb8a288e0df975c">c6860cc7346c90219475e4467bb8a288e0df975c</a><br>2025-01-10 05:43:03<br>SYCL: Refactor ggml_sycl_compute_forward<br><br>Akarshan Biswas  Log: <a href="./log/c6860cc7346c90219475e4467bb8a288e0df975c">log</a></td>
<td>100.0%<br>NA</td>
<td>42.93</td>
<td>tg=42.86<br>pp=917.17</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c0d6f790d07aa78be15584ec394ac20739ade93b">c0d6f790d07aa78be15584ec394ac20739ade93b</a><br>2025-01-07 11:56:07<br>SYCL: Use get_multi_ptr instead of depre<br>cated get_pointer in wkv6<br>Akarshan Biswas  Log: <a href="./log/c0d6f790d07aa78be15584ec394ac20739ade93b">log</a></td>
<td>100.0%<br>NA</td>
<td>42.89</td>
<td>tg=42.95<br>pp=917.19</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.4</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/86bf31cfe684849157f0875b4f0ebccac7034547">86bf31cfe684849157f0875b4f0ebccac7034547</a><br>2024-12-23 10:39:30<br>rpc-server : add support for the SYCL ba<br>ckend<br>Radoslav Gerganov  Log: <a href="./log/86bf31cfe684849157f0875b4f0ebccac7034547">log</a></td>
<td>96.0%<br>NA</td>
<td>42.33</td>
<td>tg=42.44<br>pp=948.6</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/eb5c3dc64bd967f2e23c87d9dec195f45468de60">eb5c3dc64bd967f2e23c87d9dec195f45468de60</a><br>2024-12-20 21:01:28<br>SYCL: Migrate away from deprecated ggml_<br>tensor-&gt;backend<br>Akarshan Biswas  Log: <a href="./log/eb5c3dc64bd967f2e23c87d9dec195f45468de60">log</a></td>
<td>100.0%<br>NA</td>
<td>41.12</td>
<td>tg=41.07<br>pp=915.05</td>
<td>('ok', 'pass', 0)</td>
<td>4/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ba1cb19cdd0d92e012e0f6e009e0620f854b6afd">ba1cb19cdd0d92e012e0f6e009e0620f854b6afd</a><br>2024-12-14 20:43:46<br>llama : add Qwen2VL support + multimodal<br> RoPE<br>HimariO  Log: <a href="./log/ba1cb19cdd0d92e012e0f6e009e0620f854b6afd">log</a></td>
<td>100.0%<br>NA</td>
<td>41.17</td>
<td>tg=41.11<br>pp=914.61</td>
<td>('ok', 'pass', 0)</td>
<td>232/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/83ed24a97b500ccdb32b90b94e6f9621ad8db79e">83ed24a97b500ccdb32b90b94e6f9621ad8db79e</a><br>2024-12-13 12:12:15<br>SYCL: Reduce most of the compiler warnin<br>gs<br>Akarshan Biswas  Log: <a href="./log/83ed24a97b500ccdb32b90b94e6f9621ad8db79e">log</a></td>
<td>100.0%<br>NA</td>
<td>41.11</td>
<td>tg=41.15<br>pp=913.95</td>
<td>('ok', 'pass', 0)</td>
<td>232/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/19d8762ab61df8286367588a80b9c7db4cb568db">19d8762ab61df8286367588a80b9c7db4cb568db</a><br>2024-12-07 13:37:50<br>ggml : refactor online repacking<br>Djip007  Log: <a href="./log/19d8762ab61df8286367588a80b9c7db4cb568db">log</a></td>
<td>100.0%<br>NA</td>
<td>41.16</td>
<td>tg=41.15<br>pp=914.83</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/01e6d9bb71eb71fe1f811f2fdef15753232cd0f2">01e6d9bb71eb71fe1f811f2fdef15753232cd0f2</a><br>2024-12-04 08:26:37<br>clip : add sycl support<br>piDack  Log: <a href="./log/01e6d9bb71eb71fe1f811f2fdef15753232cd0f2">log</a></td>
<td>100.0%<br>NA</td>
<td>41.14</td>
<td>tg=41.09<br>pp=913.44</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/40c6d79fb52f995f47507fedfeaae2ac05d9b35c">40c6d79fb52f995f47507fedfeaae2ac05d9b35c</a><br>2024-12-04 02:29:20<br>SYCL : Move to compile time oneMKL inter<br>face backend selection for NVIDIA backen<br>d<br>Nicolò Scipione  Log: <a href="./log/40c6d79fb52f995f47507fedfeaae2ac05d9b35c">log</a></td>
<td>100.0%<br>NA</td>
<td>41.15</td>
<td>tg=41.14<br>pp=914.04</td>
<td>('ok', 'pass', 0)</td>
<td>588/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/991f8aabeec89d801300bb179e52013fb0eb0584">991f8aabeec89d801300bb179e52013fb0eb0584</a><br>2024-12-02 12:34:11<br>SYCL: Fix and switch to GGML_LOG system <br>instead of fprintf<br>Akarshan Biswas  Log: <a href="./log/991f8aabeec89d801300bb179e52013fb0eb0584">log</a></td>
<td>100.0%<br>NA</td>
<td>41.18</td>
<td>tg=41.14<br>pp=914.34</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0f77aae5608f16780a49926b67be6d56ec4b09bd">0f77aae5608f16780a49926b67be6d56ec4b09bd</a><br>2024-11-29 12:38:45<br>sycl : offload of get_rows set to 0<br>Alberto Cabrera Pérez  Log: <a href="./log/0f77aae5608f16780a49926b67be6d56ec4b09bd">log</a></td>
<td>100.0%<br>NA</td>
<td>41.14</td>
<td>tg=41.11<br>pp=913.84</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/266b8519ee6d21e7ba2bf56f5629e20a181fee8b">266b8519ee6d21e7ba2bf56f5629e20a181fee8b</a><br>2024-11-29 09:49:43<br>sycl : Reroute permuted mul_mats through<br> oneMKL<br>Alberto Cabrera Pérez  Log: <a href="./log/266b8519ee6d21e7ba2bf56f5629e20a181fee8b">log</a></td>
<td>100.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.16<br>pp=858.44</td>
<td>('ok', 'pass', 0)</td>
<td>588/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5a8987793f3e7c1fbfa6806bfcd17d578071b6c9">5a8987793f3e7c1fbfa6806bfcd17d578071b6c9</a><br>2024-11-25 17:31:10<br>[SYCL] Fix building Win package for oneA<br>PI 2025.0 update<br>Neo Zhang Jianyu  Log: <a href="./log/5a8987793f3e7c1fbfa6806bfcd17d578071b6c9">log</a></td>
<td>96.0%<br>NA</td>
<td>41.16</td>
<td>tg=41.12<br>pp=860.81</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5931c1f233c616083d64e41a228249d58e039aa5">5931c1f233c616083d64e41a228249d58e039aa5</a><br>2024-11-25 15:13:39<br>ggml : add support for dynamic loading o<br>f backends<br>Diego Devesa  Log: <a href="./log/5931c1f233c616083d64e41a228249d58e039aa5">log</a></td>
<td>96.0%<br>NA</td>
<td>41.14</td>
<td>tg=41.15<br>pp=859.42</td>
<td>('ok', 'pass', 0)</td>
<td>588/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ad21c9e1f14d82b8c15ae369a8839019e3d498b4">ad21c9e1f14d82b8c15ae369a8839019e3d498b4</a><br>2024-11-20 13:54:25<br>update rel to 4040<br>Neo Zhang Jianyu  Log: <a href="./log/ad21c9e1f14d82b8c15ae369a8839019e3d498b4">log</a></td>
<td>96.0%<br>NA</td>
<td>41.14</td>
<td>tg=41.12<br>pp=861.21</td>
<td>('ok', 'pass', 0)</td>
<td>588/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2a1507c1629975d9d20a503d6a14f44eff292c25">2a1507c1629975d9d20a503d6a14f44eff292c25</a><br>2024-11-19 09:02:23<br>sycl : Add option to set the SYCL archit<br>ecture for all targets<br>Romain Biessy  Log: <a href="./log/2a1507c1629975d9d20a503d6a14f44eff292c25">log</a></td>
<td>93.0%<br>NA</td>
<td>41.13</td>
<td>tg=41.17<br>pp=860.07</td>
<td>('ok', 'pass', 0)</td>
<td>576/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/557924f22237c76387a39c4db5abae154d57e754">557924f22237c76387a39c4db5abae154d57e754</a><br>2024-11-19 00:50:04<br>sycl: Revert MUL_MAT_OP support changes<br>Alberto Cabrera Pérez  Log: <a href="./log/557924f22237c76387a39c4db5abae154d57e754">log</a></td>
<td>93.0%<br>NA</td>
<td>41.13</td>
<td>tg=41.08<br>pp=860.82</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/57f8355b29a8c7dfcd1fb6094758ad85644f8535">57f8355b29a8c7dfcd1fb6094758ad85644f8535</a><br>2024-11-15 12:10:45<br>sycl: Update Intel docker images to use <br>DPC++ 2025.0<br>Romain Biessy  Log: <a href="./log/57f8355b29a8c7dfcd1fb6094758ad85644f8535">log</a></td>
<td>96.0%<br>NA</td>
<td>21.47</td>
<td>tg=23.92<br>pp=331.97</td>
<td>('ok', 'pass', 0)</td>
<td>590/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5a54af4d4f588f109f31e456483fdf77096399d9">5a54af4d4f588f109f31e456483fdf77096399d9</a><br>2024-11-15 04:09:12<br>sycl: Use syclcompat::dp4a<br>Romain Biessy  Log: <a href="./log/5a54af4d4f588f109f31e456483fdf77096399d9">log</a></td>
<td>96.0%<br>NA</td>
<td>21.58</td>
<td>tg=24.02<br>pp=335.01</td>
<td>('ok', 'pass', 0)</td>
<td>598/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ae8de6d50a09d49545e0afab2e50cc4acfb280e2">ae8de6d50a09d49545e0afab2e50cc4acfb280e2</a><br>2024-11-14 18:04:35<br>ggml : build backends as libraries<br>Diego Devesa  Log: <a href="./log/ae8de6d50a09d49545e0afab2e50cc4acfb280e2">log</a></td>
<td>96.0%<br>NA</td>
<td>21.93</td>
<td>tg=24.07<br>pp=337.85</td>
<td>('ok', 'pass', 0)</td>
<td>614/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2e82ffa4af29f87e7d3d6dff8060a2a79613b72f">2e82ffa4af29f87e7d3d6dff8060a2a79613b72f</a><br>2024-11-13 09:40:57<br>sycl : Fixes to broken builds and test-b<br>ackend-ops<br>Alberto Cabrera Pérez  Log: <a href="./log/2e82ffa4af29f87e7d3d6dff8060a2a79613b72f">log</a></td>
<td>96.0%<br>NA</td>
<td>21.47</td>
<td>tg=24.02<br>pp=339.83</td>
<td>('ok', 'pass', 0)</td>
<td>592/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3bcd40b3c593d14261fb2abfabad3c0fb5b9e318">3bcd40b3c593d14261fb2abfabad3c0fb5b9e318</a><br>2024-11-07 18:19:10<br>Optimize RWKV6 Operator Naming and Imple<br>ment Multi-core CPU/ SYCL Acceleration<br>Zhiyuan Li  Log: <a href="./log/3bcd40b3c593d14261fb2abfabad3c0fb5b9e318">log</a></td>
<td>93.0%<br>NA</td>
<td>41.09</td>
<td>tg=41.09<br>pp=859.12</td>
<td>('ok', 'pass', 0)</td>
<td>602/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc">c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc</a><br>2024-10-30 02:01:23<br>llama : refactor model loader with backe<br>nd registry<br>Diego Devesa  Log: <a href="./log/c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc">log</a></td>
<td>93.0%<br>NA</td>
<td>41.05</td>
<td>tg=41.06<br>pp=906.96</td>
<td>('ok', 'pass', 0)</td>
<td>514/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/40f2555797f97314de749873cdc29dc102be66e2">40f2555797f97314de749873cdc29dc102be66e2</a><br>2024-10-24 21:23:33<br>ci : fix cmake flags for SYCL<br>Georgi Gerganov  Log: <a href="./log/40f2555797f97314de749873cdc29dc102be66e2">log</a></td>
<td>93.0%<br>NA</td>
<td>41.05</td>
<td>tg=41.09<br>pp=913.96</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31">1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31</a><br>2024-10-21 14:26:09<br>fix mul_mat_vec_q and *_vec_q error<br>Neo Zhang Jianyu  Log: <a href="./log/1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31">log</a></td>
<td>96.0%<br>NA</td>
<td>41.08</td>
<td>tg=41.1<br>pp=914.34</td>
<td>('ok', 'pass', 0)</td>
<td>505/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/87421a23e8c60e00a7b227d501e8aab2a1aff7ce">87421a23e8c60e00a7b227d501e8aab2a1aff7ce</a><br>2024-10-18 06:46:16<br>[SYCL] Add SYCL Backend registry, device<br> and Event Interfaces<br>Ouadie EL FAROUKI  Log: <a href="./log/87421a23e8c60e00a7b227d501e8aab2a1aff7ce">log</a></td>
<td>96.0%<br>NA</td>
<td>41.07</td>
<td>tg=41.11<br>pp=914.42</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5639971466ed74386a1811938022f0c333007b55">5639971466ed74386a1811938022f0c333007b55</a><br>2024-10-03 07:50:44<br>Fixed dequant precision issues in Q4_1 a<br>nd Q5_1<br>Ouadie EL FAROUKI  Log: <a href="./log/5639971466ed74386a1811938022f0c333007b55">log</a></td>
<td>96.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.06<br>pp=915.19</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6">c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6</a><br>2024-10-03 01:49:47<br>ggml-backend : add device and backend re<br>g interfaces<br>Diego Devesa  Log: <a href="./log/c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6">log</a></td>
<td>96.0%<br>NA</td>
<td>41.07</td>
<td>tg=41.06<br>pp=915.9</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f536f4c4391bec74c432a924625c04e8c484d3ee">f536f4c4391bec74c432a924625c04e8c484d3ee</a><br>2024-10-02 13:57:18<br>[SYCL] Initial cmake support of SYCL for<br> AMD GPUs<br>Alberto Cabrera Pérez  Log: <a href="./log/f536f4c4391bec74c432a924625c04e8c484d3ee">log</a></td>
<td>96.0%<br>NA</td>
<td>41.08</td>
<td>tg=41.05<br>pp=915.28</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/95bc82fbc0df6d48cf66c857a4dda3d044f45ca2">95bc82fbc0df6d48cf66c857a4dda3d044f45ca2</a><br>2024-09-26 17:38:31<br>[SYCL] add missed dll file in package<br>Neo Zhang Jianyu  Log: <a href="./log/95bc82fbc0df6d48cf66c857a4dda3d044f45ca2">log</a></td>
<td>96.0%<br>NA</td>
<td>41.03</td>
<td>tg=41.03<br>pp=914.09</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e62e9789cda3bf5573a747e55ec2a7ee32908f56">e62e9789cda3bf5573a747e55ec2a7ee32908f56</a><br>2024-09-23 08:58:06<br>Revert "[SYCL] fallback mmvq<br>Akarshan Biswas  Log: <a href="./log/e62e9789cda3bf5573a747e55ec2a7ee32908f56">log</a></td>
<td>96.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.07<br>pp=915.59</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d13edb17ed1ce3b961016cbdb616b1c8d161c026">d13edb17ed1ce3b961016cbdb616b1c8d161c026</a><br>2024-09-20 20:12:52<br>ggml : fix builds<br>Georgi Gerganov  Log: <a href="./log/d13edb17ed1ce3b961016cbdb616b1c8d161c026">log</a></td>
<td>96.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.05<br>pp=915.26</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/424c5d00a9b97dd5559635872db9b57f87c23b02">424c5d00a9b97dd5559635872db9b57f87c23b02</a><br>2024-09-20 19:04:44<br>ggml/examples: add backend support for n<br>umerical optimization<br>Johannes Gäßler  Log: <a href="./log/424c5d00a9b97dd5559635872db9b57f87c23b02">log</a></td>
<td>Build Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)</td>
<td>77/3<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/faf67b3de4688f47c3b1019c89df255df2fd59b4">faf67b3de4688f47c3b1019c89df255df2fd59b4</a><br>2024-09-18 08:30:31<br>[SYCL]set context default value to avoid<br> memory issue, update guide<br>Neo Zhang Jianyu  Log: <a href="./log/faf67b3de4688f47c3b1019c89df255df2fd59b4">log</a></td>
<td>96.0%<br>NA</td>
<td>41.07</td>
<td>tg=40.99<br>pp=916.02</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)</td>
<td>502/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6988da94a261444859f78595899212eeedc5ff9d">6988da94a261444859f78595899212eeedc5ff9d</a><br>2024-09-15 18:55:52<br>cmake : correct order of sycl flags<br>Michael Podvitskiy  Log: <a href="./log/6988da94a261444859f78595899212eeedc5ff9d">log</a></td>
<td>96.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.13<br>pp=914.83</td>
<td>('ok', 'pass', 0)</td>
<td>503/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7596487bebd58eade3cd0133d42a9008aaaf9d09">7596487bebd58eade3cd0133d42a9008aaaf9d09</a><br>2024-09-15 09:06:38<br>cmake : try to fix sycl+intel build<br>Michael Podvitskiy  Log: <a href="./log/7596487bebd58eade3cd0133d42a9008aaaf9d09">log</a></td>
<td>96.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.11<br>pp=914.12</td>
<td>('ok', 'pass', 0)</td>
<td>510/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c9c8575a1a8a170329afca4c4df4c005806efb1d">c9c8575a1a8a170329afca4c4df4c005806efb1d</a><br>2024-09-12 17:44:17<br>enhance run script to be easy to change <br>the parameters<br>Neo Zhang Jianyu  Log: <a href="./log/c9c8575a1a8a170329afca4c4df4c005806efb1d">log</a></td>
<td>92.0%<br>1441/1442</td>
<td>41.07</td>
<td>tg=41.06<br>pp=915.65</td>
<td>('ok', 'pass', 0)</td>
<td>500/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d6a04f872dea8ade92527bb1488d4b0b90cc49f0">d6a04f872dea8ade92527bb1488d4b0b90cc49f0</a><br>2024-09-12 14:23:49<br>ggml : hide ggml_object, ggml_cgraph, gg<br>ml_hash_set<br>Georgi Gerganov  Log: <a href="./log/d6a04f872dea8ade92527bb1488d4b0b90cc49f0">log</a></td>
<td>96.0%<br>NA</td>
<td>41.06</td>
<td>tg=41.05<br>pp=915.26</td>
<td>('ok', 'pass', 0)</td>
<td>502/0<br>2025.0.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/51b603863627c4074e77b7e556e18ece86bdf9a3">51b603863627c4074e77b7e556e18ece86bdf9a3</a><br>2024-09-11 01:53:42<br>sycl : update support conditions<br>Alberto Cabrera Pérez  Log: <a href="./log/51b603863627c4074e77b7e556e18ece86bdf9a3">log</a></td>
<td>96.0%<br>NA</td>
<td>42.67</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2a358fb0c4b6e917ac852aa17444cc94dd28a2a6">2a358fb0c4b6e917ac852aa17444cc94dd28a2a6</a><br>2024-09-08 19:05:29<br>[SYCL] add check malloc result on device<br><br>Neo Zhang Jianyu  Log: <a href="./log/2a358fb0c4b6e917ac852aa17444cc94dd28a2a6">log</a></td>
<td>92.0%<br>NA</td>
<td>42.71</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5910ea942772ab6cbc21d0ad2d1208750ba39e1d">5910ea942772ab6cbc21d0ad2d1208750ba39e1d</a><br>2024-09-04 16:26:33<br>[SYCL] Fix DMMV dequantization<br>Ouadie EL FAROUKI  Log: <a href="./log/5910ea942772ab6cbc21d0ad2d1208750ba39e1d">log</a></td>
<td>96.0%<br>NA</td>
<td>42.7</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/cddae4884c853b1a7ab420458236d666e2e34423">cddae4884c853b1a7ab420458236d666e2e34423</a><br>2024-08-30 20:10:01<br>Correct typo run_llama2.sh &gt; run-llama2.<br>sh<br>蕭澧邦  Log: <a href="./log/cddae4884c853b1a7ab420458236d666e2e34423">log</a></td>
<td>92.0%<br>1417/1421</td>
<td>42.92</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/11b84eb4578864827afcf956db5b571003f18180">11b84eb4578864827afcf956db5b571003f18180</a><br>2024-08-22 19:39:47<br>[SYCL] Add a space to supress a cmake wa<br>rning<br>Akarshan Biswas  Log: <a href="./log/11b84eb4578864827afcf956db5b571003f18180">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>41.92</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1731d4238f9e4f925a750810e7f5480827c66dcf">1731d4238f9e4f925a750810e7f5480827c66dcf</a><br>2024-08-22 12:50:10<br>[SYCL] Add oneDNN primitive support<br>luoyu-intel  Log: <a href="./log/1731d4238f9e4f925a750810e7f5480827c66dcf">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>41.08</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>512/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/50addec9a532a6518146ab837a85504850627316">50addec9a532a6518146ab837a85504850627316</a><br>2024-08-20 23:50:17<br>[SYCL] fallback mmvq<br>Meng, Hengyu  Log: <a href="./log/50addec9a532a6518146ab837a85504850627316">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>42.89</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>494/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b">4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b</a><br>2024-08-20 23:06:51<br>[SYCL] Fix SYCL <code>im2col</code> and <code>convert</code> O<br>verflow with Large Dims<br>zhentaoyu  Log: <a href="./log/4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>42.89</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>494/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/06943a69f678fb32829ff06d9c18367b17d4b361">06943a69f678fb32829ff06d9c18367b17d4b361</a><br>2024-08-13 21:13:15<br>ggml : move rope type enum to ggml.h<br>Daniel Bevenius  Log: <a href="./log/06943a69f678fb32829ff06d9c18367b17d4b361">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>42.91</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a21c6fd45032a20180e026773582d21294c85619">a21c6fd45032a20180e026773582d21294c85619</a><br>2024-08-11 16:37:43<br>update guide<br>Neo Zhang  Log: <a href="./log/a21c6fd45032a20180e026773582d21294c85619">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>42.88</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0478174d5959b66096ae6609fcb0df14cab66b51">0478174d5959b66096ae6609fcb0df14cab66b51</a><br>2024-08-07 11:25:36<br>[SYCL] Updated SYCL device filtering<br>Ouadie EL FAROUKI  Log: <a href="./log/0478174d5959b66096ae6609fcb0df14cab66b51">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>42.86</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf">2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf</a><br>2024-08-06 15:26:46<br>ggml : add epsilon as a parameter for gr<br>oup_norm<br>Molly Sophia  Log: <a href="./log/2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>38.34</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d4ff847153e9cf7220d1b39aa21172069e6e8cea">d4ff847153e9cf7220d1b39aa21172069e6e8cea</a><br>2024-08-06 09:09:12<br>[SYCL] correct .html name<br>Neo Zhang  Log: <a href="./log/d4ff847153e9cf7220d1b39aa21172069e6e8cea">log</a></td>
<td>92.0%<br>1338/1342</td>
<td>19.32</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0fbbd884589d585c3b43cae8c16938ffffb863b9">0fbbd884589d585c3b43cae8c16938ffffb863b9</a><br>2024-08-02 01:55:17<br>[SYCL] Fixing wrong VDR iq4nl value<br>Ouadie EL FAROUKI  Log: <a href="./log/0fbbd884589d585c3b43cae8c16938ffffb863b9">log</a></td>
<td>92.0%<br>1347/1351</td>
<td>42.94</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c887d8b01726b11ea03dbcaa9d44fa74422d0076">c887d8b01726b11ea03dbcaa9d44fa74422d0076</a><br>2024-07-30 14:56:51<br>[SYCL] Add <code>TIMESTEP_EMBEDDING</code> OP<br>zhentaoyu  Log: <a href="./log/c887d8b01726b11ea03dbcaa9d44fa74422d0076">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.93</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0832de723695ab400316a6c49b9f712380e3a731">0832de723695ab400316a6c49b9f712380e3a731</a><br>2024-07-29 10:50:27<br>[SYCL] add conv support<br>Meng, Hengyu  Log: <a href="./log/0832de723695ab400316a6c49b9f712380e3a731">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.95</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>464/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2b1f616b208a4a21c4ee7a7eb85d822ff1d787af">2b1f616b208a4a21c4ee7a7eb85d822ff1d787af</a><br>2024-07-27 04:41:55<br>ggml : reduce hash table reset cost<br>slaren  Log: <a href="./log/2b1f616b208a4a21c4ee7a7eb85d822ff1d787af">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.93</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>450/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ed67bcb24f2d6ac0072cae72620b2bd971741b98">ed67bcb24f2d6ac0072cae72620b2bd971741b98</a><br>2024-07-25 11:45:18<br>[SYCL] fix multi-gpu issue on sycl<br>Chen Xi  Log: <a href="./log/ed67bcb24f2d6ac0072cae72620b2bd971741b98">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.74</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>454/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f19bf99c015d3d745143e8bb4f056e0ea015ad40">f19bf99c015d3d745143e8bb4f056e0ea015ad40</a><br>2024-07-24 14:36:00<br>Build Llama SYCL Intel with static libs<br>Joe Todd  Log: <a href="./log/f19bf99c015d3d745143e8bb4f056e0ea015ad40">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.73</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>474/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/79167d9e49aef9caa98e13ee7ca067ec9f88b4b5">79167d9e49aef9caa98e13ee7ca067ec9f88b4b5</a><br>2024-07-24 11:55:26<br>Re-add erroneously removed -fsycl from G<br>GML_EXTRA_LIBS<br>Joe Todd  Log: <a href="./log/79167d9e49aef9caa98e13ee7ca067ec9f88b4b5">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.77</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>472/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e">64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e</a><br>2024-07-23 14:58:37<br>sycl : Add support for non-release DPC++<br> &amp; oneMKL<br>Joe Todd  Log: <a href="./log/64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e">log</a></td>
<td>92.0%<br>1331/1334</td>
<td>42.76</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>472/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/063d99ad11f1295046610ce5b97e105849a4b573">063d99ad11f1295046610ce5b97e105849a4b573</a><br>2024-07-23 07:43:28<br>[SYCL] fix scratch size of softmax<br>luoyu-intel  Log: <a href="./log/063d99ad11f1295046610ce5b97e105849a4b573">log</a></td>
<td>92.0%<br>1332/1334</td>
<td>42.79</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>474/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/16bdfa42acb09175e88cf97e9d9e4e48f616d120">16bdfa42acb09175e88cf97e9d9e4e48f616d120</a><br>2024-07-15 19:32:15<br>[SYCL] add concat through dim 1/2<br>Meng, Hengyu  Log: <a href="./log/16bdfa42acb09175e88cf97e9d9e4e48f616d120">log</a></td>
<td>91.0%<br>1279/1281</td>
<td>42.75</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>474/0<br>2024.2.1</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b549a1bbefb2f1fbb8b558bac1f2ae7967e60964">b549a1bbefb2f1fbb8b558bac1f2ae7967e60964</a><br>2024-07-12 00:52:04<br>[SYCL] fix the mul_mat_id ut issues<br>Chen Xi  Log: <a href="./log/b549a1bbefb2f1fbb8b558bac1f2ae7967e60964">log</a></td>
<td>91.0%<br>1279/1281</td>
<td>42.73</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>464/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f4444d992c16b6b9442f4770c7c3a10b19a08343">f4444d992c16b6b9442f4770c7c3a10b19a08343</a><br>2024-07-10 16:10:49<br>[SYCL] Use multi_ptr to clean up depreca<br>ted warnings<br>AidanBeltonS  Log: <a href="./log/f4444d992c16b6b9442f4770c7c3a10b19a08343">log</a></td>
<td>91.0%<br>NA</td>
<td>42.72</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>474/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b">5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b</a><br>2024-07-09 15:03:15<br>sycl : Reenabled mmvq path for the SYCL <br>Nvidia Backend<br>Alberto Cabrera Pérez  Log: <a href="./log/5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b">log</a></td>
<td>91.0%<br>NA</td>
<td>42.71</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>692/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a130eccef42b75a84da270411cefeed45c153e30">a130eccef42b75a84da270411cefeed45c153e30</a><br>2024-07-08 21:35:17<br>labeler : updated sycl to match docs and<br> code refactor<br>Alberto Cabrera Pérez  Log: <a href="./log/a130eccef42b75a84da270411cefeed45c153e30">log</a></td>
<td>91.0%<br>NA</td>
<td>42.75</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>692/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2ec846d558f6385ea647f7b8e665eb249c1ebce7">2ec846d558f6385ea647f7b8e665eb249c1ebce7</a><br>2024-07-08 14:22:41<br>sycl : fix powf call in device code<br>Alberto Cabrera Pérez  Log: <a href="./log/2ec846d558f6385ea647f7b8e665eb249c1ebce7">log</a></td>
<td>91.0%<br>NA</td>
<td>42.73</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>692/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3f2d538b817112ad8429341c7e8657dcd660f4d3">3f2d538b817112ad8429341c7e8657dcd660f4d3</a><br>2024-07-08 13:51:31<br>scripts : fix sync for sycl<br>Georgi Gerganov  Log: <a href="./log/3f2d538b817112ad8429341c7e8657dcd660f4d3">log</a></td>
<td>91.0%<br>NA</td>
<td>42.74</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>692/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d">be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d</a><br>2024-07-05 18:08:32<br>Reorganize documentation pages<br>Xuan Son Nguyen  Log: <a href="./log/be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d">log</a></td>
<td>91.0%<br>NA</td>
<td>43.43</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>705/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1f3e1b66e21310ed78b964f72f19766549633f0e">1f3e1b66e21310ed78b964f72f19766549633f0e</a><br>2024-07-05 13:23:25<br>Enabled more data types for oneMKL gemm_<br>batch<br>Ouadie EL FAROUKI  Log: <a href="./log/1f3e1b66e21310ed78b964f72f19766549633f0e">log</a></td>
<td>91.0%<br>NA</td>
<td>43.43</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>705/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f09b7cb609d80b8031803f89255991dc8b35db69">f09b7cb609d80b8031803f89255991dc8b35db69</a><br>2024-07-05 10:32:29<br>rm get_work_group_size<br>Neo Zhang Jianyu  Log: <a href="./log/f09b7cb609d80b8031803f89255991dc8b35db69">log</a></td>
<td>91.0%<br>NA</td>
<td>40.05</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>561/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a9554e20b66546b0549aebe2e1034bc8afe9d809">a9554e20b66546b0549aebe2e1034bc8afe9d809</a><br>2024-07-05 05:06:13<br>[SYCL] Fix WARP_SIZE=16 bug of Intel GPU<br><br>luoyu-intel  Log: <a href="./log/a9554e20b66546b0549aebe2e1034bc8afe9d809">log</a></td>
<td>91.0%<br>NA</td>
<td>43.45</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>703/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f619024764e72261f14d7c31d892b8fb976603b4">f619024764e72261f14d7c31d892b8fb976603b4</a><br>2024-07-04 02:07:19<br>[SYCL] Remove unneeded semicolons<br>AidanBeltonS  Log: <a href="./log/f619024764e72261f14d7c31d892b8fb976603b4">log</a></td>
<td>91.0%<br>NA</td>
<td>40.07</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>569/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/fadde6713506d9e6c124f5680ab8c7abebe31837">fadde6713506d9e6c124f5680ab8c7abebe31837</a><br>2024-07-03 02:55:34<br>Dequant improvements rebase<br>AidanBeltonS  Log: <a href="./log/fadde6713506d9e6c124f5680ab8c7abebe31837">log</a></td>
<td>91.0%<br>NA</td>
<td>40.05</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>569/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81">07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81</a><br>2024-07-02 12:18:10<br>Removes multiple newlines at the end of <br>files that is breaking the editorconfig <br>step of CI.<br>Clint Herron  Log: <a href="./log/07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81">log</a></td>
<td>91.0%<br>NA</td>
<td>40.06</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>563/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a9f3b102157ba992cfe058909b7f6e1906d2d647">a9f3b102157ba992cfe058909b7f6e1906d2d647</a><br>2024-07-02 04:50:07<br>[SYCL] Fix win build conflict of math li<br>brary<br>luoyu-intel  Log: <a href="./log/a9f3b102157ba992cfe058909b7f6e1906d2d647">log</a></td>
<td>91.0%<br>NA</td>
<td>41.13</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>550/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d08c20eddedb24515a3212e2de66bdff41a26b8c">d08c20eddedb24515a3212e2de66bdff41a26b8c</a><br>2024-07-02 02:16:00<br>[SYCL] Fix the sub group size of Intel<br>luoyu-intel  Log: <a href="./log/d08c20eddedb24515a3212e2de66bdff41a26b8c">log</a></td>
<td>91.0%<br>NA</td>
<td>43.38</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: The original copy text needed sh<br>ould describe the products/ services.', <br>0)</td>
<td>599/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846">cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846</a><br>2024-07-01 20:39:06<br>CUDA: refactor and optimize IQ MMVQ<br>Johannes Gäßler  Log: <a href="./log/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846">log</a></td>
<td>91.0%<br>NA</td>
<td>40.11</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>543/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/197fe6c1d7bec6718ce901f0141b2725240f298c">197fe6c1d7bec6718ce901f0141b2725240f298c</a><br>2024-07-01 19:39:06<br>[SYCL] Update SYCL-Rope op and Refactor<br>zhentaoyu  Log: <a href="./log/197fe6c1d7bec6718ce901f0141b2725240f298c">log</a></td>
<td>91.0%<br>NA</td>
<td>40.09</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>543/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f3f65429c44bb195a9195bfdc19a30a79709db7b">f3f65429c44bb195a9195bfdc19a30a79709db7b</a><br>2024-06-26 18:33:02<br>llama : reorganize source code + improve<br> CMake<br>Georgi Gerganov  Log: <a href="./log/f3f65429c44bb195a9195bfdc19a30a79709db7b">log</a></td>
<td>95.0%<br>NA</td>
<td>40.08</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>533/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/083bacce14c1aaf9976aa40e8266cdc25ac749d3">083bacce14c1aaf9976aa40e8266cdc25ac749d3</a><br>2024-06-25 10:19:20<br>[SYCL] Re-enabled mul_mat_batched_sycl<br>Meng, Hengyu  Log: <a href="./log/083bacce14c1aaf9976aa40e8266cdc25ac749d3">log</a></td>
<td>91.0%<br>NA</td>
<td>40.11</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>554/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/de391e4c803383bbea054b6edd016e78c024a74d">de391e4c803383bbea054b6edd016e78c024a74d</a><br>2024-06-20 13:19:05<br>[SYCL] Fix windows build and inference<br>luoyu-intel  Log: <a href="./log/de391e4c803383bbea054b6edd016e78c024a74d">log</a></td>
<td>91.0%<br>NA</td>
<td>40.12</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>554/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/623494a478134432fd2d7ee40135770a3340674f">623494a478134432fd2d7ee40135770a3340674f</a><br>2024-06-19 09:11:51<br>[SYCL] refactor<br>Meng, Hengyu  Log: <a href="./log/623494a478134432fd2d7ee40135770a3340674f">log</a></td>
<td>91.0%<br>NA</td>
<td>40.11</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>542/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/df68d4fa5dc929217d3e64d673e099d7a417b206">df68d4fa5dc929217d3e64d673e099d7a417b206</a><br>2024-06-17 11:17:07<br>[SYCL] Update README-sycl.html for Chapter<br> "Recommended release" and "News"<br>Neo Zhang  Log: <a href="./log/df68d4fa5dc929217d3e64d673e099d7a417b206">log</a></td>
<td>91.0%<br>NA</td>
<td>40.05</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7b2f4a7d193ef2475259bbe7656fcccfab4b1217">7b2f4a7d193ef2475259bbe7656fcccfab4b1217</a><br>2024-06-15 14:05:10<br>[SYCL] remove global variables<br>Meng, Hengyu  Log: <a href="./log/7b2f4a7d193ef2475259bbe7656fcccfab4b1217">log</a></td>
<td>91.0%<br>NA</td>
<td>40.04</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>480/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f578b86b2123d0f92afbaa98a031df4d4464e582">f578b86b2123d0f92afbaa98a031df4d4464e582</a><br>2024-06-13 03:11:35<br>move BLAS to a separate backend<br>slaren  Log: <a href="./log/f578b86b2123d0f92afbaa98a031df4d4464e582">log</a></td>
<td>91.0%<br>NA</td>
<td>30.36</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7">1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7</a><br>2024-06-13 00:41:52<br><code>build</code>: rename main → llama-cli, server<br> → llama-server, llava-cli → llama-llava<br>-cli, etc...<br>Olivier Chafik  Log: <a href="./log/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7">log</a></td>
<td>91.0%<br>NA</td>
<td>30.35</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a9cae48003dfc4fe95b8f5c81682fc6e63425235">a9cae48003dfc4fe95b8f5c81682fc6e63425235</a><br>2024-06-12 16:00:22<br>tests : add non-cont unary tests<br>Georgi Gerganov  Log: <a href="./log/a9cae48003dfc4fe95b8f5c81682fc6e63425235">log</a></td>
<td>91.0%<br>NA</td>
<td>30.36</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7">af4ae502ddaeb03cd5861273ca2e9a5ae4551db7</a><br>2024-06-10 02:21:31<br>use the correct SYCL context for host US<br>M allocations<br>Ben Ashbaugh  Log: <a href="./log/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7">log</a></td>
<td>91.0%<br>NA</td>
<td>30.37</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/fe1e3917cfa0f9397a765cfd0aef880674d938d5">fe1e3917cfa0f9397a765cfd0aef880674d938d5</a><br>2024-06-09 01:43:39<br>Revert "[SYCL] Update rpc-server.cpp to <br>include SYCL backend<br>slaren  Log: <a href="./log/fe1e3917cfa0f9397a765cfd0aef880674d938d5">log</a></td>
<td>91.0%<br>NA</td>
<td>30.38</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d5c938cd7716b9a2ace49a43a469dfbffcff4d28">d5c938cd7716b9a2ace49a43a469dfbffcff4d28</a><br>2024-06-07 14:28:26<br>[SYCL] fix softmax r2r result wrong issu<br>e<br>pengxin99  Log: <a href="./log/d5c938cd7716b9a2ace49a43a469dfbffcff4d28">log</a></td>
<td>91.0%<br>NA</td>
<td>30.34</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2b3389677a833cee0880226533a1768b1a9508d2">2b3389677a833cee0880226533a1768b1a9508d2</a><br>2024-06-05 11:29:20<br>ggml : refactor rope norm/neox<br>Georgi Gerganov  Log: <a href="./log/2b3389677a833cee0880226533a1768b1a9508d2">log</a></td>
<td>91.0%<br>NA</td>
<td>30.36</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)</td>
<td>463/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/554c247caffed64465f372661f2826640cb10430">554c247caffed64465f372661f2826640cb10430</a><br>2024-06-04 21:23:20<br>ggml : remove OpenCL<br>Georgi Gerganov  Log: <a href="./log/554c247caffed64465f372661f2826640cb10430">log</a></td>
<td>91.0%<br>NA</td>
<td>30.66</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make report (every ra,accept, li<br>ke,5 was(d –(a, the,', 6)</td>
<td>457/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3b38d48609280aa5f8ab7ea135a4351b2a5ee240">3b38d48609280aa5f8ab7ea135a4351b2a5ee240</a><br>2024-06-04 09:17:17<br>Per token attributes<br>jaime-m-p  Log: <a href="./log/3b38d48609280aa5f8ab7ea135a4351b2a5ee240">log</a></td>
<td>91.0%<br>NA</td>
<td>37.21</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make report (v has have has got <br>(pay( Big and (c gu in to The(Col U2 R,2<br>', 6)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a5735e4426b19a3ebd0c653ad8ac01420458ee95">a5735e4426b19a3ebd0c653ad8ac01420458ee95</a><br>2024-06-04 00:14:15<br>ggml : use OpenMP as a thread pool<br>Masaya, Kato  Log: <a href="./log/a5735e4426b19a3ebd0c653ad8ac01420458ee95">log</a></td>
<td>91.0%<br>NA</td>
<td>37.23</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/bde7cd3cd949c1a85d3a199498ac98e78039d46f">bde7cd3cd949c1a85d3a199498ac98e78039d46f</a><br>2024-06-03 20:03:26<br>llama : offload to RPC in addition to ot<br>her backends<br>Radoslav Gerganov  Log: <a href="./log/bde7cd3cd949c1a85d3a199498ac98e78039d46f">log</a></td>
<td>91.0%<br>NA</td>
<td>37.18</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make report (v has have has got <br>(pay( Big and (c gu in to The(Col U2 R,2<br>', 6)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0b832d53ba0ffcc759c8d62ede3772dd62321f8e">0b832d53ba0ffcc759c8d62ede3772dd62321f8e</a><br>2024-06-03 16:28:58<br>make: fix debug options not being applie<br>d to NVCC<br>Johannes Gäßler  Log: <a href="./log/0b832d53ba0ffcc759c8d62ede3772dd62321f8e">log</a></td>
<td>91.0%<br>NA</td>
<td>37.2</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9422c5e34bbd302493b77a8f6d546154a1f4fe82">9422c5e34bbd302493b77a8f6d546154a1f4fe82</a><br>2024-06-02 19:13:54<br>[SYCL] Update rpc-server.cpp to include <br>SYCL backend<br>nickp27  Log: <a href="./log/9422c5e34bbd302493b77a8f6d546154a1f4fe82">log</a></td>
<td>91.0%<br>NA</td>
<td>30.7</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>457/0<br>2024.2.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/7c4e5b7eae26581869e782015d9deca947c34997">7c4e5b7eae26581869e782015d9deca947c34997</a><br>2024-06-02 13:39:08<br>chore : add ignore rule for generated se<br>rver themes<br>Austin  Log: <a href="./log/7c4e5b7eae26581869e782015d9deca947c34997">log</a></td>
<td>91.0%<br>NA</td>
<td>37.19</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/fb76ec31a9914b7761c1727303ab30380fd4f05c">fb76ec31a9914b7761c1727303ab30380fd4f05c</a><br>2024-05-29 20:17:31<br>ggml : fix YARN + add tests + add assert<br>s<br>Georgi Gerganov  Log: <a href="./log/fb76ec31a9914b7761c1727303ab30380fd4f05c">log</a></td>
<td>91.0%<br>NA</td>
<td>37.18</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0e8d8bfd6caf1d0a8cbdf9d3d5c06fbbb9dfced8">0e8d8bfd6caf1d0a8cbdf9d3d5c06fbbb9dfced8</a><br>2024-05-29 12:23:47<br>Add Arc A750 and Arch linux to readme-sy<br>cl.html as verified GPU model and Linux di<br>stro<br>Akarshan Biswas  Log: <a href="./log/0e8d8bfd6caf1d0a8cbdf9d3d5c06fbbb9dfced8">log</a></td>
<td>91.0%<br>NA</td>
<td>37.24</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b864b50ce5e2beefc8c2fd31733e4e1a978b7754">b864b50ce5e2beefc8c2fd31733e4e1a978b7754</a><br>2024-05-29 07:00:24<br>[SYCL] Align GEMM dispatch<br>Meng, Hengyu  Log: <a href="./log/b864b50ce5e2beefc8c2fd31733e4e1a978b7754">log</a></td>
<td>91.0%<br>NA</td>
<td>37.25</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6bd12ce409f949012935b7d1b15a21ffa473a565">6bd12ce409f949012935b7d1b15a21ffa473a565</a><br>2024-05-28 22:22:50<br>sycl : fix assert<br>Georgi Gerganov  Log: <a href="./log/6bd12ce409f949012935b7d1b15a21ffa473a565">log</a></td>
<td>91.0%<br>NA</td>
<td>34.86</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e2b065071c5fc8ac5697d12ca343551faee465cc">e2b065071c5fc8ac5697d12ca343551faee465cc</a><br>2024-05-28 17:53:37<br>[SYCL]fix ggml_sycl_mul_mat_id<br>Neo Zhang  Log: <a href="./log/e2b065071c5fc8ac5697d12ca343551faee465cc">log</a></td>
<td>91.0%<br>NA</td>
<td>34.85</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0548a4187f2e53b8fc6d9ff0f4c71988f708ff42">0548a4187f2e53b8fc6d9ff0f4c71988f708ff42</a><br>2024-05-28 11:04:19<br>ggml : generalize GGML_OP_CONCAT<br>Georgi Gerganov  Log: <a href="./log/0548a4187f2e53b8fc6d9ff0f4c71988f708ff42">log</a></td>
<td>91.0%<br>NA</td>
<td>34.85</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/95f84d5ce8b449a9b16009434aca800df504a02e">95f84d5ce8b449a9b16009434aca800df504a02e</a><br>2024-05-27 17:34:51<br>Fix q_xxs using mul_mat_q<br>AidanBeltonS  Log: <a href="./log/95f84d5ce8b449a9b16009434aca800df504a02e">log</a></td>
<td>91.0%<br>NA</td>
<td>34.84</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5487593bc7ee0b65b9d2e2985b4b61dc77043101">5487593bc7ee0b65b9d2e2985b4b61dc77043101</a><br>2024-05-27 13:34:09<br>Add freq factors<br>AidanBeltonS  Log: <a href="./log/5487593bc7ee0b65b9d2e2985b4b61dc77043101">log</a></td>
<td>91.0%<br>NA</td>
<td>34.81</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0df0aa8e43c3378975269a51f9b876c8692e70da">0df0aa8e43c3378975269a51f9b876c8692e70da</a><br>2024-05-24 10:06:56<br>add build shared lib in win release pack<br>age<br>Neo Zhang  Log: <a href="./log/0df0aa8e43c3378975269a51f9b876c8692e70da">log</a></td>
<td>91.0%<br>NA</td>
<td>34.78</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e84b71c2c6da6e69c8f815168ea836f9716a325e">e84b71c2c6da6e69c8f815168ea836f9716a325e</a><br>2024-05-23 10:00:21<br>ggml : drop support for QK_K=64<br>Georgi Gerganov  Log: <a href="./log/e84b71c2c6da6e69c8f815168ea836f9716a325e">log</a></td>
<td>91.0%<br>NA</td>
<td>34.83</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/201cc11afa0a1950e1f632390b2ac6c937a0d8f0">201cc11afa0a1950e1f632390b2ac6c937a0d8f0</a><br>2024-05-22 04:28:32<br>llama : add phi3 128K model support<br>liuwei-git  Log: <a href="./log/201cc11afa0a1950e1f632390b2ac6c937a0d8f0">log</a></td>
<td>91.0%<br>NA</td>
<td>34.79</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6bf9b66fa3f263ca2175dcb5f6d0a658581e1dfb">6bf9b66fa3f263ca2175dcb5f6d0a658581e1dfb</a><br>2024-05-20 12:08:23<br>[SYCL] Update SYCL upscale operation<br>AidanBeltonS  Log: <a href="./log/6bf9b66fa3f263ca2175dcb5f6d0a658581e1dfb">log</a></td>
<td>91.0%<br>NA</td>
<td>34.82</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9a17ab914b0aa7353389c656a3f2a0f086726868">9a17ab914b0aa7353389c656a3f2a0f086726868</a><br>2024-05-15 13:26:30<br>Add missing "<br>AidanBeltonS  Log: <a href="./log/9a17ab914b0aa7353389c656a3f2a0f086726868">log</a></td>
<td>91.0%<br>NA</td>
<td>34.85</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/48aa8fd1f213a69b41569f809cc954f24dbc4366">48aa8fd1f213a69b41569f809cc954f24dbc4366</a><br>2024-05-15 03:52:33<br>ggml : add <code>ggml_upscale_ext</code><br>John Balis  Log: <a href="./log/48aa8fd1f213a69b41569f809cc954f24dbc4366">log</a></td>
<td>Execute_Err<br>NA</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 29: <br>./build/bin/main: No such file or direct<br>', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/948f4ec7c5bff92b18e63303f2b2d1645bccd943">948f4ec7c5bff92b18e63303f2b2d1645bccd943</a><br>2024-05-13 18:11:26<br>[SYCL] rm wait<br>Neo Zhang  Log: <a href="./log/948f4ec7c5bff92b18e63303f2b2d1645bccd943">log</a></td>
<td>91.0%<br>NA</td>
<td>34.79</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9cb317f77e53067f7a138cc89ef7657148eae8e6">9cb317f77e53067f7a138cc89ef7657148eae8e6</a><br>2024-05-11 10:32:41<br>ggml : full ALiBi support<br>Georgi Gerganov  Log: <a href="./log/9cb317f77e53067f7a138cc89ef7657148eae8e6">log</a></td>
<td>91.0%<br>NA</td>
<td>34.18</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8c570c9496212073079476651c7517c02581101f">8c570c9496212073079476651c7517c02581101f</a><br>2024-05-10 01:32:15<br>Minor arithmetic improvement to mmvq wra<br>pper kernel<br>Ouadie EL FAROUKI  Log: <a href="./log/8c570c9496212073079476651c7517c02581101f">log</a></td>
<td>91.0%<br>NA</td>
<td>34.16</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/04976db7a819fcf8bfefbfc09a3344210b79dd27">04976db7a819fcf8bfefbfc09a3344210b79dd27</a><br>2024-05-07 17:20:33<br>docs: fix typos<br>omahs  Log: <a href="./log/04976db7a819fcf8bfefbfc09a3344210b79dd27">log</a></td>
<td>90.0%<br>NA</td>
<td>34.15</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9c67c2773d4b706cf71d70ecf4aa180b62501960">9c67c2773d4b706cf71d70ecf4aa180b62501960</a><br>2024-04-30 12:16:08<br>ggml : add Flash Attention<br>Georgi Gerganov  Log: <a href="./log/9c67c2773d4b706cf71d70ecf4aa180b62501960">log</a></td>
<td>90.0%<br>NA</td>
<td>34.1</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b8a7a5a90fd3187175d84227dad705ade395ba46">b8a7a5a90fd3187175d84227dad705ade395ba46</a><br>2024-04-29 17:02:45<br>build<br>Olivier Chafik  Log: <a href="./log/b8a7a5a90fd3187175d84227dad705ade395ba46">log</a></td>
<td>90.0%<br>NA</td>
<td>34.19</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ce023f6f2ff34fbe840e32e65d443d2fed7393de">ce023f6f2ff34fbe840e32e65d443d2fed7393de</a><br>2024-04-28 22:40:31<br>add device version in device list<br>Neo Zhang  Log: <a href="./log/ce023f6f2ff34fbe840e32e65d443d2fed7393de">log</a></td>
<td>91.0%<br>NA</td>
<td>34.16</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/4e96a812b3ce7322a29a3008db2ed73d9087b176">4e96a812b3ce7322a29a3008db2ed73d9087b176</a><br>2024-04-23 02:53:18<br>[SYCL] Windows default build instruction<br>s without -DLLAMA_SYCL_F16 flag activate<br>d<br>Anas Ahouzi  Log: <a href="./log/4e96a812b3ce7322a29a3008db2ed73d9087b176">log</a></td>
<td>91.0%<br>NA</td>
<td>34.21</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/bca40e98149c7b673558ddd7a3ebeffef789349d">bca40e98149c7b673558ddd7a3ebeffef789349d</a><br>2024-04-19 09:16:31<br>fix wrong parameter in .html in readme-syc<br>l.html<br>Neo Zhang  Log: <a href="./log/bca40e98149c7b673558ddd7a3ebeffef789349d">log</a></td>
<td>91.0%<br>NA</td>
<td>34.21</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0d56246f4b9764158525d894b96606f6163c53a8">0d56246f4b9764158525d894b96606f6163c53a8</a><br>2024-04-18 15:18:48<br>ggml : group all experts in a single ggm<br>l_mul_mat_id<br>slaren  Log: <a href="./log/0d56246f4b9764158525d894b96606f6163c53a8">log</a></td>
<td>91.0%<br>NA</td>
<td>34.2</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/17e98d4c96a583d420f12046bc92102381dbd28e">17e98d4c96a583d420f12046bc92102381dbd28e</a><br>2024-04-15 17:12:26<br>fix mul_mat_id<br>Neo Zhang Jianyu  Log: <a href="./log/17e98d4c96a583d420f12046bc92102381dbd28e">log</a></td>
<td>96.0%<br>2207/2253</td>
<td>25.13</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/de17e3f7455dc7fd298cc61d86798533b9ca7a29">de17e3f7455dc7fd298cc61d86798533b9ca7a29</a><br>2024-04-14 10:42:29<br>fix memcpy<br>Neo Zhang Jianyu  Log: <a href="./log/de17e3f7455dc7fd298cc61d86798533b9ca7a29">log</a></td>
<td>96.0%<br>NA</td>
<td>25.15</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5c4d767ac028c0f9c31cba3fceaf765c6097abfc">5c4d767ac028c0f9c31cba3fceaf765c6097abfc</a><br>2024-04-12 10:52:36<br>chore: Fix markdown warnings<br>Rene Leonhardt  Log: <a href="./log/5c4d767ac028c0f9c31cba3fceaf765c6097abfc">log</a></td>
<td>96.0%<br>1075/1665</td>
<td>25.21</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/87fb5b4234d4b9c56ac94cf7aa229c8fd7defdb0">87fb5b4234d4b9c56ac94cf7aa229c8fd7defdb0</a><br>2024-04-08 13:56:01<br>remove row=1 cond<br>Abhilash Maj.htmler  Log: <a href="./log/87fb5b4234d4b9c56ac94cf7aa229c8fd7defdb0">log</a></td>
<td>96.0%<br>1076/1665</td>
<td>25.28</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d4f220a5ccdc6308173c1a31fad21d7c3fbc96c1">d4f220a5ccdc6308173c1a31fad21d7c3fbc96c1</a><br>2024-04-07 10:55:59<br>support/fix OPs GGML_TYPE_IQ4_NL, GGML_T<br>YPE_IQ4_XS, GGML_TYPE_IQ3_XXS, GGML_TYPE<br>_IQ3_S, GGML_TYPE_IQ2_XXS, GGML_TYPE_IQ2<br>_XS, GGML_TYPE_IQ2_S, GGML_TYPE_IQ1_S, G<br>GML_TYPE_IQ1_M<br>Neo Zhang Jianyu  Log: <a href="./log/d4f220a5ccdc6308173c1a31fad21d7c3fbc96c1">log</a></td>
<td>96.0%<br>1076/1665</td>
<td>25.25</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9472bce30800a581071478a839bf93abf404c893">9472bce30800a581071478a839bf93abf404c893</a><br>2024-04-07 07:05:40<br>Run make to build the project<br>limitedAtonement  Log: <a href="./log/9472bce30800a581071478a839bf93abf404c893">log</a></td>
<td>96.0%<br>1076/1665</td>
<td>25.22</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/1b496a745c315022df2d919374052e6004ced8d3">1b496a745c315022df2d919374052e6004ced8d3</a><br>2024-04-05 14:35:06<br>[SYCL] Fixed minor bug when enabling FP1<br>6 for non intel targets<br>Ouadie EL FAROUKI  Log: <a href="./log/1b496a745c315022df2d919374052e6004ced8d3">log</a></td>
<td>95.0%<br>NA</td>
<td>25.17</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a74401f0e5ebb15fa4d8b6619d1baa6ea9179123">a74401f0e5ebb15fa4d8b6619d1baa6ea9179123</a><br>2024-04-04 10:30:02<br>Correct README link<br>limitedAtonement  Log: <a href="./log/a74401f0e5ebb15fa4d8b6619d1baa6ea9179123">log</a></td>
<td>95.0%<br>NA</td>
<td>25.23</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/52604860f93063ef98863921da697576af1c7665">52604860f93063ef98863921da697576af1c7665</a><br>2024-04-03 10:34:40<br>[SYCL] Disable iqx on windows as WA<br>Meng, Hengyu  Log: <a href="./log/52604860f93063ef98863921da697576af1c7665">log</a></td>
<td>95.0%<br>NA</td>
<td>25.17</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5106ef482c65ac60ac14da9a68c7b37bca4c6993">5106ef482c65ac60ac14da9a68c7b37bca4c6993</a><br>2024-03-28 16:01:47<br>[SYCL] Revisited &amp; updated SYCL build do<br>cumentation<br>Ouadie EL FAROUKI  Log: <a href="./log/5106ef482c65ac60ac14da9a68c7b37bca4c6993">log</a></td>
<td>95.0%<br>NA</td>
<td>25.21</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/25f4a613c4ed6451162a87cb90be10d610b49f0f">25f4a613c4ed6451162a87cb90be10d610b49f0f</a><br>2024-03-28 08:55:24<br>[SYCL] fix set main gpu crash<br>Neo Zhang Jianyu  Log: <a href="./log/25f4a613c4ed6451162a87cb90be10d610b49f0f">log</a></td>
<td>95.0%<br>NA</td>
<td>25.2</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e82f9e2b833d88cd2b30123ef57346c2cb8abd99">e82f9e2b833d88cd2b30123ef57346c2cb8abd99</a><br>2024-03-27 08:16:40<br>[SYCL] Fix batched impl for NVidia GPU<br>AidanBeltonS  Log: <a href="./log/e82f9e2b833d88cd2b30123ef57346c2cb8abd99">log</a></td>
<td>95.0%<br>NA</td>
<td>25.2</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/557410b8f06380560155ac7fcb8316d71ddc9837">557410b8f06380560155ac7fcb8316d71ddc9837</a><br>2024-03-26 10:46:41<br>llama : greatly reduce output buffer mem<br>ory usage<br>compilade  Log: <a href="./log/557410b8f06380560155ac7fcb8316d71ddc9837">log</a></td>
<td>95.0%<br>NA</td>
<td>25.2</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/95ad616cddda50273e955bfe192328acd9aa4896">95ad616cddda50273e955bfe192328acd9aa4896</a><br>2024-03-25 15:52:41<br>[SYCL] fix SYCL backend build on windows<br> is break by LOG<br>Neo Zhang Jianyu  Log: <a href="./log/95ad616cddda50273e955bfe192328acd9aa4896">log</a></td>
<td>95.0%<br>NA</td>
<td>24.5</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ddf65685105a39a57b1e7f80c3aa502a6313af24">ddf65685105a39a57b1e7f80c3aa502a6313af24</a><br>2024-03-24 12:04:25<br>[SYCL] offload op<br>Meng, Hengyu  Log: <a href="./log/ddf65685105a39a57b1e7f80c3aa502a6313af24">log</a></td>
<td>95.0%<br>NA</td>
<td>24.41</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/59c17f02de8fdf7b084d6100b875b7e2bc07a83b">59c17f02de8fdf7b084d6100b875b7e2bc07a83b</a><br>2024-03-22 15:19:37<br>add blog link<br>Neo Zhang Jianyu  Log: <a href="./log/59c17f02de8fdf7b084d6100b875b7e2bc07a83b">log</a></td>
<td>95.0%<br>NA</td>
<td>24.52</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f372c49ccdc561ab96fb3c7d2b7cbc0f89a4b359">f372c49ccdc561ab96fb3c7d2b7cbc0f89a4b359</a><br>2024-03-21 11:52:35<br>Corrected typo to wrong file<br>semidark  Log: <a href="./log/f372c49ccdc561ab96fb3c7d2b7cbc0f89a4b359">log</a></td>
<td>95.0%<br>NA</td>
<td>24.46</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/c5b8595e3f4f4ed319ef71c9c9d868d1b7a27626">c5b8595e3f4f4ed319ef71c9c9d868d1b7a27626</a><br>2024-03-21 06:10:52<br>Add nvidia and .html backends<br>AidanBeltonS  Log: <a href="./log/c5b8595e3f4f4ed319ef71c9c9d868d1b7a27626">log</a></td>
<td>95.0%<br>NA</td>
<td>24.45</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6c0b287748327741b113d7d6018b68c63039b1c5">6c0b287748327741b113d7d6018b68c63039b1c5</a><br>2024-03-20 11:21:41<br>update readme sycl for new update<br>Neo Zhang Jianyu  Log: <a href="./log/6c0b287748327741b113d7d6018b68c63039b1c5">log</a></td>
<td>95.0%<br>NA</td>
<td>24.43</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/d26e8b669dbf1f5f5a0afe4d2d885e86cf566302">d26e8b669dbf1f5f5a0afe4d2d885e86cf566302</a><br>2024-03-20 08:28:49<br>increase igpu cluster limit<br>Abhilash Maj.htmler  Log: <a href="./log/d26e8b669dbf1f5f5a0afe4d2d885e86cf566302">log</a></td>
<td>95.0%<br>NA</td>
<td>24.5</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2bf8d0f7c4cc1235755ad06961ca761e458c5e55">2bf8d0f7c4cc1235755ad06961ca761e458c5e55</a><br>2024-03-18 11:03:04<br>backend : offload large batches to GPU<br>slaren  Log: <a href="./log/2bf8d0f7c4cc1235755ad06961ca761e458c5e55">log</a></td>
<td>95.0%<br>NA</td>
<td>24.53</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/46acb3676718b983157058aecf729a2064fc7d34">46acb3676718b983157058aecf729a2064fc7d34</a><br>2024-03-15 18:53:53<br>fix set main gpu error<br>Neo Zhang Jianyu  Log: <a href="./log/46acb3676718b983157058aecf729a2064fc7d34">log</a></td>
<td>95.0%<br>NA</td>
<td>24.44</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/753e36f650fa2a5869f89188d9ee745dc74cf14b">753e36f650fa2a5869f89188d9ee745dc74cf14b</a><br>2024-03-15 09:26:20<br>[SYCL] Fix non-intel device selection<br>AidanBeltonS  Log: <a href="./log/753e36f650fa2a5869f89188d9ee745dc74cf14b">log</a></td>
<td>95.0%<br>NA</td>
<td>24.51</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/f30ea47a87ed4446ad55adb265755dc9102956a2">f30ea47a87ed4446ad55adb265755dc9102956a2</a><br>2024-03-13 18:54:21<br>llama : add pipeline parallelism support<br><br>slaren  Log: <a href="./log/f30ea47a87ed4446ad55adb265755dc9102956a2">log</a></td>
<td>95.0%<br>NA</td>
<td>24.44</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b3d978600f07f22e94f2e797f18a8b5f6df23c89">b3d978600f07f22e94f2e797f18a8b5f6df23c89</a><br>2024-03-13 13:17:54<br>Update get version<br>AidanBeltonS  Log: <a href="./log/b3d978600f07f22e94f2e797f18a8b5f6df23c89">log</a></td>
<td>95.0%<br>1595/1595</td>
<td>24.5</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8030da7afea2d89f997aeadbd14183d399a017b9">8030da7afea2d89f997aeadbd14183d399a017b9</a><br>2024-03-12 14:27:20<br>ggml : reuse quantum structs across back<br>ends<br>Georgi Gerganov  Log: <a href="./log/8030da7afea2d89f997aeadbd14183d399a017b9">log</a></td>
<td>95.0%<br>1595/1595</td>
<td>24.53</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/48358b2e5b3983c41ba7e61a493e84d3901dc7b9">48358b2e5b3983c41ba7e61a493e84d3901dc7b9</a><br>2024-03-12 11:15:05<br>sycl : update IQ1_S kernels<br>Georgi Gerganov  Log: <a href="./log/48358b2e5b3983c41ba7e61a493e84d3901dc7b9">log</a></td>
<td>95.0%<br>1595/1595</td>
<td>24.51</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ef3ced26a3817d92890b97b83acaeb018ade02d0">ef3ced26a3817d92890b97b83acaeb018ade02d0</a><br>2024-03-11 10:27:56<br>[SYCL] Add q3_s and q1_s<br>Abhilash Maj.htmler  Log: <a href="./log/ef3ced26a3817d92890b97b83acaeb018ade02d0">log</a></td>
<td>95.0%<br>1595/1595</td>
<td>24.48</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/3814a07392d2bdc22911652bc7c2f9bdb0ce042e">3814a07392d2bdc22911652bc7c2f9bdb0ce042e</a><br>2024-03-11 01:13:57<br>[SYCL] Add support for SYCL Nvidia targe<br>t<br>AidanBeltonS  Log: <a href="./log/3814a07392d2bdc22911652bc7c2f9bdb0ce042e">log</a></td>
<td>100.0%<br>NA</td>
<td>24.63</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8a3012a4ad08112bb3dc3f1399afec4e93780c44">8a3012a4ad08112bb3dc3f1399afec4e93780c44</a><br>2024-03-09 12:47:57<br>ggml : add ggml-common.h to deduplicate <br>shared code<br>Georgi Gerganov  Log: <a href="./log/8a3012a4ad08112bb3dc3f1399afec4e93780c44">log</a></td>
<td>100.0%<br>NA</td>
<td>24.57</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/89fb735fcfd21781a8194b211cf32824beb3f71f">89fb735fcfd21781a8194b211cf32824beb3f71f</a><br>2024-03-07 19:14:49<br>Revert "[SYCL] fix error when set main g<br>pu to non-zero<br>Neo Zhang Jianyu  Log: <a href="./log/89fb735fcfd21781a8194b211cf32824beb3f71f">log</a></td>
<td>95.0%<br>1592/1595</td>
<td>24.61</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ceca1aef0738b57951cd12c603c3477e75312dec">ceca1aef0738b57951cd12c603c3477e75312dec</a><br>2024-03-07 16:34:31<br>[SYCL] fix error when set main gpu to no<br>n-zero<br>Neo Zhang Jianyu  Log: <a href="./log/ceca1aef0738b57951cd12c603c3477e75312dec">log</a></td>
<td>95.0%<br>1593/1595</td>
<td>24.61</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/8ced9f7e3225adb8501e9821ed1bbd92e3a5c7ae">8ced9f7e3225adb8501e9821ed1bbd92e3a5c7ae</a><br>2024-03-06 12:08:32<br>add wait<br>Neo Zhang Jianyu  Log: <a href="./log/8ced9f7e3225adb8501e9821ed1bbd92e3a5c7ae">log</a></td>
<td>95.0%<br>1594/1595</td>
<td>24.59</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/21b08674331e1ea1b599f17c5ca91f0ed173be31">21b08674331e1ea1b599f17c5ca91f0ed173be31</a><br>2024-03-05 16:08:35<br>[SYCL] fix mul_mat fault in CI/unit-test<br><br>Neo Zhang Jianyu  Log: <a href="./log/21b08674331e1ea1b599f17c5ca91f0ed173be31">log</a></td>
<td>100.0%<br>NA</td>
<td>32.79</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/9fa262734733573fa629ffc97dfcb971fe3f4832">9fa262734733573fa629ffc97dfcb971fe3f4832</a><br>2024-03-04 10:05:42<br>ggml : introduce ggml_status<br>Michael Podvitskiy  Log: <a href="./log/9fa262734733573fa629ffc97dfcb971fe3f4832">log</a></td>
<td>95.0%<br>1595/1595</td>
<td>33.02</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/715641391dda1ff9762dc5d99d9a30acce99f2c6">715641391dda1ff9762dc5d99d9a30acce99f2c6</a><br>2024-03-02 19:49:30<br>Support multiple GPUs<br>Neo Zhang Jianyu  Log: <a href="./log/715641391dda1ff9762dc5d99d9a30acce99f2c6">log</a></td>
<td>95.0%<br>1593/1593</td>
<td>33.02</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/38d152160898b0173ffe4dc7df5daadcbd2eceb0">38d152160898b0173ffe4dc7df5daadcbd2eceb0</a><br>2024-03-01 07:36:47<br>[SYCL] Use batched mul_mat pathway<br>AidanBeltonS  Log: <a href="./log/38d152160898b0173ffe4dc7df5daadcbd2eceb0">log</a></td>
<td>95.0%<br>1593/1593</td>
<td>33.02</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e849078c6e09e72fdd2c95ba61f5fba9a7b2d9ef">e849078c6e09e72fdd2c95ba61f5fba9a7b2d9ef</a><br>2024-02-26 14:02:11<br>[SYCL] Add support for soft_max ALiBi<br>AidanBeltonS  Log: <a href="./log/e849078c6e09e72fdd2c95ba61f5fba9a7b2d9ef">log</a></td>
<td>95.0%<br>1469/1469</td>
<td>33.0</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/ab336a9d5e5352ecdcdf4c12d2d54cf4ef82ce31">ab336a9d5e5352ecdcdf4c12d2d54cf4ef82ce31</a><br>2024-02-25 12:09:09<br>code : normalize enum names<br>Georgi Gerganov  Log: <a href="./log/ab336a9d5e5352ecdcdf4c12d2d54cf4ef82ce31">log</a></td>
<td>95.0%<br>1469/1469</td>
<td>33.0</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/5f706718566e3a5147916dc381f3b99de0ffad47">5f706718566e3a5147916dc381f3b99de0ffad47</a><br>2024-02-24 11:27:36<br>Introduce backend GUIDs<br>UEXTM.com  Log: <a href="./log/5f706718566e3a5147916dc381f3b99de0ffad47">log</a></td>
<td>95.0%<br>1593/1593</td>
<td>33.07</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/88c46cbdac05cebd936511b1d3c74112e721615f">88c46cbdac05cebd936511b1d3c74112e721615f</a><br>2024-02-21 17:52:06<br>[SYCL] conext add name<br>Meng, Hengyu  Log: <a href="./log/88c46cbdac05cebd936511b1d3c74112e721615f">log</a></td>
<td>95.0%<br>1407/1407</td>
<td>32.98</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b9111bd209c7b11b0592450a6ed2e0ca545b2c84">b9111bd209c7b11b0592450a6ed2e0ca545b2c84</a><br>2024-02-20 07:01:25<br>Update ggml_sycl_op_mul_mat_vec_q<br>AidanBeltonS  Log: <a href="./log/b9111bd209c7b11b0592450a6ed2e0ca545b2c84">log</a></td>
<td>95.0%<br>1199/1345</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 17: <br>1521970 Segmentation fault      (core du<br>', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/13e2c771aa4212cd5405cf310203848d50f7f859">13e2c771aa4212cd5405cf310203848d50f7f859</a><br>2024-02-19 14:45:18<br>cmake : remove obsolete sycl compile fla<br>gs<br>Abhilash Maj.htmler  Log: <a href="./log/13e2c771aa4212cd5405cf310203848d50f7f859">log</a></td>
<td>95.0%<br>1345/1345</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 17: <br>2467829 Segmentation fault      (core du<br>', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/70d45af0efce9ed360e1858b827989d971dd9caf">70d45af0efce9ed360e1858b827989d971dd9caf</a><br>2024-02-19 02:37:10<br>readme : fix typo in README-sycl.html<br>valiray  Log: <a href="./log/70d45af0efce9ed360e1858b827989d971dd9caf">log</a></td>
<td>95.0%<br>1345/1345</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 17: <br>1994862 Segmentation fault      (core du<br>', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/43fe07c1a4f3a58612e1d9543f7c6b556710f5d0">43fe07c1a4f3a58612e1d9543f7c6b556710f5d0</a><br>2024-02-12 20:22:05<br>ggml-sycl: Replace 3d ops with macro<br>Abhilash Maj.htmler  Log: <a href="./log/43fe07c1a4f3a58612e1d9543f7c6b556710f5d0">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>NA</td>
<td>tg=NA<br>pp=NA</td>
<td>('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 17: <br>2937155 Segmentation fault      (core du<br>', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6e99f2a04f1871d637dd77eb4d81de31a5510253">6e99f2a04f1871d637dd77eb4d81de31a5510253</a><br>2024-02-08 22:39:10<br>Fix f16_sycl cpy call from Arc<br>Abhilash Maj.htmler  Log: <a href="./log/6e99f2a04f1871d637dd77eb4d81de31a5510253">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>32.92</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/10afa6f1d11ebc9fcc1085f468170002cbf6e2b5">10afa6f1d11ebc9fcc1085f468170002cbf6e2b5</a><br>2024-02-07 18:16:55<br>[SYCL] update install make by w64devkit<br>Neo Zhang Jianyu  Log: <a href="./log/10afa6f1d11ebc9fcc1085f468170002cbf6e2b5">log</a></td>
<td>Execute_Err<br>NA</td>
<td>19.04</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/4833ac209da6a427de64f97e8f403dcdc5de6bc3">4833ac209da6a427de64f97e8f403dcdc5de6bc3</a><br>2024-02-05 07:08:24<br>[SYCL] Fix cpy with dims of 3<br>AidanBeltonS  Log: <a href="./log/4833ac209da6a427de64f97e8f403dcdc5de6bc3">log</a></td>
<td>Execute_Err<br>NA</td>
<td>32.97</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/a305dba8ff642e57f538f42010868fe0bc5262a1">a305dba8ff642e57f538f42010868fe0bc5262a1</a><br>2024-02-03 08:11:37<br>Fix im2col with 32fp<br>AidanBeltonS  Log: <a href="./log/a305dba8ff642e57f538f42010868fe0bc5262a1">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>33.04</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/e805f0fa9951081ce0a86378a7aa52b6f636b82d">e805f0fa9951081ce0a86378a7aa52b6f636b82d</a><br>2024-02-02 15:54:14<br>[SYCL] get MAX_MEM_ALLOC from device pro<br>perty<br>Meng, Hengyu  Log: <a href="./log/e805f0fa9951081ce0a86378a7aa52b6f636b82d">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>33.03</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/af3ba5d94627d337e32a95129e31a3064c459f6b">af3ba5d94627d337e32a95129e31a3064c459f6b</a><br>2024-02-02 15:53:27<br>[SYCL] update guide of SYCL backend<br>Neo Zhang Jianyu  Log: <a href="./log/af3ba5d94627d337e32a95129e31a3064c459f6b">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>33.04</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/6b91b1e0a92ac2e4e269eec6361ca53a61ced6c6">6b91b1e0a92ac2e4e269eec6361ca53a61ced6c6</a><br>2024-02-02 08:56:31<br>docker : add build for SYCL, Vulkan + up<br>date readme<br>Xuan Son Nguyen  Log: <a href="./log/6b91b1e0a92ac2e4e269eec6361ca53a61ced6c6">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>33.03</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b05102fe8cfa9893851c6bf6efd15cdc20b6afa2">b05102fe8cfa9893851c6bf6efd15cdc20b6afa2</a><br>2024-02-02 08:39:48<br>Tidy ggml-sycl<br>AidanBeltonS  Log: <a href="./log/b05102fe8cfa9893851c6bf6efd15cdc20b6afa2">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>33.05</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/128dcbd3c9c4b12f42b560a4430427d7b2828628">128dcbd3c9c4b12f42b560a4430427d7b2828628</a><br>2024-02-02 03:48:53<br>add --no-mmap in llama-bench<br>Neo Zhang Jianyu  Log: <a href="./log/128dcbd3c9c4b12f42b560a4430427d7b2828628">log</a></td>
<td>95.0%<br>1389/1389</td>
<td>33.01</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/b2b9f025e7821e78bd501d75d01838c26de07a57">b2b9f025e7821e78bd501d75d01838c26de07a57</a><br>2024-01-31 21:04:46<br>format license text, restore apache lice<br>nse by legal suggestion<br>Neo Zhang Jianyu  Log: <a href="./log/b2b9f025e7821e78bd501d75d01838c26de07a57">log</a></td>
<td>95.0%<br>1260/1260</td>
<td>33.04</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/01684139c352561840ae55ec627ab58abc3e06ab">01684139c352561840ae55ec627ab58abc3e06ab</a><br>2024-01-31 10:38:07<br>support SYCL backend windows build<br>Neo Zhang Jianyu  Log: <a href="./log/01684139c352561840ae55ec627ab58abc3e06ab">log</a></td>
<td>95.0%<br>1260/1260</td>
<td>32.67</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/0f648573dde61c510560f68244f70ece7e60d8c1">0f648573dde61c510560f68244f70ece7e60d8c1</a><br>2024-01-28 21:26:23<br>ggml : add unified SYCL backend for Inte<br>l GPUs<br>Abhilash Maj.htmler  Log: <a href="./log/0f648573dde61c510560f68244f70ece7e60d8c1">log</a></td>
<td>95.0%<br>1182/1182</td>
<td>32.64</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
<tr>
<td><a href="https://github.com/ggerganov/llama.cpp/commit/2307523d322af762ae06648b29ec5a9eb1c73032">2307523d322af762ae06648b29ec5a9eb1c73032</a><br>2024-01-28 18:03:59<br>ggml : add Vulkan backend<br>0cc4m  Log: <a href="./log/2307523d322af762ae06648b29ec5a9eb1c73032">log</a></td>
<td>95.0%<br>1182/1182</td>
<td>32.6</td>
<td>tg=NA<br>pp=NA</td>
<td>('ok', 'pass', 0)</td>
<td>0/0<br>2024.1.0</td>
</tr>
</tbody>
</table></section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Neo Zhang Jianyu.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>