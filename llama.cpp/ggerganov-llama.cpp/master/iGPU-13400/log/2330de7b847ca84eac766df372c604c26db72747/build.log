 
:: WARNING: setvars.sh has already been run. Skipping re-execution.
   To force a re-execution of setvars.sh, use the '--force' option.
   Using '--force' can result in excessive use of your environment variables.
  
usage: source setvars.sh [--force] [--config=file] [--help] [...]
  --force        Force setvars.sh to re-run, doing so may overload environment.
  --config=file  Customize env vars using a setvars.sh configuration file.
  --help         Display this help message and exit.
  ...            Additional args are passed to individual env/vars.sh scripts
                 and should follow this script's arguments.
  
  Some POSIX shells do not accept command-line options. In that case, you can pass
  command-line options via the SETVARS_ARGS environment variable. For example:
  
  $ SETVARS_ARGS="--config=config.txt" ; export SETVARS_ARGS
  $ . path/to/setvars.sh
  
  The SETVARS_ARGS environment variable is cleared on exiting setvars.sh.
  
The oneAPI toolkits no longer support 32-bit libraries, starting with the 2025.0 toolkit release. See the oneAPI release notes for more details.
  
-- The C compiler identification is IntelLLVM 2025.2.1
-- The CXX compiler identification is IntelLLVM 2025.2.1
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /opt/intel/oneapi/compiler/2025.2/bin/icx - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /opt/intel/oneapi/compiler/2025.2/bin/icpx - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
CMAKE_BUILD_TYPE=Release
-- Found Git: /usr/bin/git (found version "2.43.0") 
-- The ASM compiler identification is IntelLLVM
-- Found assembler: /opt/intel/oneapi/compiler/2025.2/bin/icx
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success
-- Found Threads: TRUE  
-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF
-- CMAKE_SYSTEM_PROCESSOR: x86_64
-- GGML_SYSTEM_ARCH: x86
-- Including CPU backend
-- Found OpenMP_C: -fiopenmp (found version "5.1") 
-- Found OpenMP_CXX: -fiopenmp (found version "5.1") 
-- Found OpenMP: TRUE (found version "5.1")  
-- x86 detected
-- Adding CPU backend variant ggml-cpu: -march=native 
-- GGML_SYCL_TARGET=INTEL
-- Performing Test SUPPORTS_SYCL
-- Performing Test SUPPORTS_SYCL - Success
-- Using oneAPI Release SYCL compiler (icpx).
-- SYCL found
-- SYCL Compiler version: 20250201
-- SYCL_INCLUDE_DIR: /opt/intel/oneapi/compiler/2025.2/include
-- SYCL_LIBRARY=/opt/intel/oneapi/compiler/2025.2/lib/libsycl.so
-- Found IntelSYCL: /opt/intel/oneapi/compiler/2025.2/include (found version "202012") 
-- Found oneDNN: /opt/intel/oneapi/dnnl/2025.2/lib/libdnnl.so.3.8
-- MKL_VERSION: 2025.2.0
-- MKL_ROOT: /opt/intel/oneapi/mkl/2025.2
-- MKL_ARCH: intel64
-- MKL_SYCL_LINK: None, set to ` dynamic` by default
-- MKL_LINK: None, set to ` dynamic` by default
-- MKL_SYCL_INTERFACE_FULL: None, set to ` intel_ilp64` by default
-- MKL_INTERFACE_FULL: None, set to ` intel_ilp64` by default
-- MKL_SYCL_THREADING: None, set to ` tbb_thread` by default
-- MKL_THREADING: None, set to ` intel_thread` by default
-- MKL_SYCL_MPI: None, set to ` intelmpi` by default
-- MKL_MPI: None, set to ` intelmpi` by default
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_scalapack_ilp64.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_cdft_core.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_intel_ilp64.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_intel_thread.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_core.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_blacs_intelmpi_ilp64.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_distributed_dft.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_blas.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_lapack.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_dft.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_sparse.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_data_fitting.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_rng.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_stats.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_vm.so
-- Found /opt/intel/oneapi/mkl/2025.2/lib/libmkl_tbb_thread.so
-- Found /opt/intel/oneapi/compiler/2025.2/lib/libiomp5.so
-- Including SYCL backend
-- ggml version: 0.9.4-dirty
-- ggml commit:  2330de7b8
-- Configuring done (1.8s)
-- Generating done (0.1s)
-- Build files have been written to: /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build
Change Dir: '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'

Run Build Command(s): /usr/bin/cmake -E env VERBOSE=1 /usr/bin/gmake -f Makefile -j
/usr/bin/cmake -S/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp -B/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build --check-build-system CMakeFiles/Makefile.cmake 0
/usr/bin/cmake -E cmake_progress_start /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/CMakeFiles /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build//CMakeFiles/progress.marks
/usr/bin/gmake  -f CMakeFiles/Makefile2 all
gmake[1]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-base.dir/build.make ggml/src/CMakeFiles/ggml-base.dir/depend
/usr/bin/gmake  -f common/CMakeFiles/build_info.dir/build.make common/CMakeFiles/build_info.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha256.dir/build.make examples/gguf-hash/CMakeFiles/sha256.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/xxhash.dir/build.make examples/gguf-hash/CMakeFiles/xxhash.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha1.dir/build.make examples/gguf-hash/CMakeFiles/sha1.dir/depend
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-llava-cli.dir/build.make tools/mtmd/CMakeFiles/llama-llava-cli.dir/depend
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/build.make tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/depend
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/build.make tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/depend
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash/CMakeFiles/sha256.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash/CMakeFiles/xxhash.dir/DependInfo.cmake "--color="
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/build.make tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/depend
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/CMakeFiles/ggml-base.dir/DependInfo.cmake "--color="
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/common /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/common /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/common/CMakeFiles/build_info.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash/CMakeFiles/sha1.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd/CMakeFiles/llama-llava-cli.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha1.dir/build.make examples/gguf-hash/CMakeFiles/sha1.dir/build
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-base.dir/build.make ggml/src/CMakeFiles/ggml-base.dir/build
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/sha256.dir/build.make examples/gguf-hash/CMakeFiles/sha256.dir/build
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/xxhash.dir/build.make examples/gguf-hash/CMakeFiles/xxhash.dir/build
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-llava-cli.dir/build.make tools/mtmd/CMakeFiles/llama-llava-cli.dir/build
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/build.make tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f common/CMakeFiles/build_info.dir/build.make common/CMakeFiles/build_info.dir/build
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/build.make tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/build
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/build.make tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o
[  1%] Building C object examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o
[  1%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o
[  1%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o
[  4%] Building C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o
[  4%] Building C object examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o
[  4%] Building CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o
[  4%] Building CXX object tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o -MF CMakeFiles/ggml-base.dir/gguf.cpp.o.d -o CMakeFiles/ggml-base.dir/gguf.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/gguf.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o -MF CMakeFiles/ggml-base.dir/ggml-alloc.c.o.d -o CMakeFiles/ggml-base.dir/ggml-alloc.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-alloc.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o -MF CMakeFiles/ggml-base.dir/ggml.c.o.d -o CMakeFiles/ggml-base.dir/ggml.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -MF CMakeFiles/ggml-base.dir/ggml-backend.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml-backend.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-backend.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash && /opt/intel/oneapi/compiler/2025.2/bin/icx  -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT examples/gguf-hash/CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o -MF CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o.d -o CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps/xxhash/xxhash.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o -MF CMakeFiles/ggml-base.dir/ggml.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml.cpp
[  4%] Building CXX object tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o
[  4%] Building C object examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -MF CMakeFiles/ggml-base.dir/ggml-opt.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml-opt.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-opt.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /opt/intel/oneapi/compiler/2025.2/bin/icpx   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT tools/mtmd/CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o -MF CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o.d -o CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd/deprecation-warning.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash && /opt/intel/oneapi/compiler/2025.2/bin/icx  -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT examples/gguf-hash/CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -MF CMakeFiles/sha256.dir/deps/sha256/sha256.c.o.d -o CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps/sha256/sha256.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -MF CMakeFiles/ggml-base.dir/ggml-threading.cpp.o.d -o CMakeFiles/ggml-base.dir/ggml-threading.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-threading.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icx -DGGML_BUILD -DGGML_COMMIT=\"2330de7b8\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4-dirty\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o -MF CMakeFiles/ggml-base.dir/ggml-quants.c.o.d -o CMakeFiles/ggml-base.dir/ggml-quants.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-quants.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /opt/intel/oneapi/compiler/2025.2/bin/icpx   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT tools/mtmd/CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o -MF CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o.d -o CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd/deprecation-warning.cpp
[  4%] Building CXX object common/CMakeFiles/build_info.dir/build-info.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash && /opt/intel/oneapi/compiler/2025.2/bin/icx  -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps -O3 -DNDEBUG -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -w -MD -MT examples/gguf-hash/CMakeFiles/sha1.dir/deps/sha1/sha1.c.o -MF CMakeFiles/sha1.dir/deps/sha1/sha1.c.o.d -o CMakeFiles/sha1.dir/deps/sha1/sha1.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps/sha1/sha1.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/common && /opt/intel/oneapi/compiler/2025.2/bin/icpx   -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT common/CMakeFiles/build_info.dir/build-info.cpp.o -MF CMakeFiles/build_info.dir/build-info.cpp.o.d -o CMakeFiles/build_info.dir/build-info.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/common/build-info.cpp
[  4%] Building CXX object tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o
[  4%] Building CXX object tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /opt/intel/oneapi/compiler/2025.2/bin/icpx   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT tools/mtmd/CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o -MF CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o.d -o CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd/deprecation-warning.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /opt/intel/oneapi/compiler/2025.2/bin/icpx   -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT tools/mtmd/CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o -MF CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o.d -o CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/tools/mtmd/deprecation-warning.cpp
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-alloc.c:1:1: warning: ISO C requires a translation unit to contain at least one declaration [-Wempty-translation-unit]
1 warning generated.
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  4%] Built target build_info
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  4%] Built target sha1
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  4%] Linking CXX executable ../../bin/llama-gemma3-cli
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /usr/bin/cmake -E cmake_link_script CMakeFiles/llama-gemma3-cli.dir/link.txt --verbose=1
[  4%] Linking CXX executable ../../bin/llama-qwen2vl-cli
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /usr/bin/cmake -E cmake_link_script CMakeFiles/llama-qwen2vl-cli.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -O3 -DNDEBUG "CMakeFiles/llama-gemma3-cli.dir/deprecation-warning.cpp.o" -o ../../bin/llama-gemma3-cli 
[  4%] Built target sha256
/opt/intel/oneapi/compiler/2025.2/bin/icpx -O3 -DNDEBUG "CMakeFiles/llama-qwen2vl-cli.dir/deprecation-warning.cpp.o" -o ../../bin/llama-qwen2vl-cli 
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  5%] Linking CXX executable ../../bin/llama-llava-cli
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /usr/bin/cmake -E cmake_link_script CMakeFiles/llama-llava-cli.dir/link.txt --verbose=1
[  5%] Built target llama-gemma3-cli
[  5%] Linking CXX executable ../../bin/llama-minicpmv-cli
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/tools/mtmd && /usr/bin/cmake -E cmake_link_script CMakeFiles/llama-minicpmv-cli.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -O3 -DNDEBUG "CMakeFiles/llama-llava-cli.dir/deprecation-warning.cpp.o" -o ../../bin/llama-llava-cli 
[  5%] Built target llama-qwen2vl-cli
/opt/intel/oneapi/compiler/2025.2/bin/icpx -O3 -DNDEBUG "CMakeFiles/llama-minicpmv-cli.dir/deprecation-warning.cpp.o" -o ../../bin/llama-minicpmv-cli 
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  5%] Built target llama-llava-cli
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  5%] Built target llama-minicpmv-cli
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  5%] Built target xxhash
[  6%] Linking CXX shared library ../../bin/libggml-base.so
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /usr/bin/cmake -E cmake_link_script CMakeFiles/ggml-base.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libggml-base.so -o ../../bin/libggml-base.so "CMakeFiles/ggml-base.dir/ggml.c.o" "CMakeFiles/ggml-base.dir/ggml.cpp.o" "CMakeFiles/ggml-base.dir/ggml-alloc.c.o" "CMakeFiles/ggml-base.dir/ggml-backend.cpp.o" "CMakeFiles/ggml-base.dir/ggml-opt.cpp.o" "CMakeFiles/ggml-base.dir/ggml-threading.cpp.o" "CMakeFiles/ggml-base.dir/ggml-quants.c.o" "CMakeFiles/ggml-base.dir/gguf.cpp.o"  -lm 
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  6%] Built target ggml-base
/usr/bin/gmake  -f ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/build.make ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/depend
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-cpu.dir/build.make ggml/src/CMakeFiles/ggml-cpu.dir/depend
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/CMakeFiles/ggml-cpu.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml-cpu.dir/build.make ggml/src/CMakeFiles/ggml-cpu.dir/build
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/build.make ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[  7%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/common.cpp.o
[  7%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o
[  7%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/binbcast.cpp.o
[  8%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/convert.cpp.o
[  8%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/count-equal.cpp.o
[  8%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o
[  9%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o
[  9%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o
[  9%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/ggml-sycl.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/binbcast.cpp.o -MF CMakeFiles/ggml-sycl.dir/binbcast.cpp.o.d -o CMakeFiles/ggml-sycl.dir/binbcast.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/binbcast.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/common.cpp.o -MF CMakeFiles/ggml-sycl.dir/common.cpp.o.d -o CMakeFiles/ggml-sycl.dir/common.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/common.cpp
[  7%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/convert.cpp.o -MF CMakeFiles/ggml-sycl.dir/convert.cpp.o.d -o CMakeFiles/ggml-sycl.dir/convert.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/convert.cpp
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o
[ 10%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/conv.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/repack.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/quants.c
[ 10%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/count-equal.cpp.o -MF CMakeFiles/ggml-sycl.dir/count-equal.cpp.o.d -o CMakeFiles/ggml-sycl.dir/count-equal.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/count-equal.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/ggml-sycl.cpp.o -MF CMakeFiles/ggml-sycl.dir/ggml-sycl.cpp.o.d -o CMakeFiles/ggml-sycl.dir/ggml-sycl.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/ggml-sycl.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/conv.cpp.o -MF CMakeFiles/ggml-sycl.dir/conv.cpp.o.d -o CMakeFiles/ggml-sycl.dir/conv.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/conv.cpp
[ 10%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/cpy.cpp.o
[ 10%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/concat.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/cpy.cpp.o -MF CMakeFiles/ggml-sycl.dir/cpy.cpp.o.d -o CMakeFiles/ggml-sycl.dir/cpy.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/cpy.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/concat.cpp.o -MF CMakeFiles/ggml-sycl.dir/concat.cpp.o.d -o CMakeFiles/ggml-sycl.dir/concat.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/concat.cpp
[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o
[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/traits.cpp
[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp
[ 11%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o
[ 12%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/dmmv.cpp.o
[ 13%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp
[ 14%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/dmmv.cpp.o -MF CMakeFiles/ggml-sycl.dir/dmmv.cpp.o.d -o CMakeFiles/ggml-sycl.dir/dmmv.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/dmmv.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/hbm.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp
[ 14%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/element_wise.cpp.o
[ 15%] Building C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o
[ 15%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/getrows.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/vec.cpp
[ 15%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/gla.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/ops.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/arch/x86/quants.c
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/getrows.cpp.o -MF CMakeFiles/ggml-sycl.dir/getrows.cpp.o.d -o CMakeFiles/ggml-sycl.dir/getrows.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/getrows.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/element_wise.cpp.o -MF CMakeFiles/ggml-sycl.dir/element_wise.cpp.o.d -o CMakeFiles/ggml-sycl.dir/element_wise.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/element_wise.cpp
[ 15%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/norm.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/gla.cpp.o -MF CMakeFiles/ggml-sycl.dir/gla.cpp.o.d -o CMakeFiles/ggml-sycl.dir/gla.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/gla.cpp
[ 15%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/im2col.cpp.o
[ 15%] Building CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o
[ 15%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/mmvq.cpp.o
[ 16%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/mmq.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/im2col.cpp.o -MF CMakeFiles/ggml-sycl.dir/im2col.cpp.o.d -o CMakeFiles/ggml-sycl.dir/im2col.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/im2col.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/mmq.cpp.o -MF CMakeFiles/ggml-sycl.dir/mmq.cpp.o.d -o CMakeFiles/ggml-sycl.dir/mmq.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/mmq.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -march=native -fno-associative-math -fiopenmp -MD -MT ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o -MF CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o.d -o CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-cpu/arch/x86/repack.cpp
[ 16%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/rope.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/mmvq.cpp.o -MF CMakeFiles/ggml-sycl.dir/mmvq.cpp.o.d -o CMakeFiles/ggml-sycl.dir/mmvq.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/mmvq.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/norm.cpp.o -MF CMakeFiles/ggml-sycl.dir/norm.cpp.o.d -o CMakeFiles/ggml-sycl.dir/norm.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/norm.cpp
[ 17%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/outprod.cpp.o
[ 17%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/pad.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/outprod.cpp.o -MF CMakeFiles/ggml-sycl.dir/outprod.cpp.o.d -o CMakeFiles/ggml-sycl.dir/outprod.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/outprod.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/rope.cpp.o -MF CMakeFiles/ggml-sycl.dir/rope.cpp.o.d -o CMakeFiles/ggml-sycl.dir/rope.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/rope.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/pad.cpp.o -MF CMakeFiles/ggml-sycl.dir/pad.cpp.o.d -o CMakeFiles/ggml-sycl.dir/pad.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/pad.cpp
[ 18%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/set.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/set.cpp.o -MF CMakeFiles/ggml-sycl.dir/set.cpp.o.d -o CMakeFiles/ggml-sycl.dir/set.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/set.cpp
[ 18%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/set_rows.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/set_rows.cpp.o -MF CMakeFiles/ggml-sycl.dir/set_rows.cpp.o.d -o CMakeFiles/ggml-sycl.dir/set_rows.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/set_rows.cpp
[ 18%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/sycl_hw.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/sycl_hw.cpp.o -MF CMakeFiles/ggml-sycl.dir/sycl_hw.cpp.o.d -o CMakeFiles/ggml-sycl.dir/sycl_hw.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/sycl_hw.cpp
[ 19%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/wkv.cpp.o
[ 19%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/tsembd.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/wkv.cpp.o -MF CMakeFiles/ggml-sycl.dir/wkv.cpp.o.d -o CMakeFiles/ggml-sycl.dir/wkv.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/wkv.cpp
[ 20%] Building CXX object ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/softmax.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/tsembd.cpp.o -MF CMakeFiles/ggml-sycl.dir/tsembd.cpp.o.d -o CMakeFiles/ggml-sycl.dir/tsembd.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/tsembd.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_SYCL_DNNL=1 -DGGML_SYCL_GRAPH -DGGML_SYCL_USE_INTEL_ONEMKL -DGGML_SYCL_WARP_SIZE=16 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_sycl_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/.. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -isystem /opt/intel/oneapi/compiler/2025.2/include -isystem /opt/intel/oneapi/dnnl/2025.2/include -isystem /opt/intel/oneapi/mkl/2025.2/include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-narrowing -fsycl -DMKL_ILP64 -MD -MT ggml/src/ggml-sycl/CMakeFiles/ggml-sycl.dir/softmax.cpp.o -MF CMakeFiles/ggml-sycl.dir/softmax.cpp.o.d -o CMakeFiles/ggml-sycl.dir/softmax.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/softmax.cpp
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/pad.cpp:64:30: warning: unused parameter 'item_ct1' [-Wunused-parameter]
   64 |         [=](sycl::nd_item<3> item_ct1) {
      |                              ^
1 warning generated.
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-sycl/pad.cpp:64:30: warning: unused parameter 'item_ct1' [-Wunused-parameter]
   64 |         [=](sycl::nd_item<3> item_ct1) {
      |                              ^
1 warning generated.
[ 21%] Linking CXX shared library ../../bin/libggml-cpu.so
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /usr/bin/cmake -E cmake_link_script CMakeFiles/ggml-cpu.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -fPIC -O3 -DNDEBUG -fiopenmp -shared -Wl,-soname,libggml-cpu.so -o ../../bin/libggml-cpu.so "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o" "CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o"  -Wl,-rpath,/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/bin: ../../bin/libggml-base.so /opt/intel/oneapi/compiler/2025.2/lib/libiomp5.so /lib/x86_64-linux-gnu/libpthread.a 
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[ 21%] Built target ggml-cpu
[ 21%] Linking CXX shared library ../../../bin/libggml-sycl.so
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/ggml-sycl && /usr/bin/cmake -E cmake_link_script CMakeFiles/ggml-sycl.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -fPIC -O3 -DNDEBUG -fsycl -shared -Wl,-soname,libggml-sycl.so -o ../../../bin/libggml-sycl.so "CMakeFiles/ggml-sycl.dir/ggml-sycl.cpp.o" "CMakeFiles/ggml-sycl.dir/binbcast.cpp.o" "CMakeFiles/ggml-sycl.dir/common.cpp.o" "CMakeFiles/ggml-sycl.dir/concat.cpp.o" "CMakeFiles/ggml-sycl.dir/conv.cpp.o" "CMakeFiles/ggml-sycl.dir/convert.cpp.o" "CMakeFiles/ggml-sycl.dir/count-equal.cpp.o" "CMakeFiles/ggml-sycl.dir/cpy.cpp.o" "CMakeFiles/ggml-sycl.dir/dmmv.cpp.o" "CMakeFiles/ggml-sycl.dir/element_wise.cpp.o" "CMakeFiles/ggml-sycl.dir/getrows.cpp.o" "CMakeFiles/ggml-sycl.dir/gla.cpp.o" "CMakeFiles/ggml-sycl.dir/im2col.cpp.o" "CMakeFiles/ggml-sycl.dir/mmq.cpp.o" "CMakeFiles/ggml-sycl.dir/mmvq.cpp.o" "CMakeFiles/ggml-sycl.dir/norm.cpp.o" "CMakeFiles/ggml-sycl.dir/outprod.cpp.o" "CMakeFiles/ggml-sycl.dir/pad.cpp.o" "CMakeFiles/ggml-sycl.dir/rope.cpp.o" "CMakeFiles/ggml-sycl.dir/set.cpp.o" "CMakeFiles/ggml-sycl.dir/set_rows.cpp.o" "CMakeFiles/ggml-sycl.dir/softmax.cpp.o" "CMakeFiles/ggml-sycl.dir/sycl_hw.cpp.o" "CMakeFiles/ggml-sycl.dir/tsembd.cpp.o" "CMakeFiles/ggml-sycl.dir/wkv.cpp.o"  -Wl,-rpath,/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/bin: ../../../bin/libggml-base.so /opt/intel/oneapi/dnnl/2025.2/lib/libdnnl.so.3.8 /opt/intel/oneapi/compiler/2025.2/lib/libsycl.so -lOpenCL /opt/intel/oneapi/tbb/2022.2/lib/intel64/gcc4.8/libtbb.so.12 -ldl -fsycl -Wl,-rpath=/opt/intel/oneapi/mkl/2025.2/lib /opt/intel/oneapi/mkl/2025.2/lib/libmkl_sycl_blas.so /opt/intel/oneapi/mkl/2025.2/lib/libmkl_intel_ilp64.so /opt/intel/oneapi/mkl/2025.2/lib/libmkl_tbb_thread.so /opt/intel/oneapi/mkl/2025.2/lib/libmkl_core.so /opt/intel/oneapi/tbb/2022.2/lib/intel64/gcc4.8/libtbb.so.12 -Wl,-rpath,/opt/intel/oneapi/tbb/2022.2/lib/intel64/gcc4.8 -L/opt/intel/oneapi/tbb/2022.2/lib/intel64/gcc4.8 -ltbb -lm -ldl -lpthread -lsycl -lOpenCL 
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[ 21%] Built target ggml-sycl
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml.dir/build.make ggml/src/CMakeFiles/ggml.dir/depend
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src/CMakeFiles/ggml.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f ggml/src/CMakeFiles/ggml.dir/build.make ggml/src/CMakeFiles/ggml.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[ 21%] Building CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -std=gnu++17 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -MF CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o.d -o CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/ggml-backend-reg.cpp
[ 22%] Linking CXX shared library ../../bin/libggml.so
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/ggml/src && /usr/bin/cmake -E cmake_link_script CMakeFiles/ggml.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -fPIC -O3 -DNDEBUG -shared -Wl,-soname,libggml.so -o ../../bin/libggml.so "CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o"  -Wl,-rpath,/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/bin: -ldl ../../bin/libggml-cpu.so ../../bin/libggml-sycl.so ../../bin/libggml-base.so -ldl 
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[ 22%] Built target ggml
/usr/bin/gmake  -f src/CMakeFiles/llama.dir/build.make src/CMakeFiles/llama.dir/depend
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build.make examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/depend
/usr/bin/gmake  -f examples/gguf/CMakeFiles/llama-gguf.dir/build.make examples/gguf/CMakeFiles/llama-gguf.dir/depend
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf/CMakeFiles/llama-gguf.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/DependInfo.cmake "--color="
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build && /usr/bin/cmake -E cmake_depends "Unix Makefiles" /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src/CMakeFiles/llama.dir/DependInfo.cmake "--color="
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f examples/gguf/CMakeFiles/llama-gguf.dir/build.make examples/gguf/CMakeFiles/llama-gguf.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f src/CMakeFiles/llama.dir/build.make src/CMakeFiles/llama.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
/usr/bin/gmake  -f examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build.make examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build
gmake[2]: Entering directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
[ 23%] Building CXX object src/CMakeFiles/llama.dir/llama-adapter.cpp.o
[ 23%] Building CXX object src/CMakeFiles/llama.dir/llama.cpp.o
[ 23%] Building CXX object examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o
[ 24%] Building CXX object src/CMakeFiles/llama.dir/llama-graph.cpp.o
[ 24%] Building CXX object src/CMakeFiles/llama.dir/llama-batch.cpp.o
[ 24%] Building CXX object src/CMakeFiles/llama.dir/llama-chat.cpp.o
[ 24%] Building CXX object src/CMakeFiles/llama.dir/llama-impl.cpp.o
[ 25%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT examples/gguf/CMakeFiles/llama-gguf.dir/gguf.cpp.o -MF CMakeFiles/llama-gguf.dir/gguf.cpp.o.d -o CMakeFiles/llama-gguf.dir/gguf.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf/gguf.cpp
[ 26%] Building CXX object src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o
[ 26%] Building CXX object src/CMakeFiles/llama.dir/llama-hparams.cpp.o
[ 27%] Building CXX object src/CMakeFiles/llama.dir/llama-grammar.cpp.o
[ 27%] Building CXX object src/CMakeFiles/llama.dir/llama-arch.cpp.o
[ 27%] Building CXX object src/CMakeFiles/llama.dir/llama-cparams.cpp.o
[ 27%] Building CXX object src/CMakeFiles/llama.dir/llama-context.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama.cpp.o -MF CMakeFiles/llama.dir/llama.cpp.o.d -o CMakeFiles/llama.dir/llama.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-adapter.cpp.o -MF CMakeFiles/llama.dir/llama-adapter.cpp.o.d -o CMakeFiles/llama.dir/llama-adapter.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-arch.cpp.o -MF CMakeFiles/llama.dir/llama-arch.cpp.o.d -o CMakeFiles/llama.dir/llama-arch.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-arch.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-batch.cpp.o -MF CMakeFiles/llama.dir/llama-batch.cpp.o.d -o CMakeFiles/llama.dir/llama-batch.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-chat.cpp.o -MF CMakeFiles/llama.dir/llama-chat.cpp.o.d -o CMakeFiles/llama.dir/llama-chat.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-chat.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-context.cpp.o -MF CMakeFiles/llama.dir/llama-context.cpp.o.d -o CMakeFiles/llama.dir/llama-context.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp
[ 27%] Building CXX object src/CMakeFiles/llama.dir/llama-memory.cpp.o
[ 27%] Building CXX object src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-cparams.cpp.o -MF CMakeFiles/llama.dir/llama-cparams.cpp.o.d -o CMakeFiles/llama.dir/llama-cparams.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-cparams.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-grammar.cpp.o -MF CMakeFiles/llama.dir/llama-grammar.cpp.o.d -o CMakeFiles/llama.dir/llama-grammar.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-grammar.cpp
[ 28%] Building CXX object src/CMakeFiles/llama.dir/llama-io.cpp.o
[ 28%] Building CXX object src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-graph.cpp.o -MF CMakeFiles/llama.dir/llama-graph.cpp.o.d -o CMakeFiles/llama.dir/llama-graph.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp
[ 28%] Building CXX object examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/deps -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o -MF CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o.d -o CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/examples/gguf-hash/gguf-hash.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-hparams.cpp.o -MF CMakeFiles/llama.dir/llama-hparams.cpp.o.d -o CMakeFiles/llama.dir/llama-hparams.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-hparams.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-impl.cpp.o -MF CMakeFiles/llama.dir/llama-impl.cpp.o.d -o CMakeFiles/llama.dir/llama-impl.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-impl.cpp
[ 28%] Building CXX object src/CMakeFiles/llama.dir/llama-model-saver.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-io.cpp.o -MF CMakeFiles/llama.dir/llama-io.cpp.o.d -o CMakeFiles/llama.dir/llama-io.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-io.cpp
[ 29%] Building CXX object src/CMakeFiles/llama.dir/llama-model.cpp.o
[ 30%] Building CXX object src/CMakeFiles/llama.dir/llama-model-loader.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o -MF CMakeFiles/llama.dir/llama-kv-cache.cpp.o.d -o CMakeFiles/llama.dir/llama-kv-cache.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp
[ 30%] Building CXX object src/CMakeFiles/llama.dir/llama-mmap.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o -MF CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o.d -o CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-memory.cpp.o -MF CMakeFiles/llama.dir/llama-memory.cpp.o.d -o CMakeFiles/llama.dir/llama-memory.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o -MF CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o.d -o CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o -MF CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o.d -o CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-mmap.cpp.o -MF CMakeFiles/llama.dir/llama-mmap.cpp.o.d -o CMakeFiles/llama.dir/llama-mmap.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-mmap.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-model-loader.cpp.o -MF CMakeFiles/llama.dir/llama-model-loader.cpp.o.d -o CMakeFiles/llama.dir/llama-model-loader.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-loader.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-model-saver.cpp.o -MF CMakeFiles/llama.dir/llama-model-saver.cpp.o.d -o CMakeFiles/llama.dir/llama-model-saver.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-model.cpp.o -MF CMakeFiles/llama.dir/llama-model.cpp.o.d -o CMakeFiles/llama.dir/llama-model.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp
[ 30%] Building CXX object src/CMakeFiles/llama.dir/llama-quant.cpp.o
[ 30%] Building CXX object src/CMakeFiles/llama.dir/unicode-data.cpp.o
[ 30%] Building CXX object src/CMakeFiles/llama.dir/llama-sampling.cpp.o
[ 30%] Building CXX object src/CMakeFiles/llama.dir/unicode.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-quant.cpp.o -MF CMakeFiles/llama.dir/llama-quant.cpp.o.d -o CMakeFiles/llama.dir/llama-quant.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-sampling.cpp.o -MF CMakeFiles/llama.dir/llama-sampling.cpp.o.d -o CMakeFiles/llama.dir/llama-sampling.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-sampling.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/unicode-data.cpp.o -MF CMakeFiles/llama.dir/unicode-data.cpp.o.d -o CMakeFiles/llama.dir/unicode-data.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/unicode-data.cpp
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/unicode.cpp.o -MF CMakeFiles/llama.dir/unicode.cpp.o.d -o CMakeFiles/llama.dir/unicode.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/unicode.cpp
[ 31%] Building CXX object src/CMakeFiles/llama.dir/llama-vocab.cpp.o
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/src && /opt/intel/oneapi/compiler/2025.2/bin/icpx -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DGGML_USE_SYCL -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/. -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include -I/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/ggml/src/../include -O3 -DNDEBUG -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -MD -MT src/CMakeFiles/llama.dir/llama-vocab.cpp.o -MF CMakeFiles/llama.dir/llama-vocab.cpp.o.d -o CMakeFiles/llama.dir/llama-vocab.cpp.o -c /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-vocab.cpp
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.hIn file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
:   18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
26  : error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
285/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
   |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
239/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
   |     } llama_batch;
      |       ^
239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.cpp:1:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:12:1: error: incomplete type 'llama_batch_allocr' named in nested name specifier
   12 | llama_batch_allocr::llama_batch_allocr(uIn file included from int32_t n_pos_per_embd) : n_pos_per_embd(n_pos_per_embd) {
      | ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
:11  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
:/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
239 | /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:12:1: error: incomplete type 'llama_batch_allocr' named in nested name specifier
    12 | llama_batch_allocr::llama_batch_allocr(uint32_t n_pos_per_embd) : n_pos_per_embd(n_pos_per_embd) {
      | ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h   } llama_batch;
      |       ^
:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:25:6: error: incomplete type 'llama_batch_allocr' named in nested name specifier
   25 | bool llama_batch_allocr::init(
      |      ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:364:14: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  364 | llama_ubatch llama_batch_allocr::ubatch_reserve(uint32_t n_seq_tokens, uint32_t n_seqs) {
      |              ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:407:21: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  407 | const llama_batch & llama_batch_allocr::get_batch() const {
      |                     ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:411:10: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  411 | uint32_t llama_batch_allocr::get_n_tokens() const {
      |          ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:415:10: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  415 | uint32_t llama_batch_allocr::get_n_outputs() const {
      |          ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:419:10: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  419 | uint32_t llama_batch_allocr::get_n_used() const {
      |          ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:423:24: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  423 | std::vector<int32_t> & llama_batch_allocr::get_out_ids() {
      |                        ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
l  lama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
:/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  427:11: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  239 |     } llama_batch;
      |       ^
427 | llama_pos llama_batch_allocr::seq_pos_min(llama_seq_id seq_id) const {
      |           ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:431:11: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  431 | llama_pos llama_batch_allocr::seq_pos_max(llama_seq_id seq_id) const {
      |           ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:435:6: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  435 | void llama_batch_allocr::split_reset() {
      |      ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:444:14: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  444 | llama_ubatch llama_batch_allocr::split_simple(uint32_t n_ubatch) {
      |              ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:478:14: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  478 | llama_ubatch llama_batch_allocr::split_equal(uint32_t n_ubatch, bool sequential) {
      |              ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:583:14: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  583 | llama_ubatch llama_batch_allocr::split_seq(uint32_t n_ubatch) {
      |              ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:625:6: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  625 | void llama_batch_allocr::clear() {
      |      ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:651:14: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  651 | llama_ubatch llama_batch_allocr::ubatch_add(const std::vector<int32_t> & idxs, uint32_t n_seqs, bool equal_seqs) {
      |              ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-batch.cpp:734:6: error: incomplete type 'llama_batch_allocr' named in nested name specifier
  734 | void llama_batch_allocr::ubatch_print(const llama_ubatch & ubatch, int debug) {
      |      ^~~~~~~~~~~~~~~~~~~~
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory.h:11:7: note: forward declaration of 'llama_batch_allocr'
   11 | class llama_batch_allocr;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
:/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
18 errors generated.
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:118: src/CMakeFiles/llama.dir/llama-batch.cpp.o] Error 1
gmake[2]: *** Waiting for unfinished jobs....
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
152  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
 | /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
      void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
239/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
   |     } llama_batch;
      |       ^
239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:354:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  354 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:375:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  375 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
l   lama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const ll/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
a  ma_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:397:47: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  397 | using llm_graph_cb = std::function<void(const llama_ubatch & ubatch, ggml_tensor * cur, const char * name, int il)>;
      |                                               ^~~~~~~~~~~~
      |                                               llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     coIn file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
n  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
s/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
t llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
20 errors generated.
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:407:5: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  407 |     llama_ubatch ubatch; // note: intentionally make a copy
      |     ^~~~~~~~~~~~
      |     llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-context.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:430:20: error: no member named 'equal_seqs' in 'llama_batch'

  430 |             ubatch.equal_seqs() == other.ubatch.equal_seqs() &&
      |             ~~~~~~ ^
      |                          llama_batch
fatal error: too many errors emitted, stopping now [-ferror-limit=]
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-adapter.cpp:5:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:188: src/CMakeFiles/llama.dir/llama-graph.cpp.o] Error 1
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const lIn file included from lama_ubatch * ub/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
a  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
t/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  ch) =239 |     } llama_batch;
      |       ^
 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error:   unknown type name 'llama_ubatch'; did you mean 'llama_batch'?110
 |     void set_input(const llama_ubatch   *123  |  u  b avtocih)d o vseertr_iidne;p
u      t| (                         ^~~~~~~~~~~~
c      o| n                         llama_batchs
t llama_ubatch/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h :*239 u:b7:a tnote: c'llama_batch' declared hereh
) o  239v | e  r  r}i dlel;a
m      a| _                         ^~~~~~~~~~~~b
a      t| c                         llama_batchh
;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
20 errors generated.
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     constIn file included from  ll/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cppa:m1a:
_In file included from c/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.hp:a5r:
am/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.hs: 139c:pa26r:a mserror: ;unknown type name 'llama_ubatch'; did you mean 'llama_batch'?

      |                         ^
  /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h139: | 18 : 8 :  vnote: oforward declaration of 'llama_cparams'i
d set_   i18n | psuttr(uccotn sltl almlaa_mcap_aurbaamtsc;h
       *|         ^u
batch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_inIn file included from put(const llama_/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
u  batc183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
h/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
   * 239 |     } llama_batch;
      |       ^
ubatch) override;
      In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  |                          ^~~~~~~~~~~~
      |                          llama_batch190 |     const llama_cparams cparams;
      |                         ^

/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:146: src/CMakeFiles/llama.dir/llama-context.cpp.o] Error 1
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
3:
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: 239 |     } llama_batch;
      |       ^
unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_In file included from input(/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
c  190 |     const llama_cparams cparams;
      |                         ^
o/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   nst 18 | struct llama_cparams;
      |        ^
llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache-iswa.h:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-kv-cache.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
20 errors generated.
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:90: src/CMakeFiles/llama.dir/llama-adapter.cpp.o] Error 1
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-quant.cpp:3:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
20 errors generated.
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.hIn file included from :321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llagmake[2]: *** [src/CMakeFiles/llama.dir/build.make:258: src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o] Error 1
ma_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;In file included from 
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
20      |       ^
 errors generated.
fatal error: too many errors emitted, stopping now [-ferror-limit=]
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:244: src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o] Error 1
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-recurrent.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:300: src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o] Error 1
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:88:34: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
   88 |     virtual void set_input(const llama_ubatch * ubatch) = 0;
      |                                  ^~~~~~~~~~~~
      |                                  llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:110:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  110 |     void set_inputIn file included from (const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
239   |     } llama_batch;
      |       ^
139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:123:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  123 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:139:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  139 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   In file included from 18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:152:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  152 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batc/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
h  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
;/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  
      |       ^
239 |     } llama_batch;
      |       ^
[ 32%] Linking CXX executable ../../bin/llama-gguf
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf && /usr/bin/cmake -E cmake_link_script CMakeFiles/llama-gguf.dir/link.txt --verbose=1
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:166:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  166 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  In file included from 216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:183:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  183 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:190:25: error: field has incomplete type 'const llama_cparams'
  190 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/opt/intel/oneapi/compiler/2025.2/bin/icpx -O3 -DNDEBUG "CMakeFiles/llama-gguf.dir/gguf.cpp.o" -o ../../bin/llama-gguf  -Wl,-rpath,/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/bin: ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-sycl.so ../../bin/libggml-base.so 
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.cpp:1:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-memory-hybrid.h:4:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:200:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  200 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:204:25: error: field has incomplete type 'const llama_cparams'
  204 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:212:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  212 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:216:25: error: field has incomplete type 'const llama_cparams'
  216 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparamsIn file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
;  
      |        ^
258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:225:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  225 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 | /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
      } llama_batch;
      |       ^
285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model-saver.cpp:7:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void seIn file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:243:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
t  243 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
_/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:258:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  258 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:270:25: error: field has incomplete type 'const llama_cparams'
  270 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
   18 | struct llama_cparams;
      |        ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:285:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  285 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama.cpp:8:
In file included from /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-model.h:5:
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:304:25: error: field has incomplete type 'const llama_cparams'
  20304 |     const llama_cparams cparams;
      |                         ^
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:18:8: note: forward declaration of 'llama_cparams'
    errors generated.
18 | struct llama_cparams;
      |        ^
20 errors generated.
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:286: src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o] Error 1
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/llama-graph.h:321:26: error: unknown type name 'llama_ubatch'; did you mean 'llama_batch'?
  321 |     void set_input(const llama_ubatch * ubatch) override;
      |                          ^~~~~~~~~~~~
      |                          llama_batch
/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/src/../include/llama.h:239:7: note: 'llama_batch' declared here
  239 |     } llama_batch;
      |       ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:342: src/CMakeFiles/llama.dir/llama-model-saver.cpp.o] Error 1
20 errors generated.
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:76: src/CMakeFiles/llama.dir/llama.cpp.o] Error 1
20 errors generated.
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:370: src/CMakeFiles/llama.dir/llama-quant.cpp.o] Error 1
[ 32%] Linking CXX executable ../../bin/llama-gguf-hash
cd /home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/examples/gguf-hash && /usr/bin/cmake -E cmake_link_script CMakeFiles/llama-gguf-hash.dir/link.txt --verbose=1
/opt/intel/oneapi/compiler/2025.2/bin/icpx -O3 -DNDEBUG "CMakeFiles/llama-gguf-hash.dir/gguf-hash.cpp.o" CMakeFiles/xxhash.dir/deps/xxhash/xxhash.c.o CMakeFiles/sha1.dir/deps/sha1/sha1.c.o CMakeFiles/sha256.dir/deps/sha256/sha256.c.o -o ../../bin/llama-gguf-hash  -Wl,-rpath,/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build/bin: ../../bin/libggml.so ../../bin/libggml-cpu.so ../../bin/libggml-sycl.so ../../bin/libggml-base.so 
20 errors generated.
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_backend_alloc_ctx_tensors_from_buft'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_new_n'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_get_buffer_size'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_reserve_n'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_free'
gmake[2]: *** [src/CMakeFiles/llama.dir/build.make:356: src/CMakeFiles/llama.dir/llama-model.cpp.o] Error 1
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_alloc_graph'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_backend_alloc_ctx_tensors'
icpx: error: linker command failed with exit code 1 (use -v to see invocation)
gmake[2]: *** [examples/gguf/CMakeFiles/llama-gguf.dir/build.make:101: bin/llama-gguf] Error 1
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[1]: *** [CMakeFiles/Makefile2:3099: examples/gguf/CMakeFiles/llama-gguf.dir/all] Error 2
gmake[1]: *** Waiting for unfinished jobs....
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_backend_alloc_ctx_tensors_from_buft'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_new_n'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_get_buffer_size'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_reserve_n'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_free'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_gallocr_alloc_graph'
/usr/bin/ld: ../../bin/libggml-base.so: undefined reference to `ggml_backend_alloc_ctx_tensors'
icpx: error: linker command failed with exit code 1 (use -v to see invocation)
gmake[2]: *** [examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/build.make:107: bin/llama-gguf-hash] Error 1
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[1]: *** [CMakeFiles/Makefile2:2992: examples/gguf-hash/CMakeFiles/llama-gguf-hash.dir/all] Error 2
gmake[2]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake[1]: *** [CMakeFiles/Makefile2:1848: src/CMakeFiles/llama.dir/all] Error 2
gmake[1]: Leaving directory '/home/zjy/ws/jenkins/workspace/ci-arc770/ggerganov-llama.cpp/build'
gmake: *** [Makefile:146: all] Error 2

