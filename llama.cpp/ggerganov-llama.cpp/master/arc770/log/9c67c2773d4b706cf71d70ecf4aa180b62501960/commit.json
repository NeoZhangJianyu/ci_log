{"author": "Georgi Gerganov <ggerganov@gmail.com>", "date": "2024-04-30 12:16:08", "title": "ggml : add Flash Attention", "pr_id": "5021", "files": ["ci/run.sh", "common/common.cpp", "common/common.h", "examples/batched-bench/batched-bench.cpp", "examples/llama-bench/llama-bench.cpp", "examples/server/bench/bench.py", "examples/server/server.cpp", "ggml-cuda.cu", "ggml-cuda/common.cuh", "ggml-cuda/fattn.cu", "ggml-cuda/fattn.cuh", "ggml-cuda/softmax.cu", "ggml-kompute.cpp", "ggml-metal.m", "ggml-metal.metal", "ggml-sycl.cpp", "ggml-vulkan.cpp", "ggml.c", "ggml.h", "llama.cpp", "llama.h", "tests/test-backend-ops.cpp"]}