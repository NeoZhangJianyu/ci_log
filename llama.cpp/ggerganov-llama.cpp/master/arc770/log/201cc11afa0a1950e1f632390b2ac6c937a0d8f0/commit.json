{"author": "liuwei-git <14815172+liuwei-git@users.noreply.github.com>", "date": "2024-05-22 04:28:32", "title": "llama : add phi3 128K model support", "pr_id": "7225", "files": ["convert-hf-to-gguf.py", "examples/finetune/finetune.cpp", "examples/train-text-from-scratch/train-text-from-scratch.cpp", "ggml-cuda/rope.cu", "ggml-kompute.cpp", "ggml-metal.m", "ggml-metal.metal", "ggml-sycl.cpp", "ggml-vulkan.cpp", "ggml.c", "ggml.h", "gguf-py/gguf/constants.py", "gguf-py/gguf/gguf_writer.py", "llama.cpp", "tests/test-backend-ops.cpp"]}