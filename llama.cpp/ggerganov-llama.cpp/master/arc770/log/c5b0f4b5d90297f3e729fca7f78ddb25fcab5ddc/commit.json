{"author": "Diego Devesa <slarengh@gmail.com>", "date": "2024-10-30 02:01:23", "title": "llama : refactor model loader with backend registry", "pr_id": "10026", "files": ["examples/llama-bench/llama-bench.cpp", "ggml/include/ggml-backend.h", "ggml/include/ggml-cuda.h", "ggml/src/ggml-amx.cpp", "ggml/src/ggml-backend-impl.h", "ggml/src/ggml-backend.cpp", "ggml/src/ggml-blas.cpp", "ggml/src/ggml-cann.cpp", "ggml/src/ggml-cuda.cu", "ggml/src/ggml-kompute.cpp", "ggml/src/ggml-metal.m", "ggml/src/ggml-rpc.cpp", "ggml/src/ggml-sycl.cpp", "ggml/src/ggml-vulkan.cpp", "ggml/src/ggml.c", "include/llama.h", "scripts/compare-llama-bench.py", "src/llama.cpp"]}