# [ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp/tree/master) CI for iGPU-i5-1250P by SYCL Backend

## Summary

Figure

![Performance](./perf.png)
## Detail

**GGUF res** is verified by script ./example/sycl/run.sh with llama2-7b-Q4 for correction

**GGUF Perf** is the performance data by script ./example/sycl/run.sh with llama2-7b-Q4

**Bench Perf** is the performance data by llama-bench with llama2-7b-Q4

|Commit Info|UT PassRate<br>Detail|GGUF Perf<br>(token/s)|Bench Perf<br>(token/s)|<div style="width:100px">GGUF res</div>|Warn/Err<br>oneAPI|
|-|-|-|-|-|-|
|[1025fd2c09b1d4f9aa3fb2f7349084eecd04f958](https://github.com/ggerganov/llama.cpp/commit/1025fd2c09b1d4f9aa3fb2f7349084eecd04f958)<br>2026-01-30 06:01:38<br>sycl: implement GGML_UNARY_OP_SOFTPLUS<br>s8322  Log: [log](./log/1025fd2c09b1d4f9aa3fb2f7349084eecd04f958)|90.0%<br>NA|6.67|tg=7.78<br>pp=77.3|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[c7358ddf6458ffaf45dc1d9ca447b354c919fcff](https://github.com/ggerganov/llama.cpp/commit/c7358ddf6458ffaf45dc1d9ca447b354c919fcff)<br>2026-01-30 06:00:49<br>sycl: implement GGML_OP_TRI<br>RachelMantel  Log: [log](./log/c7358ddf6458ffaf45dc1d9ca447b354c919fcff)|93.0%<br>NA|6.76|tg=7.78<br>pp=77.38|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[d4964a7c66c4ff935d86c9ac92abeb12073723bf](https://github.com/ggerganov/llama.cpp/commit/d4964a7c66c4ff935d86c9ac92abeb12073723bf)<br>2026-01-29 09:20:22<br>sycl: fix norm kernels: l2_norm, group_n<br>orm, rms_norm by remove assert to suppor<br>t more cases<br>Neo Zhang  Log: [log](./log/d4964a7c66c4ff935d86c9ac92abeb12073723bf)|93.0%<br>NA|6.71|tg=7.76<br>pp=77.35|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[0cd7032ca4f1f2ac0c9527a62a76ed4dc6ad26fe](https://github.com/ggerganov/llama.cpp/commit/0cd7032ca4f1f2ac0c9527a62a76ed4dc6ad26fe)<br>2026-01-28 16:33:54<br>ggml-sycl: remove unused syclcompat head<br>er<br>Patryk Kaminski  Log: [log](./log/0cd7032ca4f1f2ac0c9527a62a76ed4dc6ad26fe)|90.0%<br>NA|6.76|tg=7.79<br>pp=77.44|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[cb6caca191b9a3a9a4eaa13dd9e465225d127034](https://github.com/ggerganov/llama.cpp/commit/cb6caca191b9a3a9a4eaa13dd9e465225d127034)<br>2026-01-23 20:54:10<br>[SYCL] use malloc to support both iGPU a<br>nd dGPU in same time<br>Neo Zhang  Log: [log](./log/cb6caca191b9a3a9a4eaa13dd9e465225d127034)|88.0%<br>NA|6.3|tg=7.78<br>pp=77.3|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[365a3e8c319ddb5442afdf17d0d23dfa0ff26c78](https://github.com/ggerganov/llama.cpp/commit/365a3e8c319ddb5442afdf17d0d23dfa0ff26c78)<br>2026-01-19 20:03:19<br>ggml : add ggml_build_forward_select<br>Georgi Gerganov  Log: [log](./log/365a3e8c319ddb5442afdf17d0d23dfa0ff26c78)|90.0%<br>NA|6.73|tg=7.79<br>pp=77.36|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[516a4ca9b5f2fa72c2a71f412929a67cf76a6213](https://github.com/ggerganov/llama.cpp/commit/516a4ca9b5f2fa72c2a71f412929a67cf76a6213)<br>2026-01-14 18:02:47<br>refactor : remove libcurl, use OpenSSL w<br>hen available<br>Adrien Gallouët  Log: [log](./log/516a4ca9b5f2fa72c2a71f412929a67cf76a6213)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|0/0<br>2025.0.4|
|[9a5724dee2457d58e506268efcb1d2286498cf3d](https://github.com/ggerganov/llama.cpp/commit/9a5724dee2457d58e506268efcb1d2286498cf3d)<br>2026-01-08 01:03:21<br>ggml: add env var GGML_OP_OFFLOAD_MIN_BA<br>TCH<br>Doctor Shotgun  Log: [log](./log/9a5724dee2457d58e506268efcb1d2286498cf3d)|96.0%<br>NA|NA|NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|0/0<br>2025.0.4|
|[7bcaf815c20f471fead106088b558e542982bf30](https://github.com/ggerganov/llama.cpp/commit/7bcaf815c20f471fead106088b558e542982bf30)<br>2025-12-31 14:23:44<br>sycl: add newline at the end of CMakeLis<br>ts.txt<br>Aman Gupta  Log: [log](./log/7bcaf815c20f471fead106088b558e542982bf30)|95.0%<br>NA|6.77|tg=7.79<br>pp=77.46|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[c8a37980419e8b7f0193d058fb6f8f01b458cfca](https://github.com/ggerganov/llama.cpp/commit/c8a37980419e8b7f0193d058fb6f8f01b458cfca)<br>2025-12-31 06:38:44<br>Work around broken IntelSYCLConfig.cmake<br> in Intel oneAPI 2025.x<br>Rahul Sathe  Log: [log](./log/c8a37980419e8b7f0193d058fb6f8f01b458cfca)|95.0%<br>NA|6.72|tg=7.78<br>pp=77.23|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[af3be131c065a38e476c34295bceda6cb956e7d7](https://github.com/ggerganov/llama.cpp/commit/af3be131c065a38e476c34295bceda6cb956e7d7)<br>2025-12-25 21:34:30<br>docs: added note for pre SYCL Intel hard<br>ware<br>Francisco Herrera  Log: [log](./log/af3be131c065a38e476c34295bceda6cb956e7d7)|95.0%<br>NA|6.78|tg=7.79<br>pp=77.32|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[1ce0126b18c58b9c5d6586a606fdf2780162afa1](https://github.com/ggerganov/llama.cpp/commit/1ce0126b18c58b9c5d6586a606fdf2780162afa1)<br>2025-12-24 11:19:47<br>docs: Fix typos in SYCL documentation<br>Jesse Ikonen  Log: [log](./log/1ce0126b18c58b9c5d6586a606fdf2780162afa1)|95.0%<br>NA|6.62|tg=7.79<br>pp=77.39|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[a6a552e4ec43c2b6ed29b05d8da6921c59f05ed7](https://github.com/ggerganov/llama.cpp/commit/a6a552e4ec43c2b6ed29b05d8da6921c59f05ed7)<br>2025-12-23 12:59:12<br>[SYCL] replace llama-cli by llama-comple<br>tion to rm the impact to test script<br>Neo Zhang  Log: [log](./log/a6a552e4ec43c2b6ed29b05d8da6921c59f05ed7)|95.0%<br>NA|6.77|tg=7.8<br>pp=77.32|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[279cef27c2b297476ecde6e5df729c057691f1de](https://github.com/ggerganov/llama.cpp/commit/279cef27c2b297476ecde6e5df729c057691f1de)<br>2025-12-16 04:45:09<br>added note for old Intel hardware pre sy<br>cl<br>Francisco Herrera  Log: [log](./log/279cef27c2b297476ecde6e5df729c057691f1de)|95.0%<br>NA|6.74|tg=7.79<br>pp=77.41|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[4aced7a63156555911157d3002f9d3ddef4a1e55](https://github.com/ggerganov/llama.cpp/commit/4aced7a63156555911157d3002f9d3ddef4a1e55)<br>2025-12-15 10:35:15<br>[SYCL] Support gpt-oss by OPs add-id, mu<br>l_mat for mxfp4, swiglu_oai<br>Neo Zhang Jianyu  Log: [log](./log/4aced7a63156555911157d3002f9d3ddef4a1e55)|95.0%<br>NA|6.75|tg=7.79<br>pp=77.25|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[2e9eab80c26d4b7e64f27c48b5af683c35c28742](https://github.com/ggerganov/llama.cpp/commit/2e9eab80c26d4b7e64f27c48b5af683c35c28742)<br>2025-12-10 16:59:57<br>fix softmax for iGPU<br>Neo Zhang Jianyu  Log: [log](./log/2e9eab80c26d4b7e64f27c48b5af683c35c28742)|95.0%<br>NA|6.68|tg=7.8<br>pp=77.37|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[68522c678daa7b65718f8a3de89bb2fbb139e26f](https://github.com/ggerganov/llama.cpp/commit/68522c678daa7b65718f8a3de89bb2fbb139e26f)<br>2025-12-08 22:09:39<br>ci : support bfloat16 SYCL release packa<br>ge<br>Neo Zhang  Log: [log](./log/68522c678daa7b65718f8a3de89bb2fbb139e26f)|92.0%<br>3217/3257|6.72|tg=7.77<br>pp=77.38|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[d9e03db1e701e34ed0b764615025110041729864](https://github.com/ggerganov/llama.cpp/commit/d9e03db1e701e34ed0b764615025110041729864)<br>2025-12-07 09:18:18<br>sycl: add missing BF16 conversion suppor<br>t for Intel oneAPI<br>Law Po Ying  Log: [log](./log/d9e03db1e701e34ed0b764615025110041729864)|92.0%<br>3217/3257|6.75|tg=7.78<br>pp=77.11|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[09c7c50e64c98adac452d090406b6e5f6c320a41](https://github.com/ggerganov/llama.cpp/commit/09c7c50e64c98adac452d090406b6e5f6c320a41)<br>2025-12-06 06:07:02<br>ggml : add circular tiling support to pa<br>d, for Vulkan, CUDA, and CPU<br>Phylliida Dev  Log: [log](./log/09c7c50e64c98adac452d090406b6e5f6c320a41)|92.0%<br>3217/3257|6.74|tg=7.79<br>pp=77.3|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[98bd9ab1e4fdef1497da628574bb90d0890539e7](https://github.com/ggerganov/llama.cpp/commit/98bd9ab1e4fdef1497da628574bb90d0890539e7)<br>2025-12-02 08:56:46<br>enhance argsort for UT<br>Neo Zhang Jianyu  Log: [log](./log/98bd9ab1e4fdef1497da628574bb90d0890539e7)|92.0%<br>3217/3257|6.76|tg=7.79<br>pp=77.29|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[2ba719519d950c5a62c00cdb8b119cc0914c1fa3](https://github.com/ggerganov/llama.cpp/commit/2ba719519d950c5a62c00cdb8b119cc0914c1fa3)<br>2025-11-30 21:57:31<br>model: LFM2-VL fixes<br>Tarek Dakhran  Log: [log](./log/2ba719519d950c5a62c00cdb8b119cc0914c1fa3)|89.0%<br>NA|6.75|tg=7.79<br>pp=77.29|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[7d2add51d8e3759020d70f2ff3a76b5795ff67bc](https://github.com/ggerganov/llama.cpp/commit/7d2add51d8e3759020d70f2ff3a76b5795ff67bc)<br>2025-11-29 20:59:44<br>sycl : support to malloc memory on devic<br>e more than 4GB, update the doc and scri<br>pt<br>Neo Zhang  Log: [log](./log/7d2add51d8e3759020d70f2ff3a76b5795ff67bc)|92.0%<br>NA|6.72|tg=7.79<br>pp=77.26|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[efaaccdd69cd9db777584c2a062f70c0526a6fb5](https://github.com/ggerganov/llama.cpp/commit/efaaccdd69cd9db777584c2a062f70c0526a6fb5)<br>2025-11-28 08:50:56<br>refactor pad_reflect_1d to make the UT c<br>ase pass<br>Neo Zhang Jianyu  Log: [log](./log/efaaccdd69cd9db777584c2a062f70c0526a6fb5)|89.0%<br>NA|6.74|tg=7.92<br>pp=77.38|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[72bd7321a7d7465d371eb2ae46cd5518842c8f44](https://github.com/ggerganov/llama.cpp/commit/72bd7321a7d7465d371eb2ae46cd5518842c8f44)<br>2025-11-16 01:52:42<br>sycl : unify unary kernels with a generi<br>c implementation and enable wide operato<br>r support<br>shani-f  Log: [log](./log/72bd7321a7d7465d371eb2ae46cd5518842c8f44)|92.0%<br>3134/3176|6.79|tg=7.92<br>pp=77.36|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[07751f8d446e2d05d069e8d77d984dd64c1a5878](https://github.com/ggerganov/llama.cpp/commit/07751f8d446e2d05d069e8d77d984dd64c1a5878)<br>2025-11-13 08:42:23<br>update SYCL support OPs<br>Neo Zhang Jianyu  Log: [log](./log/07751f8d446e2d05d069e8d77d984dd64c1a5878)|89.0%<br>3001/3043|6.78|tg=7.88<br>pp=77.38|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[5da7664960f93a5602d166326f6375dd7cc112ad](https://github.com/ggerganov/llama.cpp/commit/5da7664960f93a5602d166326f6375dd7cc112ad)<br>2025-11-12 14:44:29<br>[SYCL]fix ci crash about SSM_CONV<br>Neo Zhang Jianyu  Log: [log](./log/5da7664960f93a5602d166326f6375dd7cc112ad)|92.0%<br>3001/3043|6.8|tg=7.88<br>pp=77.48|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[9d7c518d642db8657e2a53a9793c5f039ed8ea5a](https://github.com/ggerganov/llama.cpp/commit/9d7c518d642db8657e2a53a9793c5f039ed8ea5a)<br>2025-11-06 12:02:33<br>sycl: add CONCAT operator support<br>YehuditE  Log: [log](./log/9d7c518d642db8657e2a53a9793c5f039ed8ea5a)|92.0%<br>NA|6.72|tg=8.0<br>pp=77.46|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[7e994168b1ccc12337ba8de939c4fd466107c1fb](https://github.com/ggerganov/llama.cpp/commit/7e994168b1ccc12337ba8de939c4fd466107c1fb)<br>2025-11-03 03:35:33<br>SYCL: optimized repeat_back kernel<br>shani-f  Log: [log](./log/7e994168b1ccc12337ba8de939c4fd466107c1fb)|92.0%<br>NA|6.82|tg=8.07<br>pp=77.26|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[d261223d24e97f2df50220e4a5b7f0adb69bba81](https://github.com/ggerganov/llama.cpp/commit/d261223d24e97f2df50220e4a5b7f0adb69bba81)<br>2025-10-30 23:19:14<br>model: add support for qwen3vl series<br>JJJYmmm  Log: [log](./log/d261223d24e97f2df50220e4a5b7f0adb69bba81)|89.0%<br>NA|6.82|tg=8.02<br>pp=77.2|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[338074c383c81366320d176d83b94b0a567ee0c2](https://github.com/ggerganov/llama.cpp/commit/338074c383c81366320d176d83b94b0a567ee0c2)<br>2025-10-29 08:14:39<br>sycl: add RMS_NORM_BACK operation suppor<br>t<br>YaelLogic  Log: [log](./log/338074c383c81366320d176d83b94b0a567ee0c2)|89.0%<br>NA|6.81|tg=8.04<br>pp=77.29|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[ad8d36beffd791db10c94eb9e964afb891e3ca55](https://github.com/ggerganov/llama.cpp/commit/ad8d36beffd791db10c94eb9e964afb891e3ca55)<br>2025-10-28 03:50:33<br>sycl: add SSM_CONV operation support<br>tamarPal  Log: [log](./log/ad8d36beffd791db10c94eb9e964afb891e3ca55)|92.0%<br>NA|6.82|tg=8.11<br>pp=77.4|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[2b9bd9bf4e759c05db629ec1c391dc8aeaa71887](https://github.com/ggerganov/llama.cpp/commit/2b9bd9bf4e759c05db629ec1c391dc8aeaa71887)<br>2025-10-27 03:20:24<br>sycl: add ROLL operation support<br>tamarPal  Log: [log](./log/2b9bd9bf4e759c05db629ec1c391dc8aeaa71887)|92.0%<br>17779/17824|6.82|tg=8.15<br>pp=77.38|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[59fc1ec8e83b14354c1a3a8acf8c5c2cbf9af42f](https://github.com/ggerganov/llama.cpp/commit/59fc1ec8e83b14354c1a3a8acf8c5c2cbf9af42f)<br>2025-10-27 03:19:50<br>sycl: add REPEAT_BACK operation support<br>shani-f  Log: [log](./log/59fc1ec8e83b14354c1a3a8acf8c5c2cbf9af42f)|89.0%<br>17779/17824|6.79|tg=8.13<br>pp=77.4|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[9de9672adb0f4ca4e39483ac3ffed52b3f70a55d](https://github.com/ggerganov/llama.cpp/commit/9de9672adb0f4ca4e39483ac3ffed52b3f70a55d)<br>2025-10-22 20:05:15<br>sycl: use async memory allocation to fix<br> crashes during graph recording<br>Matthew Michel  Log: [log](./log/9de9672adb0f4ca4e39483ac3ffed52b3f70a55d)|89.0%<br>17638/17680|6.71|tg=8.15<br>pp=77.32|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2](https://github.com/ggerganov/llama.cpp/commit/6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2)<br>2025-10-21 01:21:12<br>sycl : add PAD_REFLECT_D1 operator suppo<br>rt<br>YehuditE  Log: [log](./log/6de8ed75196c7cd98c1f34bbf3a7452451ba8ac2)|89.0%<br>17636/17678|6.78|tg=7.72<br>pp=76.85|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[2330de7b847ca84eac766df372c604c26db72747](https://github.com/ggerganov/llama.cpp/commit/2330de7b847ca84eac766df372c604c26db72747)<br>2025-10-20 11:08:32<br>SYCL: Add support for FLOOR,CEIL,ROUND a<br>nd TRUNC unary operators<br>safranowith  Log: [log](./log/2330de7b847ca84eac766df372c604c26db72747)|92.0%<br>17638/17678|6.81|tg=7.77<br>pp=76.8|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[ceff6bb253dd306f5404d7ccb3f11fadafe71b52](https://github.com/ggerganov/llama.cpp/commit/ceff6bb253dd306f5404d7ccb3f11fadafe71b52)<br>2025-10-17 05:36:40<br>SYCL SET operator optimized for F32 tens<br>ors<br>GittyBurstein  Log: [log](./log/ceff6bb253dd306f5404d7ccb3f11fadafe71b52)|89.0%<br>17622/17662|6.74|tg=7.64<br>pp=76.58|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[b22572e97dc51757d3ebe917a5a283385010ec68](https://github.com/ggerganov/llama.cpp/commit/b22572e97dc51757d3ebe917a5a283385010ec68)<br>2025-10-16 16:26:21<br>sycl : add ARANGE operator<br>GittyBurstein  Log: [log](./log/b22572e97dc51757d3ebe917a5a283385010ec68)|92.0%<br>17622/17662|6.8|tg=7.64<br>pp=76.49|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[ee50ee1eadff58777ae746827b04de7ba0befc55](https://github.com/ggerganov/llama.cpp/commit/ee50ee1eadff58777ae746827b04de7ba0befc55)<br>2025-10-16 07:21:28<br>SYCL: Add GGML_OP_MEAN operator support<br>yael-works  Log: [log](./log/ee50ee1eadff58777ae746827b04de7ba0befc55)|92.0%<br>17622/17662|6.72|tg=7.65<br>pp=76.68|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[c7be9febcbafa9af7d1b9443f86475c59c9c5f87](https://github.com/ggerganov/llama.cpp/commit/c7be9febcbafa9af7d1b9443f86475c59c9c5f87)<br>2025-10-12 21:53:35<br>[SYCL] fix UT fault cases: count-equal, <br>argsort, pad OPs<br>Neo Zhang Jianyu  Log: [log](./log/c7be9febcbafa9af7d1b9443f86475c59c9c5f87)|92.0%<br>15938/15978|6.81|tg=7.69<br>pp=76.79|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[b2602137557b2b28a39e03612717d85ead9a6f5a](https://github.com/ggerganov/llama.cpp/commit/b2602137557b2b28a39e03612717d85ead9a6f5a)<br>2025-10-09 15:25:11<br>[SYCL] refactor soft_max, add soft_max_b<br>ack<br>Neo Zhang Jianyu  Log: [log](./log/b2602137557b2b28a39e03612717d85ead9a6f5a)|92.0%<br>NA|6.81|tg=7.64<br>pp=76.6|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[2be72c2b121ee99f33927149265ce6073ade9e59](https://github.com/ggerganov/llama.cpp/commit/2be72c2b121ee99f33927149265ce6073ade9e59)<br>2025-10-02 15:16:25<br>SYCL: Update to oneAPI 2025.2<br>Neo Zhang Jianyu  Log: [log](./log/2be72c2b121ee99f33927149265ce6073ade9e59)|89.0%<br>NA|6.87|tg=7.62<br>pp=76.71|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[3ecb2f671a2f49d56357f99d135a94e841759178](https://github.com/ggerganov/llama.cpp/commit/3ecb2f671a2f49d56357f99d135a94e841759178)<br>2025-09-22 19:13:00<br>ggml : implement set_rows with i32 index<br><br>Sigbjørn Skjæret  Log: [log](./log/3ecb2f671a2f49d56357f99d135a94e841759178)|92.0%<br>NA|6.85|tg=7.68<br>pp=76.89|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[c0b45097c33e2667a94444f08cc9e36bec0a5e2e](https://github.com/ggerganov/llama.cpp/commit/c0b45097c33e2667a94444f08cc9e36bec0a5e2e)<br>2025-09-18 13:46:17<br>rename optimize_graph to graph_optimize<br>Jeff Bolz  Log: [log](./log/c0b45097c33e2667a94444f08cc9e36bec0a5e2e)|92.0%<br>NA|6.85|tg=7.7<br>pp=76.89|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[3913f8730ec6d6245480affc30ae3049107956f4](https://github.com/ggerganov/llama.cpp/commit/3913f8730ec6d6245480affc30ae3049107956f4)<br>2025-09-16 15:25:57<br>ggml : fix padding in timestep embedding<br> kernels<br>Daniel Bevenius  Log: [log](./log/3913f8730ec6d6245480affc30ae3049107956f4)|92.0%<br>NA|6.78|tg=7.62<br>pp=76.55|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[b907255f4bd169b0dc7dca9553b4c54af5170865](https://github.com/ggerganov/llama.cpp/commit/b907255f4bd169b0dc7dca9553b4c54af5170865)<br>2025-09-15 19:51:35<br>SYCL: Add COUNT_EQUAL operator support<br>yael-works  Log: [log](./log/b907255f4bd169b0dc7dca9553b4c54af5170865)|92.0%<br>NA|6.77|tg=7.68<br>pp=76.78|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[704d90c987cdf00751567b2088c4e54742aa2d3f](https://github.com/ggerganov/llama.cpp/commit/704d90c987cdf00751567b2088c4e54742aa2d3f)<br>2025-09-12 09:15:12<br>Revert "sycl: add usage of enqueue_funct<br>ions extension<br>Neo Zhang Jianyu  Log: [log](./log/704d90c987cdf00751567b2088c4e54742aa2d3f)|92.0%<br>NA|6.77|tg=7.7<br>pp=76.69|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[e68aa10d8f3d26fdad5b912540362d79de5460e3](https://github.com/ggerganov/llama.cpp/commit/e68aa10d8f3d26fdad5b912540362d79de5460e3)<br>2025-09-08 13:10:07<br>vulkan: sort graph to allow more paralle<br>l execution<br>Jeff Bolz  Log: [log](./log/e68aa10d8f3d26fdad5b912540362d79de5460e3)|92.0%<br>NA|6.83|tg=7.6<br>pp=76.94|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[0a1b3982cd0bd18730d50a693053b88c13fd04a6](https://github.com/ggerganov/llama.cpp/commit/0a1b3982cd0bd18730d50a693053b88c13fd04a6)<br>2025-09-04 16:38:49<br>ggml: add ops for WAN video model<br>leejet  Log: [log](./log/0a1b3982cd0bd18730d50a693053b88c13fd04a6)|92.0%<br>NA|6.85|tg=7.66<br>pp=76.82|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select the Website Name', 0)|0/0<br>2025.0.4|
|[8b696861364360770e9f61a3422d32941a477824](https://github.com/ggerganov/llama.cpp/commit/8b696861364360770e9f61a3422d32941a477824)<br>2025-08-27 00:27:49<br>SYCL: fix rms_norm_mul_add for tensor di<br>m not a multiple of sg_size<br>Akarshan Biswas  Log: [log](./log/8b696861364360770e9f61a3422d32941a477824)|92.0%<br>NA|7.47|tg=7.64<br>pp=76.77|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[0a9b43e507a359ca392c037cf341f55137ad0b69](https://github.com/ggerganov/llama.cpp/commit/0a9b43e507a359ca392c037cf341f55137ad0b69)<br>2025-08-23 08:35:21<br>vulkan : support ggml_mean<br>Acly  Log: [log](./log/0a9b43e507a359ca392c037cf341f55137ad0b69)|92.0%<br>NA|7.5|tg=7.68<br>pp=76.89|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[29f538ac630d6544406a0702476e36808a6bd1b3](https://github.com/ggerganov/llama.cpp/commit/29f538ac630d6544406a0702476e36808a6bd1b3)<br>2025-08-21 06:12:28<br>examples : remove references to `make` i<br>n examples [no ci]<br>Daniel Bevenius  Log: [log](./log/29f538ac630d6544406a0702476e36808a6bd1b3)|92.0%<br>NA|7.63|tg=7.64<br>pp=76.8|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[f4586ee5986d6f965becb37876d6f3666478a961](https://github.com/ggerganov/llama.cpp/commit/f4586ee5986d6f965becb37876d6f3666478a961)<br>2025-08-12 13:58:22<br>sycl: Fix and disable more configuration<br>s of mul_mat<br>Romain Biessy  Log: [log](./log/f4586ee5986d6f965becb37876d6f3666478a961)|94.0%<br>NA|7.64|tg=7.68<br>pp=76.96|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[cd6983d56d2cce94ecb86bb114ae8379a609073c](https://github.com/ggerganov/llama.cpp/commit/cd6983d56d2cce94ecb86bb114ae8379a609073c)<br>2025-08-08 21:37:22<br>ggml : fix field name when new ggml_back<br>end<br>AN Long  Log: [log](./log/cd6983d56d2cce94ecb86bb114ae8379a609073c)|94.0%<br>NA|7.37|tg=7.53<br>pp=75.95|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|6/0<br>2025.0.4|
|[fd1234cb468935ea087d6929b2487926c3afff4b](https://github.com/ggerganov/llama.cpp/commit/fd1234cb468935ea087d6929b2487926c3afff4b)<br>2025-08-05 22:10:36<br>llama : add gpt-oss<br>Georgi Gerganov  Log: [log](./log/fd1234cb468935ea087d6929b2487926c3afff4b)|91.0%<br>10828/10829|7.46|tg=7.59<br>pp=76.5|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|6/0<br>2025.0.4|
|[3306ceabf02e3df66666e5851800e843c7ca207e](https://github.com/ggerganov/llama.cpp/commit/3306ceabf02e3df66666e5851800e843c7ca207e)<br>2025-08-05 18:39:55<br>sycl: fix mul_mat selection<br>Romain Biessy  Log: [log](./log/3306ceabf02e3df66666e5851800e843c7ca207e)|94.0%<br>NA|7.59|tg=7.64<br>pp=76.9|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|6/0<br>2025.0.4|
|[15e92fd33791e60a4ddb5970b47242a855c27117](https://github.com/ggerganov/llama.cpp/commit/15e92fd33791e60a4ddb5970b47242a855c27117)<br>2025-08-02 17:13:05<br>cuda, sycl : fix batched gemm when ne02 <br>== 1 && ne03 > 1<br>Georgi Gerganov  Log: [log](./log/15e92fd33791e60a4ddb5970b47242a855c27117)|91.0%<br>8292/8325|7.55|tg=7.69<br>pp=77.08|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|6/0<br>2025.0.4|
|[cd1fce6d4f9c191f1c7429cc96f61281c3b63ffc](https://github.com/ggerganov/llama.cpp/commit/cd1fce6d4f9c191f1c7429cc96f61281c3b63ffc)<br>2025-07-28 20:32:15<br>SYCL: Add set_rows support for quantized<br> types<br>Akarshan Biswas  Log: [log](./log/cd1fce6d4f9c191f1c7429cc96f61281c3b63ffc)|91.0%<br>8131/8132|7.54|tg=7.53<br>pp=76.34|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|6/0<br>2025.0.4|
|[afc0e8969896ada62238da07b98731e5a4b12ba4](https://github.com/ggerganov/llama.cpp/commit/afc0e8969896ada62238da07b98731e5a4b12ba4)<br>2025-07-28 11:05:53<br>sycl: refactor quantization to q8_1<br>Alberto Cabrera Pérez  Log: [log](./log/afc0e8969896ada62238da07b98731e5a4b12ba4)|94.0%<br>NA|7.52|tg=7.55<br>pp=76.33|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[bbfc84927481d1e59d8af6939b93b76850f0ab53](https://github.com/ggerganov/llama.cpp/commit/bbfc84927481d1e59d8af6939b93b76850f0ab53)<br>2025-07-27 17:52:58<br>SYCL: add ops doc<br>Akarshan Biswas  Log: [log](./log/bbfc84927481d1e59d8af6939b93b76850f0ab53)|94.0%<br>NA|7.61|tg=7.57<br>pp=76.51|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[4ec6291a2407404de52239c1f9ca66c07e7fb28b](https://github.com/ggerganov/llama.cpp/commit/4ec6291a2407404de52239c1f9ca66c07e7fb28b)<br>2025-07-24 13:50:41<br>sycl: fix undefined variable in work gro<br>up size check<br>Donghyeon Jeong  Log: [log](./log/4ec6291a2407404de52239c1f9ca66c07e7fb28b)|94.0%<br>NA|7.45|tg=7.57<br>pp=76.67|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[cb4a63aad6650c2b536a7578403935388cb2920e](https://github.com/ggerganov/llama.cpp/commit/cb4a63aad6650c2b536a7578403935388cb2920e)<br>2025-07-24 11:09:57<br>sycl: fixed semantics of block offset ca<br>lculation<br>Alberto Cabrera Pérez  Log: [log](./log/cb4a63aad6650c2b536a7578403935388cb2920e)|94.0%<br>NA|7.55|tg=7.63<br>pp=76.88|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[cd465d823c378853f1f6570eebfb77f69c7e1d39](https://github.com/ggerganov/llama.cpp/commit/cd465d823c378853f1f6570eebfb77f69c7e1d39)<br>2025-07-21 18:39:29<br>sycl: Fix im2col<br>Romain Biessy  Log: [log](./log/cd465d823c378853f1f6570eebfb77f69c7e1d39)|94.0%<br>NA|7.47|tg=7.63<br>pp=76.87|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[349ea79fcebc75b0c55bf61594a47736966d4f95](https://github.com/ggerganov/llama.cpp/commit/349ea79fcebc75b0c55bf61594a47736966d4f95)<br>2025-07-18 10:23:14<br>use max work group size for device to re<br>place the magic number<br>Neo Zhang Jianyu  Log: [log](./log/349ea79fcebc75b0c55bf61594a47736966d4f95)|94.0%<br>NA|7.61|tg=7.57<br>pp=76.47|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[bdca38376f7e8dd928defe01ce6a16218a64b040](https://github.com/ggerganov/llama.cpp/commit/bdca38376f7e8dd928defe01ce6a16218a64b040)<br>2025-07-14 18:12:42<br>sycl: Hotfix for non dnnl codepath<br>Anton Mitkov  Log: [log](./log/bdca38376f7e8dd928defe01ce6a16218a64b040)|94.0%<br>NA|7.43|tg=7.55<br>pp=76.64|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[0f4c6ec0f1a9607ba67071f8a02c69b0afc2f91e](https://github.com/ggerganov/llama.cpp/commit/0f4c6ec0f1a9607ba67071f8a02c69b0afc2f91e)<br>2025-07-14 15:07:55<br>SYCL: use 1D kernel for set_rows<br>Akarshan Biswas  Log: [log](./log/0f4c6ec0f1a9607ba67071f8a02c69b0afc2f91e)|94.0%<br>NA|7.48|tg=7.56<br>pp=76.67|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[65a3ebb0aa56d6c501466e0f950ad15105fd32d8](https://github.com/ggerganov/llama.cpp/commit/65a3ebb0aa56d6c501466e0f950ad15105fd32d8)<br>2025-07-14 10:37:35<br>sycl: Batched mulmat rework for oneDNN d<br>ispatch<br>Anton Mitkov  Log: [log](./log/65a3ebb0aa56d6c501466e0f950ad15105fd32d8)|94.0%<br>NA|7.48|tg=7.64<br>pp=77.01|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|8/0<br>2025.0.4|
|[05fec5bd298d3c0243cbb9336e59b8b6aff75a81](https://github.com/ggerganov/llama.cpp/commit/05fec5bd298d3c0243cbb9336e59b8b6aff75a81)<br>2025-07-13 10:36:33<br>ggml : add build-time message to remind <br>about ggml_set_rows<br>Georgi Gerganov  Log: [log](./log/05fec5bd298d3c0243cbb9336e59b8b6aff75a81)|94.0%<br>NA|7.35|tg=7.67<br>pp=77.24|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[704bb7a71c01dc07c1478b85f6322bf5dfde1eaf](https://github.com/ggerganov/llama.cpp/commit/704bb7a71c01dc07c1478b85f6322bf5dfde1eaf)<br>2025-07-10 13:59:38<br>SYCL: Initial set_rows kernel implementa<br>tion<br>Akarshan Biswas  Log: [log](./log/704bb7a71c01dc07c1478b85f6322bf5dfde1eaf)|94.0%<br>NA|7.44|tg=7.57<br>pp=76.69|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[98bab638fb28cf95a5a66dd2d51b40d6c8f6d69a](https://github.com/ggerganov/llama.cpp/commit/98bab638fb28cf95a5a66dd2d51b40d6c8f6d69a)<br>2025-07-09 18:16:12<br>ggml : add ggml_scale_bias<br>Xuan-Son Nguyen  Log: [log](./log/98bab638fb28cf95a5a66dd2d51b40d6c8f6d69a)|94.0%<br>NA|7.42|tg=7.58<br>pp=76.68|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[4d0dcd4a06080e796e6742a88f2ffa7fc41b28b8](https://github.com/ggerganov/llama.cpp/commit/4d0dcd4a06080e796e6742a88f2ffa7fc41b28b8)<br>2025-07-08 10:15:21<br>cuda : fix rope with partial rotation an<br>d non-cont src<br>Georgi Gerganov  Log: [log](./log/4d0dcd4a06080e796e6742a88f2ffa7fc41b28b8)|94.0%<br>NA|7.35|tg=7.58<br>pp=76.05|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[28657a8229b5adc6028cf1c4ed62191792d2fdb0](https://github.com/ggerganov/llama.cpp/commit/28657a8229b5adc6028cf1c4ed62191792d2fdb0)<br>2025-07-03 23:07:22<br>ggml : implement GEGLU_ERF and GEGLU_QUI<br>CK ops<br>Sigbjørn Skjæret  Log: [log](./log/28657a8229b5adc6028cf1c4ed62191792d2fdb0)|94.0%<br>NA|7.31|tg=7.42<br>pp=76.52|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[7b63a71a6b0f54effe9b94073d4d0519dcf53676](https://github.com/ggerganov/llama.cpp/commit/7b63a71a6b0f54effe9b94073d4d0519dcf53676)<br>2025-07-03 11:00:03<br>Fix conditional enabling following arch <br>checks for ggml-sycl<br>Nicolò Scipione  Log: [log](./log/7b63a71a6b0f54effe9b94073d4d0519dcf53676)|94.0%<br>NA|7.48|tg=7.6<br>pp=76.85|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: Select your website type', 0)|0/0<br>2025.0.4|
|[a70c8a0c4b4c1606cd9a0ba889ce61aa88610095](https://github.com/ggerganov/llama.cpp/commit/a70c8a0c4b4c1606cd9a0ba889ce61aa88610095)<br>2025-07-03 10:53:35<br>kv-cache : use ggml_set_rows<br>Georgi Gerganov  Log: [log](./log/a70c8a0c4b4c1606cd9a0ba889ce61aa88610095)|94.0%<br>NA|4.04|tg=4.2<br>pp=76.77|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[a7417f55945eb7c7a5ea6807e66564b8066a4e50](https://github.com/ggerganov/llama.cpp/commit/a7417f55945eb7c7a5ea6807e66564b8066a4e50)<br>2025-06-30 14:52:02<br>ggml-cpu: sycl: Re-enable exp f16<br>Romain Biessy  Log: [log](./log/a7417f55945eb7c7a5ea6807e66564b8066a4e50)|94.0%<br>NA|4.05|tg=4.2<br>pp=76.93|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[e9b6350e61d592634263a14b3d77ecbf6c1fb096](https://github.com/ggerganov/llama.cpp/commit/e9b6350e61d592634263a14b3d77ecbf6c1fb096)<br>2025-06-30 10:17:18<br>scripts : make the shell scripts cross-p<br>latform<br>Vedran Miletić  Log: [log](./log/e9b6350e61d592634263a14b3d77ecbf6c1fb096)|94.0%<br>NA|4.05|tg=4.2<br>pp=76.93|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[f47c1d7106e49062279bcc57fc1077c0db61e278](https://github.com/ggerganov/llama.cpp/commit/f47c1d7106e49062279bcc57fc1077c0db61e278)<br>2025-06-29 21:07:58<br>SYCL: disable faulty fp16 exp kernel<br>Akarshan Biswas  Log: [log](./log/f47c1d7106e49062279bcc57fc1077c0db61e278)|94.0%<br>NA|4.05|tg=4.2<br>pp=76.85|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[a0535ffa0d35fccfec3e1a0a3bfc9dbb6054d7c0](https://github.com/ggerganov/llama.cpp/commit/a0535ffa0d35fccfec3e1a0a3bfc9dbb6054d7c0)<br>2025-06-29 11:04:10<br>ggml : implement REGLU/GEGLU/SWIGLU ops<br>Sigbjørn Skjæret  Log: [log](./log/a0535ffa0d35fccfec3e1a0a3bfc9dbb6054d7c0)|91.0%<br>6236/6239|4.06|tg=4.2<br>pp=76.87|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[ec68e84c32325a3417fbcd2e60d4bda6adb4e4bc](https://github.com/ggerganov/llama.cpp/commit/ec68e84c32325a3417fbcd2e60d4bda6adb4e4bc)<br>2025-06-27 21:50:57<br>ggml : support bcast ggml_soft_max_ext, <br>ggml_flash_attn_ext<br>Georgi Gerganov  Log: [log](./log/ec68e84c32325a3417fbcd2e60d4bda6adb4e4bc)|94.0%<br>NA|4.05|tg=4.2<br>pp=76.98|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[2bf9d539dd158345e3a3b096e16474af535265b4](https://github.com/ggerganov/llama.cpp/commit/2bf9d539dd158345e3a3b096e16474af535265b4)<br>2025-06-25 17:09:55<br>sycl: GGML_SYCL_DISABLE_OPT on by defaul<br>t for all Intel Devices<br>Anton Mitkov  Log: [log](./log/2bf9d539dd158345e3a3b096e16474af535265b4)|94.0%<br>NA|4.01|tg=4.14<br>pp=76.84|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[8308f98c7fb778e54bf75538f5234d8bd20915e9](https://github.com/ggerganov/llama.cpp/commit/8308f98c7fb778e54bf75538f5234d8bd20915e9)<br>2025-06-20 15:07:21<br>sycl: add usage of enqueue_functions ext<br>ension<br>Nicolò Scipione  Log: [log](./log/8308f98c7fb778e54bf75538f5234d8bd20915e9)|94.0%<br>NA|3.99|tg=4.14<br>pp=76.21|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[600e3e9b50c1f0c9fc4a70356241fd87f00e8e14](https://github.com/ggerganov/llama.cpp/commit/600e3e9b50c1f0c9fc4a70356241fd87f00e8e14)<br>2025-06-19 11:40:21<br>sycl: Cleanup codepaths in Get Rows in s<br>ycl backend<br>Anton Mitkov  Log: [log](./log/600e3e9b50c1f0c9fc4a70356241fd87f00e8e14)|94.0%<br>NA|3.99|tg=4.09<br>pp=76.51|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[40643edb86eb10b471b0f57d4f3f7eb0e06a0df7](https://github.com/ggerganov/llama.cpp/commit/40643edb86eb10b471b0f57d4f3f7eb0e06a0df7)<br>2025-06-13 17:32:56<br>sycl: fix docker image<br>Svetlozar Georgiev  Log: [log](./log/40643edb86eb10b471b0f57d4f3f7eb0e06a0df7)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2025.0.4|
|[0889eba570126f8a2f5a0e88fde776bbc91cca66](https://github.com/ggerganov/llama.cpp/commit/0889eba570126f8a2f5a0e88fde776bbc91cca66)<br>2025-06-13 08:51:39<br>sycl: Adding additional cpy dbg print ou<br>tput<br>Anton Mitkov  Log: [log](./log/0889eba570126f8a2f5a0e88fde776bbc91cca66)|97.0%<br>NA|3.99|tg=4.13<br>pp=76.67|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[c61285e7396c8e526fe7794c19e8d4f1c99bfc51](https://github.com/ggerganov/llama.cpp/commit/c61285e7396c8e526fe7794c19e8d4f1c99bfc51)<br>2025-06-13 08:45:37<br>SYCL: Bump oneMath commit<br>Ewan Crawford  Log: [log](./log/c61285e7396c8e526fe7794c19e8d4f1c99bfc51)|97.0%<br>NA|3.99|tg=4.13<br>pp=76.61|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[ed52f3668e633423054a4eab61bb7efee47025ab](https://github.com/ggerganov/llama.cpp/commit/ed52f3668e633423054a4eab61bb7efee47025ab)<br>2025-06-12 14:15:11<br>sycl: Remove not needed copy f16->f32 fo<br>r dnnl mul mat<br>Anton Mitkov  Log: [log](./log/ed52f3668e633423054a4eab61bb7efee47025ab)|97.0%<br>NA|3.98|tg=4.13<br>pp=76.72|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[f470bc36bed4d836b9de5a483fa0dfaee176d6f5](https://github.com/ggerganov/llama.cpp/commit/f470bc36bed4d836b9de5a483fa0dfaee176d6f5)<br>2025-06-09 22:47:13<br>ggml-cpu : split arch-specific implement<br>ations<br>xctan  Log: [log](./log/f470bc36bed4d836b9de5a483fa0dfaee176d6f5)|100.0%<br>NA|4.0|tg=4.12<br>pp=76.69|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[b460d16ae858c6624fd37aec316622a4060ca325](https://github.com/ggerganov/llama.cpp/commit/b460d16ae858c6624fd37aec316622a4060ca325)<br>2025-06-09 11:47:07<br>sycl: Add reorder to Q6_K mmvq implement<br>ation<br>Nicolò Scipione  Log: [log](./log/b460d16ae858c6624fd37aec316622a4060ca325)|100.0%<br>NA|3.98|tg=4.13<br>pp=76.69|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[228f34c9ceefa3ea4f4d6933edd858121e8106cb](https://github.com/ggerganov/llama.cpp/commit/228f34c9ceefa3ea4f4d6933edd858121e8106cb)<br>2025-06-07 18:58:20<br>SYCL: Implement few same quantized type <br>copy kernels<br>Akarshan Biswas  Log: [log](./log/228f34c9ceefa3ea4f4d6933edd858121e8106cb)|100.0%<br>NA|4.0|tg=4.13<br>pp=76.79|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[663445b0deb21fb602176da030d4154197a4fca6](https://github.com/ggerganov/llama.cpp/commit/663445b0deb21fb602176da030d4154197a4fca6)<br>2025-06-02 10:12:20<br>sycl: quantize and reorder the input to <br>q8_1 when reorder is enabled<br>Atharva Dubey  Log: [log](./log/663445b0deb21fb602176da030d4154197a4fca6)|97.0%<br>5526/5527|4.0|tg=4.13<br>pp=76.66|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[d337252acf14a91a685c355fa4f3f599a8068207](https://github.com/ggerganov/llama.cpp/commit/d337252acf14a91a685c355fa4f3f599a8068207)<br>2025-05-31 12:39:19<br>cmake : Fix broken CMake error messages<br>Kai Pastor  Log: [log](./log/d337252acf14a91a685c355fa4f3f599a8068207)|100.0%<br>NA|4.0|tg=4.12<br>pp=76.75|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[b49a8ff96b769b8a4c36d89fb783ec0135be582b](https://github.com/ggerganov/llama.cpp/commit/b49a8ff96b769b8a4c36d89fb783ec0135be582b)<br>2025-05-30 19:40:57<br>SYCL: Add mrope kernel<br>Akarshan Biswas  Log: [log](./log/b49a8ff96b769b8a4c36d89fb783ec0135be582b)|100.0%<br>NA|3.98|tg=4.13<br>pp=76.61|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[f3101a8cc665f73217c752a10a7042889275cfbc](https://github.com/ggerganov/llama.cpp/commit/f3101a8cc665f73217c752a10a7042889275cfbc)<br>2025-05-27 20:52:59<br>SYCL: add gelu_erf kernel<br>Akarshan Biswas  Log: [log](./log/f3101a8cc665f73217c752a10a7042889275cfbc)|100.0%<br>NA|4.0|tg=4.13<br>pp=76.59|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[6f180b915c9ed9ec0c240b5dcd64644988fb5e82](https://github.com/ggerganov/llama.cpp/commit/6f180b915c9ed9ec0c240b5dcd64644988fb5e82)<br>2025-05-26 21:10:36<br>SYCL: Add non contiguous support in RMS_<br>NORM and NORM kernels<br>Akarshan Biswas  Log: [log](./log/6f180b915c9ed9ec0c240b5dcd64644988fb5e82)|97.0%<br>NA|3.99|tg=4.12<br>pp=76.88|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[9012eb9b454a82eaa4cd77ae904c0ea391e4db42](https://github.com/ggerganov/llama.cpp/commit/9012eb9b454a82eaa4cd77ae904c0ea391e4db42)<br>2025-05-26 10:28:53<br>sycl: Add more debug prints<br>Romain Biessy  Log: [log](./log/9012eb9b454a82eaa4cd77ae904c0ea391e4db42)|97.0%<br>NA|3.98|tg=4.13<br>pp=76.92|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[515fdbf7ed839dfe6a24aeb6225936609a7f6d6d](https://github.com/ggerganov/llama.cpp/commit/515fdbf7ed839dfe6a24aeb6225936609a7f6d6d)<br>2025-05-25 12:38:37<br>SYCL: revert "sycl: simplify bin_bcast_k<br>ernel<br>Akarshan Biswas  Log: [log](./log/515fdbf7ed839dfe6a24aeb6225936609a7f6d6d)|97.0%<br>NA|3.98|tg=4.13<br>pp=76.82|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[d394a9aedc50a13b7f6373416f7c1ccabfe79c32](https://github.com/ggerganov/llama.cpp/commit/d394a9aedc50a13b7f6373416f7c1ccabfe79c32)<br>2025-05-22 13:54:43<br>sycl : Remove waits from function calls<br>Nicolò Scipione  Log: [log](./log/d394a9aedc50a13b7f6373416f7c1ccabfe79c32)|94.0%<br>5503/5527|3.99|tg=4.13<br>pp=76.66|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[6b56a64690a318fcabcd7739ac7e314d44785ea8](https://github.com/ggerganov/llama.cpp/commit/6b56a64690a318fcabcd7739ac7e314d44785ea8)<br>2025-05-22 09:24:09<br>SYCL: Avoid using with SYCL-Graph for un<br>supported nodes<br>Ewan Crawford  Log: [log](./log/6b56a64690a318fcabcd7739ac7e314d44785ea8)|94.0%<br>5502/5527|3.99|tg=4.13<br>pp=76.38|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[4245e622e0cc3af1ca3056104e465dc4d303bd7d](https://github.com/ggerganov/llama.cpp/commit/4245e622e0cc3af1ca3056104e465dc4d303bd7d)<br>2025-05-20 10:34:15<br>sycl: disable reorder for sycl mulmat<br>Svetlozar Georgiev  Log: [log](./log/4245e622e0cc3af1ca3056104e465dc4d303bd7d)|94.0%<br>5495/5519|3.98|tg=4.13<br>pp=76.33|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[f7c9429c85748cde9599499601ba48d0057722e6](https://github.com/ggerganov/llama.cpp/commit/f7c9429c85748cde9599499601ba48d0057722e6)<br>2025-05-20 02:54:43<br>sycl : Overcoming workaround for mmap<br>Nicolò Scipione  Log: [log](./log/f7c9429c85748cde9599499601ba48d0057722e6)|94.0%<br>5493/5519|3.97|tg=4.13<br>pp=75.92|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[725f23f1f3f0d3adf49f95d8dfa6e7c74adff149](https://github.com/ggerganov/llama.cpp/commit/725f23f1f3f0d3adf49f95d8dfa6e7c74adff149)<br>2025-05-19 14:38:20<br>sycl : backend documentation review<br>Alberto Cabrera Pérez  Log: [log](./log/725f23f1f3f0d3adf49f95d8dfa6e7c74adff149)|94.0%<br>5496/5519|3.97|tg=4.13<br>pp=76.27|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[f71f40a2847d4c9f57b86cd206e0a27b2bfb6d1c](https://github.com/ggerganov/llama.cpp/commit/f71f40a2847d4c9f57b86cd206e0a27b2bfb6d1c)<br>2025-05-19 11:46:09<br>ci : upgraded oneAPI version in SYCL wor<br>kflows and dockerfile<br>Alberto Cabrera Pérez  Log: [log](./log/f71f40a2847d4c9f57b86cd206e0a27b2bfb6d1c)|94.0%<br>5495/5519|3.99|tg=4.13<br>pp=76.22|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[0a338ed013c23aecdce6449af736a35a465fa60f](https://github.com/ggerganov/llama.cpp/commit/0a338ed013c23aecdce6449af736a35a465fa60f)<br>2025-05-16 12:15:29<br>sycl : fixed compilation warnings<br>Łukasz Ślusarczyk  Log: [log](./log/0a338ed013c23aecdce6449af736a35a465fa60f)|94.0%<br>5494/5519|3.98|tg=4.14<br>pp=75.54|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[9c404ed54c3c8d8d2aa3153313766c8286739387](https://github.com/ggerganov/llama.cpp/commit/9c404ed54c3c8d8d2aa3153313766c8286739387)<br>2025-05-15 16:53:41<br>sycl: use oneDNN for matrices multiplica<br>tion<br>Łukasz Ślusarczyk  Log: [log](./log/9c404ed54c3c8d8d2aa3153313766c8286739387)|97.0%<br>NA|3.92|tg=4.12<br>pp=75.99|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[02cdd2d8b092b5a4bb18e013c6887ce49ba20ac5](https://github.com/ggerganov/llama.cpp/commit/02cdd2d8b092b5a4bb18e013c6887ce49ba20ac5)<br>2025-05-15 16:39:52<br>sycl: simplify bin_bcast_kernel<br>Atharva Dubey  Log: [log](./log/02cdd2d8b092b5a4bb18e013c6887ce49ba20ac5)|94.0%<br>5493/5519|3.97|tg=4.13<br>pp=76.26|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[64bb51cf90d3eede8c150a23d59a0c718b78065b](https://github.com/ggerganov/llama.cpp/commit/64bb51cf90d3eede8c150a23d59a0c718b78065b)<br>2025-05-15 16:35:44<br>sycl: reordered Q4_K MMVQ<br>Svetlozar Georgiev  Log: [log](./log/64bb51cf90d3eede8c150a23d59a0c718b78065b)|97.0%<br>NA|3.99|tg=4.12<br>pp=76.45|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[14492144c286bbf38bb1903128403d9e2ebad54c](https://github.com/ggerganov/llama.cpp/commit/14492144c286bbf38bb1903128403d9e2ebad54c)<br>2025-05-12 06:15:32<br>enable dpcpp nightly builds with librari<br>es<br>Atharva Dubey  Log: [log](./log/14492144c286bbf38bb1903128403d9e2ebad54c)|97.0%<br>NA|3.97|tg=4.13<br>pp=76.62|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[17512a94d636c4b6c1332370acb3e5af3ca70918](https://github.com/ggerganov/llama.cpp/commit/17512a94d636c4b6c1332370acb3e5af3ca70918)<br>2025-05-09 16:34:08<br>sycl : implementation of reordered Q4_0 <br>MMVQ for Intel GPUs<br>Alberto Cabrera Pérez  Log: [log](./log/17512a94d636c4b6c1332370acb3e5af3ca70918)|97.0%<br>NA|3.98|tg=4.13<br>pp=76.27|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[8733e0cf6eefc7c7752297cc22d0836706f4222c](https://github.com/ggerganov/llama.cpp/commit/8733e0cf6eefc7c7752297cc22d0836706f4222c)<br>2025-05-08 10:08:01<br>sycl: addressing non-contiguous src1 mul<br>_mats<br>Alberto Cabrera Pérez  Log: [log](./log/8733e0cf6eefc7c7752297cc22d0836706f4222c)|97.0%<br>NA|4.0|tg=4.13<br>pp=76.6|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[1e333d5bba18e99bc328bb87ac1ee6a4e6260e0e](https://github.com/ggerganov/llama.cpp/commit/1e333d5bba18e99bc328bb87ac1ee6a4e6260e0e)<br>2025-05-06 20:27:06<br>SYCL: Disable reorder optimize by defaul<br>t and stop setting tensor extras when op<br>timize is disabled<br>Akarshan Biswas  Log: [log](./log/1e333d5bba18e99bc328bb87ac1ee6a4e6260e0e)|97.0%<br>NA|4.0|tg=4.19<br>pp=67.15|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[66645a5285d8c4c5f9a3b3f360d042baac2d820a](https://github.com/ggerganov/llama.cpp/commit/66645a5285d8c4c5f9a3b3f360d042baac2d820a)<br>2025-05-05 13:39:10<br>SYCL: Disable mul_mat kernels for noncon<br>tiguous tensor b<br>Akarshan Biswas  Log: [log](./log/66645a5285d8c4c5f9a3b3f360d042baac2d820a)|97.0%<br>NA|3.98|tg=4.19<br>pp=67.08|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[13b0a04597a4581cad4d9027a848f450c623801d](https://github.com/ggerganov/llama.cpp/commit/13b0a04597a4581cad4d9027a848f450c623801d)<br>2025-05-05 13:09:35<br>whisper: remove MSVC warnings pragmas<br>Daniel Bevenius  Log: [log](./log/13b0a04597a4581cad4d9027a848f450c623801d)|97.0%<br>NA|4.02|tg=4.19<br>pp=67.31|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[a4c340f974f9b7ac0c1aae897aabaa54549a97e5](https://github.com/ggerganov/llama.cpp/commit/a4c340f974f9b7ac0c1aae897aabaa54549a97e5)<br>2025-04-28 15:03:25<br>SYCL: Add all missing unary kernels<br>Akarshan Biswas  Log: [log](./log/a4c340f974f9b7ac0c1aae897aabaa54549a97e5)|97.0%<br>NA|4.0|tg=4.13<br>pp=76.88|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[514c45608f93f66106a712dee1abe062099ce790](https://github.com/ggerganov/llama.cpp/commit/514c45608f93f66106a712dee1abe062099ce790)<br>2025-04-25 17:37:51<br>change the reorder tensor from init to e<br>xecute OP<br>Neo Zhang Jianyu  Log: [log](./log/514c45608f93f66106a712dee1abe062099ce790)|100.0%<br>NA|4.0|tg=4.13<br>pp=76.97|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[5368ddda7a262d195b54687a31009dcc1f8b1602](https://github.com/ggerganov/llama.cpp/commit/5368ddda7a262d195b54687a31009dcc1f8b1602)<br>2025-04-21 19:13:30<br>SYCL: Add non-contiguous support in ROPE<br><br>Akarshan Biswas  Log: [log](./log/5368ddda7a262d195b54687a31009dcc1f8b1602)|100.0%<br>NA|3.98|tg=4.13<br>pp=76.99|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[8d6600576318dfc6b091fca744b0fd36a5e5255f](https://github.com/ggerganov/llama.cpp/commit/8d6600576318dfc6b091fca744b0fd36a5e5255f)<br>2025-04-18 19:27:56<br>SYCL: Refactor and enable FP16 in binary<br> broadcast OPs<br>Akarshan Biswas  Log: [log](./log/8d6600576318dfc6b091fca744b0fd36a5e5255f)|100.0%<br>NA|3.97|tg=4.13<br>pp=76.88|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[510676475f885ec064ff147af9f20ee7a9b12a50](https://github.com/ggerganov/llama.cpp/commit/510676475f885ec064ff147af9f20ee7a9b12a50)<br>2025-04-15 14:07:42<br>SYCL: Add ROPE vision kernel<br>Akarshan Biswas  Log: [log](./log/510676475f885ec064ff147af9f20ee7a9b12a50)|100.0%<br>NA|3.97|tg=4.09<br>pp=76.93|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[81c7e64fc239288e91a58adad9145110e0353822](https://github.com/ggerganov/llama.cpp/commit/81c7e64fc239288e91a58adad9145110e0353822)<br>2025-04-14 18:19:07<br>dsiable curl lib check, this action is m<br>issed by commit bd3f59f81289b920bcc597a2<br>08c14f55e39ed37e<br>Neo Zhang Jianyu  Log: [log](./log/81c7e64fc239288e91a58adad9145110e0353822)|100.0%<br>NA|4.0|tg=4.13<br>pp=76.89|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[75afa0ae31f0a51aaadcc5ff146eb7a32a7f9088](https://github.com/ggerganov/llama.cpp/commit/75afa0ae31f0a51aaadcc5ff146eb7a32a7f9088)<br>2025-04-14 17:53:53<br>SYCL: Fix im2col<br>Akarshan Biswas  Log: [log](./log/75afa0ae31f0a51aaadcc5ff146eb7a32a7f9088)|100.0%<br>NA|3.96|tg=4.12<br>pp=77.05|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[578754b3157d662c2fdd51eaa62b6c1f43d3172c](https://github.com/ggerganov/llama.cpp/commit/578754b3157d662c2fdd51eaa62b6c1f43d3172c)<br>2025-04-11 15:32:14<br>sycl: Support sycl_ext_oneapi_limited_gr<br>aph<br>Ewan Crawford  Log: [log](./log/578754b3157d662c2fdd51eaa62b6c1f43d3172c)|100.0%<br>NA|3.99|tg=4.12<br>pp=76.82|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[fccf9cae83e6c6cd31a0ecb403d237638e427d0a](https://github.com/ggerganov/llama.cpp/commit/fccf9cae83e6c6cd31a0ecb403d237638e427d0a)<br>2025-04-11 13:33:50<br>SYCL: Add fp16 type support to unary op <br>kernels<br>Akarshan Biswas  Log: [log](./log/fccf9cae83e6c6cd31a0ecb403d237638e427d0a)|100.0%<br>NA|3.97|tg=4.12<br>pp=76.18|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[fe92821ea9ae53f3088cf2699a9e102448295fa0](https://github.com/ggerganov/llama.cpp/commit/fe92821ea9ae53f3088cf2699a9e102448295fa0)<br>2025-04-09 12:32:13<br>ggml : add bilinear upscale support<br>Diego Devesa  Log: [log](./log/fe92821ea9ae53f3088cf2699a9e102448295fa0)|100.0%<br>NA|4.0|tg=4.13<br>pp=76.83|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[8ed71242f464dc0a3fb3cffcfe064e55bdec72f9](https://github.com/ggerganov/llama.cpp/commit/8ed71242f464dc0a3fb3cffcfe064e55bdec72f9)<br>2025-04-09 11:22:04<br>sycl: update documentation to use -no-cn<br>v<br>Romain Biessy  Log: [log](./log/8ed71242f464dc0a3fb3cffcfe064e55bdec72f9)|100.0%<br>NA|3.97|tg=4.12<br>pp=75.94|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[656babd6c21a3b9b3622324cfcc80a2ab78da25b](https://github.com/ggerganov/llama.cpp/commit/656babd6c21a3b9b3622324cfcc80a2ab78da25b)<br>2025-04-08 15:03:21<br>Revert "sycl:remove redundant memcopy in<br> function ggml_backend_sycl_buffer_set_t<br>ensor"<br>Neo Zhang Jianyu  Log: [log](./log/656babd6c21a3b9b3622324cfcc80a2ab78da25b)|100.0%<br>NA|4.0|tg=4.13<br>pp=77.01|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[518a01480eb3a7c80a4951b430db9dee55428310](https://github.com/ggerganov/llama.cpp/commit/518a01480eb3a7c80a4951b430db9dee55428310)<br>2025-04-07 23:22:57<br>sycl: remove redundant memcopy in functi<br>on ggml_backend_sycl_buffer_set_tensor<br>zhouwg  Log: [log](./log/518a01480eb3a7c80a4951b430db9dee55428310)|100.0%<br>NA|4.01|tg=4.13<br>pp=76.73|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[bd3f59f81289b920bcc597a208c14f55e39ed37e](https://github.com/ggerganov/llama.cpp/commit/bd3f59f81289b920bcc597a208c14f55e39ed37e)<br>2025-04-07 13:35:19<br>cmake : enable curl by default<br>Xuan-Son Nguyen  Log: [log](./log/bd3f59f81289b920bcc597a208c14f55e39ed37e)|100.0%<br>NA|3.98|tg=4.13<br>pp=76.74|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[94148ba330968bbfb8d9ecc67751bdc2218486cd](https://github.com/ggerganov/llama.cpp/commit/94148ba330968bbfb8d9ecc67751bdc2218486cd)<br>2025-04-04 16:00:46<br>sycl: allow ggml-sycl configuration and <br>compilation using Visual Studio project/<br>solution<br>Nicolò Scipione  Log: [log](./log/94148ba330968bbfb8d9ecc67751bdc2218486cd)|100.0%<br>NA|3.99|tg=4.13<br>pp=77.3|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[2004644b7a5da6fe080e51861ab583480280f1d3](https://github.com/ggerganov/llama.cpp/commit/2004644b7a5da6fe080e51861ab583480280f1d3)<br>2025-04-03 13:12:39<br>ci : add env variable in ggml-ci and doc<br>ument the same in SYCL.md<br>Atharva Dubey  Log: [log](./log/2004644b7a5da6fe080e51861ab583480280f1d3)|100.0%<br>NA|3.98|tg=4.13<br>pp=77.27|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[8bbf26083d93274240a20d16cda324441c57fcc6](https://github.com/ggerganov/llama.cpp/commit/8bbf26083d93274240a20d16cda324441c57fcc6)<br>2025-04-01 13:41:39<br>SYCL: switch to SYCL namespace<br>Akarshan Biswas  Log: [log](./log/8bbf26083d93274240a20d16cda324441c57fcc6)|100.0%<br>NA|3.98|tg=4.13<br>pp=76.12|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[82939705421f4ef27e924879fdeed6d7b5f6d769](https://github.com/ggerganov/llama.cpp/commit/82939705421f4ef27e924879fdeed6d7b5f6d769)<br>2025-04-01 10:24:29<br>SYCL: Rename oneMKL to oneMath<br>Romain Biessy  Log: [log](./log/82939705421f4ef27e924879fdeed6d7b5f6d769)|100.0%<br>NA|3.97|tg=4.12<br>pp=77.16|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[6c02a032fa21d69e881ef9a5c94ba28ebaf1d749](https://github.com/ggerganov/llama.cpp/commit/6c02a032fa21d69e881ef9a5c94ba28ebaf1d749)<br>2025-03-31 14:55:24<br>SYCL: Remove misleading ggml_sycl_op_fla<br>tten function<br>Akarshan Biswas  Log: [log](./log/6c02a032fa21d69e881ef9a5c94ba28ebaf1d749)|100.0%<br>NA|4.0|tg=4.13<br>pp=77.34|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[f17a3bb4e8b0aa24c0f86636d234aca7dc2cfa01](https://github.com/ggerganov/llama.cpp/commit/f17a3bb4e8b0aa24c0f86636d234aca7dc2cfa01)<br>2025-03-27 07:16:00<br>SYCL: implement memset ggml backend buff<br>er interface<br>Akarshan Biswas  Log: [log](./log/f17a3bb4e8b0aa24c0f86636d234aca7dc2cfa01)|100.0%<br>NA|3.99|tg=4.13<br>pp=77.08|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[e2f560175a195f63c3276972a3d1caec0bd13e05](https://github.com/ggerganov/llama.cpp/commit/e2f560175a195f63c3276972a3d1caec0bd13e05)<br>2025-03-25 16:10:18<br>SYCL: disable Q4_0 reorder optimization<br>Akarshan Biswas  Log: [log](./log/e2f560175a195f63c3276972a3d1caec0bd13e05)|100.0%<br>NA|3.99|tg=4.13<br>pp=76.8|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[c95fa362b3587d1822558f7e28414521075f254f](https://github.com/ggerganov/llama.cpp/commit/c95fa362b3587d1822558f7e28414521075f254f)<br>2025-03-24 23:05:38<br>ci: [SYCL] ggml-ci Use main GPU and enab<br>le sysman<br>Akarshan Biswas  Log: [log](./log/c95fa362b3587d1822558f7e28414521075f254f)|100.0%<br>NA|4.0|tg=4.19<br>pp=76.87|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[48d7021c61ceda6fcf1a7294d2115b8e1a53ae95](https://github.com/ggerganov/llama.cpp/commit/48d7021c61ceda6fcf1a7294d2115b8e1a53ae95)<br>2025-03-24 18:28:32<br>CI: fix SYCL build<br>Akarshan Biswas  Log: [log](./log/48d7021c61ceda6fcf1a7294d2115b8e1a53ae95)|100.0%<br>NA|4.0|tg=4.19<br>pp=76.81|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[1aa87ee53d05505247c54612e40f6a38c680b433](https://github.com/ggerganov/llama.cpp/commit/1aa87ee53d05505247c54612e40f6a38c680b433)<br>2025-03-21 14:58:47<br>[SYCL] Fix build on Windows when ccache <br>enabled<br>蕭澧邦  Log: [log](./log/1aa87ee53d05505247c54612e40f6a38c680b433)|100.0%<br>NA|3.97|tg=4.19<br>pp=76.95|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[9ffcc9e374080f73b16b7a351e6d76e7a8a19ce3](https://github.com/ggerganov/llama.cpp/commit/9ffcc9e374080f73b16b7a351e6d76e7a8a19ce3)<br>2025-03-21 02:15:56<br>sycl: cleanup oneDNN related code<br>Svetlozar Georgiev  Log: [log](./log/9ffcc9e374080f73b16b7a351e6d76e7a8a19ce3)|100.0%<br>NA|3.96|tg=4.19<br>pp=76.93|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[35cae5ba05a5292dc3108636a71ec59fa2f80ab7](https://github.com/ggerganov/llama.cpp/commit/35cae5ba05a5292dc3108636a71ec59fa2f80ab7)<br>2025-03-18 11:16:31<br>SYCL: using graphs is configurable by en<br>vironment variable and compile option<br>Łukasz Ślusarczyk  Log: [log](./log/35cae5ba05a5292dc3108636a71ec59fa2f80ab7)|100.0%<br>NA|3.98|tg=4.19<br>pp=77.24|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[7dfad387e3f6ac98d383ded2d175eb59736a3993](https://github.com/ggerganov/llama.cpp/commit/7dfad387e3f6ac98d383ded2d175eb59736a3993)<br>2025-03-18 07:27:50<br>llama: Add support for RWKV v7 architect<br>ure<br>Molly Sophia  Log: [log](./log/7dfad387e3f6ac98d383ded2d175eb59736a3993)|100.0%<br>NA|3.98|tg=4.19<br>pp=77.81|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[a53f7f7b8859f3e634415ab03e1e295b9861d7e6](https://github.com/ggerganov/llama.cpp/commit/a53f7f7b8859f3e634415ab03e1e295b9861d7e6)<br>2025-03-18 01:51:25<br>fixed compilation warnings in ggml-sycl<br>Łukasz Ślusarczyk  Log: [log](./log/a53f7f7b8859f3e634415ab03e1e295b9861d7e6)|100.0%<br>NA|4.0|tg=4.19<br>pp=77.58|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[b3c9a65673a63a6c9a75da24ee00d13499494e0c](https://github.com/ggerganov/llama.cpp/commit/b3c9a65673a63a6c9a75da24ee00d13499494e0c)<br>2025-03-17 07:15:12<br>SYCL: set extras only on GGML_TYPE_Q4_0<br>Akarshan Biswas  Log: [log](./log/b3c9a65673a63a6c9a75da24ee00d13499494e0c)|100.0%<br>NA|4.0|tg=4.15<br>pp=77.52|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[3d35d87b4113648e224b837bb88e6b2c4c7f29e5](https://github.com/ggerganov/llama.cpp/commit/3d35d87b4113648e224b837bb88e6b2c4c7f29e5)<br>2025-03-15 22:49:03<br>SYCL: Delete redundant plus sign and spa<br>ce<br>aubreyli  Log: [log](./log/3d35d87b4113648e224b837bb88e6b2c4c7f29e5)|100.0%<br>NA|3.95|tg=4.17<br>pp=77.33|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[b19bd064c09822cb81efe4a38abafab3e979c9ce](https://github.com/ggerganov/llama.cpp/commit/b19bd064c09822cb81efe4a38abafab3e979c9ce)<br>2025-03-15 15:19:30<br>SYCL : support non-contiguous tensors in<br> binary ops<br>fairydreaming  Log: [log](./log/b19bd064c09822cb81efe4a38abafab3e979c9ce)|100.0%<br>NA|3.96|tg=4.17<br>pp=77.58|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[363f8c5d67dcf80e00c39580dfa86dc2774d74c2](https://github.com/ggerganov/llama.cpp/commit/363f8c5d67dcf80e00c39580dfa86dc2774d74c2)<br>2025-03-12 09:57:32<br>sycl : variable sg_size support for mmvq<br> kernels<br>Alberto Cabrera Pérez  Log: [log](./log/363f8c5d67dcf80e00c39580dfa86dc2774d74c2)|100.0%<br>NA|3.96|tg=4.11<br>pp=76.64|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[5e43f104cca1a14874e980326a506b44fde022b8](https://github.com/ggerganov/llama.cpp/commit/5e43f104cca1a14874e980326a506b44fde022b8)<br>2025-03-05 21:28:23<br>SYCL: Disable f16 Unary OPs as not suppo<br>rted by the kernels<br>Akarshan Biswas  Log: [log](./log/5e43f104cca1a14874e980326a506b44fde022b8)|100.0%<br>NA|3.95|tg=4.11<br>pp=76.4|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[ece9745bb8079b9f4af45df29b67ad0c6e50584d](https://github.com/ggerganov/llama.cpp/commit/ece9745bb8079b9f4af45df29b67ad0c6e50584d)<br>2025-03-03 15:37:22<br>SYCL: Move CPY kernels to a separate fil<br>e and add few missing kernels<br>Akarshan Biswas  Log: [log](./log/ece9745bb8079b9f4af45df29b67ad0c6e50584d)|100.0%<br>NA|3.96|tg=4.12<br>pp=76.49|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[70680c48e5f77d2d3138712a6582bd8c1e548922](https://github.com/ggerganov/llama.cpp/commit/70680c48e5f77d2d3138712a6582bd8c1e548922)<br>2025-02-28 05:41:47<br>ggml : upgrade init_tensor API to return<br> a ggml_status<br>William Tambellini  Log: [log](./log/70680c48e5f77d2d3138712a6582bd8c1e548922)|100.0%<br>NA|3.95|tg=4.12<br>pp=76.72|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[08d5986290cc42d2c52739e046642b8252f97e4b](https://github.com/ggerganov/llama.cpp/commit/08d5986290cc42d2c52739e046642b8252f97e4b)<br>2025-02-24 22:33:23<br>[SYCL] Optimize mul_mat for Q4_0 on Inte<br>l GPU<br>Neo Zhang Jianyu  Log: [log](./log/08d5986290cc42d2c52739e046642b8252f97e4b)|100.0%<br>NA|3.95|tg=4.11<br>pp=76.61|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[8303e8b0fb2c1e26a8edd58071f9120a5bd6930a](https://github.com/ggerganov/llama.cpp/commit/8303e8b0fb2c1e26a8edd58071f9120a5bd6930a)<br>2025-02-24 15:48:25<br>SYCL: Fix GGML_SYCL_DEBUG macro<br>Akarshan Biswas  Log: [log](./log/8303e8b0fb2c1e26a8edd58071f9120a5bd6930a)|100.0%<br>NA|3.97|tg=4.13<br>pp=76.58|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[68ff663a04ed92044a9937bcae353e9d9733f9cd](https://github.com/ggerganov/llama.cpp/commit/68ff663a04ed92044a9937bcae353e9d9733f9cd)<br>2025-02-15 16:40:57<br>repo : update links to new url<br>Georgi Gerganov  Log: [log](./log/68ff663a04ed92044a9937bcae353e9d9733f9cd)|100.0%<br>NA|3.97|tg=4.12<br>pp=76.5|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[ec3bc8270bc67b58955748d40a3e558a05b2d8f2](https://github.com/ggerganov/llama.cpp/commit/ec3bc8270bc67b58955748d40a3e558a05b2d8f2)<br>2025-02-07 14:57:53<br>SYCL: remove XMX info from print devices<br><br>Akarshan Biswas  Log: [log](./log/ec3bc8270bc67b58955748d40a3e558a05b2d8f2)|100.0%<br>NA|3.98|tg=4.12<br>pp=76.72|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[194b2e69f8da3a22395c74fd9acd6d5835437b96](https://github.com/ggerganov/llama.cpp/commit/194b2e69f8da3a22395c74fd9acd6d5835437b96)<br>2025-02-06 17:12:35<br>SYCL: Adjust support condition for norm <br>operators<br>Akarshan Biswas  Log: [log](./log/194b2e69f8da3a22395c74fd9acd6d5835437b96)|100.0%<br>NA|3.97|tg=4.12<br>pp=76.59|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[6e84b0ab8e10b8f6f99a32855f976ebcd35b0353](https://github.com/ggerganov/llama.cpp/commit/6e84b0ab8e10b8f6f99a32855f976ebcd35b0353)<br>2025-01-28 15:26:58<br>SYCL : SOFTMAX F16 mask support and othe<br>r fixes<br>Akarshan Biswas  Log: [log](./log/6e84b0ab8e10b8f6f99a32855f976ebcd35b0353)|100.0%<br>NA|3.96|tg=4.12<br>pp=76.46|('ok', 'pass', 0)|0/0<br>2025.0.4|
|[a07c2c8a52464646ce13040e62c1ea04459f721e](https://github.com/ggerganov/llama.cpp/commit/a07c2c8a52464646ce13040e62c1ea04459f721e)<br>2025-01-24 13:30:13<br>docs : Update readme to build targets fo<br>r local docker build<br>Jafar Uruç  Log: [log](./log/a07c2c8a52464646ce13040e62c1ea04459f721e)|100.0%<br>NA|3.96|tg=4.13<br>pp=76.76|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[99487b57d47e14dc342b7b89d238ca11c0345241](https://github.com/ggerganov/llama.cpp/commit/99487b57d47e14dc342b7b89d238ca11c0345241)<br>2025-01-19 14:33:34<br>SYCL: Introducing memory host pool<br>Nicolò Scipione  Log: [log](./log/99487b57d47e14dc342b7b89d238ca11c0345241)|100.0%<br>NA|3.97|tg=4.12<br>pp=76.47|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[f446c2cf6a56a750b67c967505e717a996d2f2fd](https://github.com/ggerganov/llama.cpp/commit/f446c2cf6a56a750b67c967505e717a996d2f2fd)<br>2025-01-15 08:50:17<br>SYCL: Add gated linear attention kernel<br>Akarshan Biswas  Log: [log](./log/f446c2cf6a56a750b67c967505e717a996d2f2fd)|100.0%<br>NA|3.96|tg=4.11<br>pp=76.57|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[ee7136c6d1e0ba7633294dad137b1573048031ec](https://github.com/ggerganov/llama.cpp/commit/ee7136c6d1e0ba7633294dad137b1573048031ec)<br>2025-01-10 09:58:08<br>llama: add support for QRWKV6 model arch<br>itecture<br>Molly Sophia  Log: [log](./log/ee7136c6d1e0ba7633294dad137b1573048031ec)|100.0%<br>NA|3.96|tg=4.11<br>pp=76.48|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[c6860cc7346c90219475e4467bb8a288e0df975c](https://github.com/ggerganov/llama.cpp/commit/c6860cc7346c90219475e4467bb8a288e0df975c)<br>2025-01-10 05:43:03<br>SYCL: Refactor ggml_sycl_compute_forward<br><br>Akarshan Biswas  Log: [log](./log/c6860cc7346c90219475e4467bb8a288e0df975c)|100.0%<br>NA|3.96|tg=4.11<br>pp=76.86|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[c0d6f790d07aa78be15584ec394ac20739ade93b](https://github.com/ggerganov/llama.cpp/commit/c0d6f790d07aa78be15584ec394ac20739ade93b)<br>2025-01-07 11:56:07<br>SYCL: Use get_multi_ptr instead of depre<br>cated get_pointer in wkv6<br>Akarshan Biswas  Log: [log](./log/c0d6f790d07aa78be15584ec394ac20739ade93b)|100.0%<br>NA|3.97|tg=4.12<br>pp=76.45|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[86bf31cfe684849157f0875b4f0ebccac7034547](https://github.com/ggerganov/llama.cpp/commit/86bf31cfe684849157f0875b4f0ebccac7034547)<br>2024-12-23 10:39:30<br>rpc-server : add support for the SYCL ba<br>ckend<br>Radoslav Gerganov  Log: [log](./log/86bf31cfe684849157f0875b4f0ebccac7034547)|100.0%<br>NA|3.97|tg=4.13<br>pp=77.3|('ok', 'pass', 0)|4/0<br>2025.0.4|
|[eb5c3dc64bd967f2e23c87d9dec195f45468de60](https://github.com/ggerganov/llama.cpp/commit/eb5c3dc64bd967f2e23c87d9dec195f45468de60)<br>2024-12-20 21:01:28<br>SYCL: Migrate away from deprecated ggml_<br>tensor->backend<br>Akarshan Biswas  Log: [log](./log/eb5c3dc64bd967f2e23c87d9dec195f45468de60)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[ba1cb19cdd0d92e012e0f6e009e0620f854b6afd](https://github.com/ggerganov/llama.cpp/commit/ba1cb19cdd0d92e012e0f6e009e0620f854b6afd)<br>2024-12-14 20:43:46<br>llama : add Qwen2VL support + multimodal<br> RoPE<br>HimariO  Log: [log](./log/ba1cb19cdd0d92e012e0f6e009e0620f854b6afd)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[83ed24a97b500ccdb32b90b94e6f9621ad8db79e](https://github.com/ggerganov/llama.cpp/commit/83ed24a97b500ccdb32b90b94e6f9621ad8db79e)<br>2024-12-13 12:12:15<br>SYCL: Reduce most of the compiler warnin<br>gs<br>Akarshan Biswas  Log: [log](./log/83ed24a97b500ccdb32b90b94e6f9621ad8db79e)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[19d8762ab61df8286367588a80b9c7db4cb568db](https://github.com/ggerganov/llama.cpp/commit/19d8762ab61df8286367588a80b9c7db4cb568db)<br>2024-12-07 13:37:50<br>ggml : refactor online repacking<br>Djip007  Log: [log](./log/19d8762ab61df8286367588a80b9c7db4cb568db)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[01e6d9bb71eb71fe1f811f2fdef15753232cd0f2](https://github.com/ggerganov/llama.cpp/commit/01e6d9bb71eb71fe1f811f2fdef15753232cd0f2)<br>2024-12-04 08:26:37<br>clip : add sycl support<br>piDack  Log: [log](./log/01e6d9bb71eb71fe1f811f2fdef15753232cd0f2)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[40c6d79fb52f995f47507fedfeaae2ac05d9b35c](https://github.com/ggerganov/llama.cpp/commit/40c6d79fb52f995f47507fedfeaae2ac05d9b35c)<br>2024-12-04 02:29:20<br>SYCL : Move to compile time oneMKL inter<br>face backend selection for NVIDIA backen<br>d<br>Nicolò Scipione  Log: [log](./log/40c6d79fb52f995f47507fedfeaae2ac05d9b35c)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[991f8aabeec89d801300bb179e52013fb0eb0584](https://github.com/ggerganov/llama.cpp/commit/991f8aabeec89d801300bb179e52013fb0eb0584)<br>2024-12-02 12:34:11<br>SYCL: Fix and switch to GGML_LOG system <br>instead of fprintf<br>Akarshan Biswas  Log: [log](./log/991f8aabeec89d801300bb179e52013fb0eb0584)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[0f77aae5608f16780a49926b67be6d56ec4b09bd](https://github.com/ggerganov/llama.cpp/commit/0f77aae5608f16780a49926b67be6d56ec4b09bd)<br>2024-11-29 12:38:45<br>sycl : offload of get_rows set to 0<br>Alberto Cabrera Pérez  Log: [log](./log/0f77aae5608f16780a49926b67be6d56ec4b09bd)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[266b8519ee6d21e7ba2bf56f5629e20a181fee8b](https://github.com/ggerganov/llama.cpp/commit/266b8519ee6d21e7ba2bf56f5629e20a181fee8b)<br>2024-11-29 09:49:43<br>sycl : Reroute permuted mul_mats through<br> oneMKL<br>Alberto Cabrera Pérez  Log: [log](./log/266b8519ee6d21e7ba2bf56f5629e20a181fee8b)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[5a8987793f3e7c1fbfa6806bfcd17d578071b6c9](https://github.com/ggerganov/llama.cpp/commit/5a8987793f3e7c1fbfa6806bfcd17d578071b6c9)<br>2024-11-25 17:31:10<br>[SYCL] Fix building Win package for oneA<br>PI 2025.0 update<br>Neo Zhang Jianyu  Log: [log](./log/5a8987793f3e7c1fbfa6806bfcd17d578071b6c9)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[5931c1f233c616083d64e41a228249d58e039aa5](https://github.com/ggerganov/llama.cpp/commit/5931c1f233c616083d64e41a228249d58e039aa5)<br>2024-11-25 15:13:39<br>ggml : add support for dynamic loading o<br>f backends<br>Diego Devesa  Log: [log](./log/5931c1f233c616083d64e41a228249d58e039aa5)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[ad21c9e1f14d82b8c15ae369a8839019e3d498b4](https://github.com/ggerganov/llama.cpp/commit/ad21c9e1f14d82b8c15ae369a8839019e3d498b4)<br>2024-11-20 13:54:25<br>update rel to 4040<br>Neo Zhang Jianyu  Log: [log](./log/ad21c9e1f14d82b8c15ae369a8839019e3d498b4)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[2a1507c1629975d9d20a503d6a14f44eff292c25](https://github.com/ggerganov/llama.cpp/commit/2a1507c1629975d9d20a503d6a14f44eff292c25)<br>2024-11-19 09:02:23<br>sycl : Add option to set the SYCL archit<br>ecture for all targets<br>Romain Biessy  Log: [log](./log/2a1507c1629975d9d20a503d6a14f44eff292c25)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[557924f22237c76387a39c4db5abae154d57e754](https://github.com/ggerganov/llama.cpp/commit/557924f22237c76387a39c4db5abae154d57e754)<br>2024-11-19 00:50:04<br>sycl: Revert MUL_MAT_OP support changes<br>Alberto Cabrera Pérez  Log: [log](./log/557924f22237c76387a39c4db5abae154d57e754)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[57f8355b29a8c7dfcd1fb6094758ad85644f8535](https://github.com/ggerganov/llama.cpp/commit/57f8355b29a8c7dfcd1fb6094758ad85644f8535)<br>2024-11-15 12:10:45<br>sycl: Update Intel docker images to use <br>DPC++ 2025.0<br>Romain Biessy  Log: [log](./log/57f8355b29a8c7dfcd1fb6094758ad85644f8535)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[5a54af4d4f588f109f31e456483fdf77096399d9](https://github.com/ggerganov/llama.cpp/commit/5a54af4d4f588f109f31e456483fdf77096399d9)<br>2024-11-15 04:09:12<br>sycl: Use syclcompat::dp4a<br>Romain Biessy  Log: [log](./log/5a54af4d4f588f109f31e456483fdf77096399d9)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|NA|0/0<br>2024.1.0|
|[ae8de6d50a09d49545e0afab2e50cc4acfb280e2](https://github.com/ggerganov/llama.cpp/commit/ae8de6d50a09d49545e0afab2e50cc4acfb280e2)<br>2024-11-14 18:04:35<br>ggml : build backends as libraries<br>Diego Devesa  Log: [log](./log/ae8de6d50a09d49545e0afab2e50cc4acfb280e2)|100.0%<br>NA|4.3|tg=4.24<br>pp=45.83|('ok', 'pass', 0)|615/0<br>2024.1.0|
|[2e82ffa4af29f87e7d3d6dff8060a2a79613b72f](https://github.com/ggerganov/llama.cpp/commit/2e82ffa4af29f87e7d3d6dff8060a2a79613b72f)<br>2024-11-13 09:40:57<br>sycl : Fixes to broken builds and test-b<br>ackend-ops<br>Alberto Cabrera Pérez  Log: [log](./log/2e82ffa4af29f87e7d3d6dff8060a2a79613b72f)|100.0%<br>NA|4.3|tg=4.23<br>pp=45.71|('ok', 'pass', 0)|609/0<br>2024.1.0|
|[3bcd40b3c593d14261fb2abfabad3c0fb5b9e318](https://github.com/ggerganov/llama.cpp/commit/3bcd40b3c593d14261fb2abfabad3c0fb5b9e318)<br>2024-11-07 18:19:10<br>Optimize RWKV6 Operator Naming and Imple<br>ment Multi-core CPU/ SYCL Acceleration<br>Zhiyuan Li  Log: [log](./log/3bcd40b3c593d14261fb2abfabad3c0fb5b9e318)|96.0%<br>NA|4.88|tg=4.97<br>pp=49.95|('ok', 'pass', 0)|606/0<br>2024.1.0|
|[c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc](https://github.com/ggerganov/llama.cpp/commit/c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc)<br>2024-10-30 02:01:23<br>llama : refactor model loader with backe<br>nd registry<br>Diego Devesa  Log: [log](./log/c5b0f4b5d90297f3e729fca7f78ddb25fcab5ddc)|96.0%<br>NA|4.89|tg=4.97<br>pp=50.75|('ok', 'pass', 0)|520/0<br>2024.1.0|
|[40f2555797f97314de749873cdc29dc102be66e2](https://github.com/ggerganov/llama.cpp/commit/40f2555797f97314de749873cdc29dc102be66e2)<br>2024-10-24 21:23:33<br>ci : fix cmake flags for SYCL<br>Georgi Gerganov  Log: [log](./log/40f2555797f97314de749873cdc29dc102be66e2)|96.0%<br>NA|4.96|tg=5.12<br>pp=51.02|('ok', 'pass', 0)|497/0<br>2024.1.0|
|[1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31](https://github.com/ggerganov/llama.cpp/commit/1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31)<br>2024-10-21 14:26:09<br>fix mul_mat_vec_q and *_vec_q error<br>Neo Zhang Jianyu  Log: [log](./log/1db8c84fc62857e1e45c1c7ea93bcd5344cb3d31)|100.0%<br>NA|4.96|tg=5.12<br>pp=51.09|('ok', 'pass', 0)|526/0<br>2024.1.0|
|[87421a23e8c60e00a7b227d501e8aab2a1aff7ce](https://github.com/ggerganov/llama.cpp/commit/87421a23e8c60e00a7b227d501e8aab2a1aff7ce)<br>2024-10-18 06:46:16<br>[SYCL] Add SYCL Backend registry, device<br> and Event Interfaces<br>Ouadie EL FAROUKI  Log: [log](./log/87421a23e8c60e00a7b227d501e8aab2a1aff7ce)|100.0%<br>NA|4.95|tg=5.12<br>pp=50.92|('ok', 'pass', 0)|526/0<br>2024.1.0|
|[5639971466ed74386a1811938022f0c333007b55](https://github.com/ggerganov/llama.cpp/commit/5639971466ed74386a1811938022f0c333007b55)<br>2024-10-03 07:50:44<br>Fixed dequant precision issues in Q4_1 a<br>nd Q5_1<br>Ouadie EL FAROUKI  Log: [log](./log/5639971466ed74386a1811938022f0c333007b55)|100.0%<br>NA|4.96|tg=5.12<br>pp=51.79|('ok', 'pass', 0)|514/0<br>2024.1.0|
|[c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6](https://github.com/ggerganov/llama.cpp/commit/c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6)<br>2024-10-03 01:49:47<br>ggml-backend : add device and backend re<br>g interfaces<br>Diego Devesa  Log: [log](./log/c83ad6d01e7b89ec71080d97c7e5db7ac1f4fda6)|100.0%<br>NA|4.95|tg=5.11<br>pp=50.96|('ok', 'pass', 0)|501/0<br>2024.1.0|
|[f536f4c4391bec74c432a924625c04e8c484d3ee](https://github.com/ggerganov/llama.cpp/commit/f536f4c4391bec74c432a924625c04e8c484d3ee)<br>2024-10-02 13:57:18<br>[SYCL] Initial cmake support of SYCL for<br> AMD GPUs<br>Alberto Cabrera Pérez  Log: [log](./log/f536f4c4391bec74c432a924625c04e8c484d3ee)|100.0%<br>NA|4.96|tg=5.12<br>pp=50.76|('ok', 'pass', 0)|522/0<br>2024.1.0|
|[95bc82fbc0df6d48cf66c857a4dda3d044f45ca2](https://github.com/ggerganov/llama.cpp/commit/95bc82fbc0df6d48cf66c857a4dda3d044f45ca2)<br>2024-09-26 17:38:31<br>[SYCL] add missed dll file in package<br>Neo Zhang Jianyu  Log: [log](./log/95bc82fbc0df6d48cf66c857a4dda3d044f45ca2)|100.0%<br>NA|4.95|tg=5.11<br>pp=56.1|('ok', 'pass', 0)|522/0<br>2024.1.0|
|[e62e9789cda3bf5573a747e55ec2a7ee32908f56](https://github.com/ggerganov/llama.cpp/commit/e62e9789cda3bf5573a747e55ec2a7ee32908f56)<br>2024-09-23 08:58:06<br>Revert "[SYCL] fallback mmvq<br>Akarshan Biswas  Log: [log](./log/e62e9789cda3bf5573a747e55ec2a7ee32908f56)|100.0%<br>NA|4.96|tg=5.12<br>pp=53.89|('ok', 'pass', 0)|522/0<br>2024.1.0|
|[d13edb17ed1ce3b961016cbdb616b1c8d161c026](https://github.com/ggerganov/llama.cpp/commit/d13edb17ed1ce3b961016cbdb616b1c8d161c026)<br>2024-09-20 20:12:52<br>ggml : fix builds<br>Georgi Gerganov  Log: [log](./log/d13edb17ed1ce3b961016cbdb616b1c8d161c026)|100.0%<br>NA|4.95|tg=5.12<br>pp=51.04|('ok', 'pass', 0)|515/0<br>2024.1.0|
|[424c5d00a9b97dd5559635872db9b57f87c23b02](https://github.com/ggerganov/llama.cpp/commit/424c5d00a9b97dd5559635872db9b57f87c23b02)<br>2024-09-20 19:04:44<br>ggml/examples: add backend support for n<br>umerical optimization<br>Johannes Gäßler  Log: [log](./log/424c5d00a9b97dd5559635872db9b57f87c23b02)|Build Err<br>NA|NA|tg=NA<br>pp=NA|NA|77/3<br>2024.1.0|
|[faf67b3de4688f47c3b1019c89df255df2fd59b4](https://github.com/ggerganov/llama.cpp/commit/faf67b3de4688f47c3b1019c89df255df2fd59b4)<br>2024-09-18 08:30:31<br>[SYCL]set context default value to avoid<br> memory issue, update guide<br>Neo Zhang Jianyu  Log: [log](./log/faf67b3de4688f47c3b1019c89df255df2fd59b4)|100.0%<br>NA|4.95|tg=5.12<br>pp=51.01|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: 467408 2006-11-08 - 467408', 0)|522/0<br>2024.1.0|
|[6988da94a261444859f78595899212eeedc5ff9d](https://github.com/ggerganov/llama.cpp/commit/6988da94a261444859f78595899212eeedc5ff9d)<br>2024-09-15 18:55:52<br>cmake : correct order of sycl flags<br>Michael Podvitskiy  Log: [log](./log/6988da94a261444859f78595899212eeedc5ff9d)|100.0%<br>NA|4.94|tg=5.12<br>pp=50.84|('ok', 'pass', 0)|511/0<br>2024.1.0|
|[7596487bebd58eade3cd0133d42a9008aaaf9d09](https://github.com/ggerganov/llama.cpp/commit/7596487bebd58eade3cd0133d42a9008aaaf9d09)<br>2024-09-15 09:06:38<br>cmake : try to fix sycl+intel build<br>Michael Podvitskiy  Log: [log](./log/7596487bebd58eade3cd0133d42a9008aaaf9d09)|100.0%<br>NA|4.95|tg=5.07<br>pp=50.87|('ok', 'pass', 0)|511/0<br>2024.1.0|
|[c9c8575a1a8a170329afca4c4df4c005806efb1d](https://github.com/ggerganov/llama.cpp/commit/c9c8575a1a8a170329afca4c4df4c005806efb1d)<br>2024-09-12 17:44:17<br>enhance run script to be easy to change <br>the parameters<br>Neo Zhang Jianyu  Log: [log](./log/c9c8575a1a8a170329afca4c4df4c005806efb1d)|100.0%<br>NA|4.95|tg=5.12<br>pp=53.53|('ok', 'pass', 0)|506/0<br>2024.1.0|
|[d6a04f872dea8ade92527bb1488d4b0b90cc49f0](https://github.com/ggerganov/llama.cpp/commit/d6a04f872dea8ade92527bb1488d4b0b90cc49f0)<br>2024-09-12 14:23:49<br>ggml : hide ggml_object, ggml_cgraph, gg<br>ml_hash_set<br>Georgi Gerganov  Log: [log](./log/d6a04f872dea8ade92527bb1488d4b0b90cc49f0)|100.0%<br>NA|4.95|tg=5.12<br>pp=59.38|('ok', 'pass', 0)|506/0<br>2024.1.0|
|[51b603863627c4074e77b7e556e18ece86bdf9a3](https://github.com/ggerganov/llama.cpp/commit/51b603863627c4074e77b7e556e18ece86bdf9a3)<br>2024-09-11 01:53:42<br>sycl : update support conditions<br>Alberto Cabrera Pérez  Log: [log](./log/51b603863627c4074e77b7e556e18ece86bdf9a3)|100.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|522/0<br>2024.1.0|
|[2a358fb0c4b6e917ac852aa17444cc94dd28a2a6](https://github.com/ggerganov/llama.cpp/commit/2a358fb0c4b6e917ac852aa17444cc94dd28a2a6)<br>2024-09-08 19:05:29<br>[SYCL] add check malloc result on device<br><br>Neo Zhang Jianyu  Log: [log](./log/2a358fb0c4b6e917ac852aa17444cc94dd28a2a6)|96.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|469/0<br>2024.1.0|
|[5910ea942772ab6cbc21d0ad2d1208750ba39e1d](https://github.com/ggerganov/llama.cpp/commit/5910ea942772ab6cbc21d0ad2d1208750ba39e1d)<br>2024-09-04 16:26:33<br>[SYCL] Fix DMMV dequantization<br>Ouadie EL FAROUKI  Log: [log](./log/5910ea942772ab6cbc21d0ad2d1208750ba39e1d)|100.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|505/0<br>2024.1.0|
|[cddae4884c853b1a7ab420458236d666e2e34423](https://github.com/ggerganov/llama.cpp/commit/cddae4884c853b1a7ab420458236d666e2e34423)<br>2024-08-30 20:10:01<br>Correct typo run_llama2.sh > run-llama2.<br>sh<br>蕭澧邦  Log: [log](./log/cddae4884c853b1a7ab420458236d666e2e34423)|96.0%<br>1417/1421|4.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|523/0<br>2024.1.0|
|[11b84eb4578864827afcf956db5b571003f18180](https://github.com/ggerganov/llama.cpp/commit/11b84eb4578864827afcf956db5b571003f18180)<br>2024-08-22 19:39:47<br>[SYCL] Add a space to supress a cmake wa<br>rning<br>Akarshan Biswas  Log: [log](./log/11b84eb4578864827afcf956db5b571003f18180)|96.0%<br>1338/1342|4.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|513/0<br>2024.1.0|
|[1731d4238f9e4f925a750810e7f5480827c66dcf](https://github.com/ggerganov/llama.cpp/commit/1731d4238f9e4f925a750810e7f5480827c66dcf)<br>2024-08-22 12:50:10<br>[SYCL] Add oneDNN primitive support<br>luoyu-intel  Log: [log](./log/1731d4238f9e4f925a750810e7f5480827c66dcf)|96.0%<br>1338/1342|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|523/0<br>2024.1.0|
|[50addec9a532a6518146ab837a85504850627316](https://github.com/ggerganov/llama.cpp/commit/50addec9a532a6518146ab837a85504850627316)<br>2024-08-20 23:50:17<br>[SYCL] fallback mmvq<br>Meng, Hengyu  Log: [log](./log/50addec9a532a6518146ab837a85504850627316)|96.0%<br>1338/1342|4.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|490/0<br>2024.1.0|
|[4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b](https://github.com/ggerganov/llama.cpp/commit/4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b)<br>2024-08-20 23:06:51<br>[SYCL] Fix SYCL `im2col` and `convert` O<br>verflow with Large Dims<br>zhentaoyu  Log: [log](./log/4f8d19ff17faa601f456ee1db7d8b8a15fa3f90b)|96.0%<br>1338/1342|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|505/0<br>2024.1.0|
|[06943a69f678fb32829ff06d9c18367b17d4b361](https://github.com/ggerganov/llama.cpp/commit/06943a69f678fb32829ff06d9c18367b17d4b361)<br>2024-08-13 21:13:15<br>ggml : move rope type enum to ggml.h<br>Daniel Bevenius  Log: [log](./log/06943a69f678fb32829ff06d9c18367b17d4b361)|96.0%<br>1338/1342|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|491/0<br>2024.1.0|
|[a21c6fd45032a20180e026773582d21294c85619](https://github.com/ggerganov/llama.cpp/commit/a21c6fd45032a20180e026773582d21294c85619)<br>2024-08-11 16:37:43<br>update guide<br>Neo Zhang  Log: [log](./log/a21c6fd45032a20180e026773582d21294c85619)|96.0%<br>1338/1342|4.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|484/0<br>2024.1.0|
|[0478174d5959b66096ae6609fcb0df14cab66b51](https://github.com/ggerganov/llama.cpp/commit/0478174d5959b66096ae6609fcb0df14cab66b51)<br>2024-08-07 11:25:36<br>[SYCL] Updated SYCL device filtering<br>Ouadie EL FAROUKI  Log: [log](./log/0478174d5959b66096ae6609fcb0df14cab66b51)|96.0%<br>1338/1342|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|483/0<br>2024.1.0|
|[2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf](https://github.com/ggerganov/llama.cpp/commit/2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf)<br>2024-08-06 15:26:46<br>ggml : add epsilon as a parameter for gr<br>oup_norm<br>Molly Sophia  Log: [log](./log/2d5dd7bb3fa382806cd3e0bfc7a1d92349bc0ccf)|96.0%<br>1338/1342|4.97|tg=NA<br>pp=NA|('ok', 'pass', 0)|462/0<br>2024.1.0|
|[d4ff847153e9cf7220d1b39aa21172069e6e8cea](https://github.com/ggerganov/llama.cpp/commit/d4ff847153e9cf7220d1b39aa21172069e6e8cea)<br>2024-08-06 09:09:12<br>[SYCL] correct cmd name<br>Neo Zhang  Log: [log](./log/d4ff847153e9cf7220d1b39aa21172069e6e8cea)|96.0%<br>1338/1342|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|491/0<br>2024.1.0|
|[0fbbd884589d585c3b43cae8c16938ffffb863b9](https://github.com/ggerganov/llama.cpp/commit/0fbbd884589d585c3b43cae8c16938ffffb863b9)<br>2024-08-02 01:55:17<br>[SYCL] Fixing wrong VDR iq4nl value<br>Ouadie EL FAROUKI  Log: [log](./log/0fbbd884589d585c3b43cae8c16938ffffb863b9)|96.0%<br>1347/1351|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|491/0<br>2024.1.0|
|[c887d8b01726b11ea03dbcaa9d44fa74422d0076](https://github.com/ggerganov/llama.cpp/commit/c887d8b01726b11ea03dbcaa9d44fa74422d0076)<br>2024-07-30 14:56:51<br>[SYCL] Add `TIMESTEP_EMBEDDING` OP<br>zhentaoyu  Log: [log](./log/c887d8b01726b11ea03dbcaa9d44fa74422d0076)|96.0%<br>1332/1334|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|491/0<br>2024.1.0|
|[0832de723695ab400316a6c49b9f712380e3a731](https://github.com/ggerganov/llama.cpp/commit/0832de723695ab400316a6c49b9f712380e3a731)<br>2024-07-29 10:50:27<br>[SYCL] add conv support<br>Meng, Hengyu  Log: [log](./log/0832de723695ab400316a6c49b9f712380e3a731)|96.0%<br>1332/1334|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|475/0<br>2024.1.0|
|[2b1f616b208a4a21c4ee7a7eb85d822ff1d787af](https://github.com/ggerganov/llama.cpp/commit/2b1f616b208a4a21c4ee7a7eb85d822ff1d787af)<br>2024-07-27 04:41:55<br>ggml : reduce hash table reset cost<br>slaren  Log: [log](./log/2b1f616b208a4a21c4ee7a7eb85d822ff1d787af)|96.0%<br>1332/1334|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|461/0<br>2024.1.0|
|[ed67bcb24f2d6ac0072cae72620b2bd971741b98](https://github.com/ggerganov/llama.cpp/commit/ed67bcb24f2d6ac0072cae72620b2bd971741b98)<br>2024-07-25 11:45:18<br>[SYCL] fix multi-gpu issue on sycl<br>Chen Xi  Log: [log](./log/ed67bcb24f2d6ac0072cae72620b2bd971741b98)|96.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|465/0<br>2024.1.0|
|[f19bf99c015d3d745143e8bb4f056e0ea015ad40](https://github.com/ggerganov/llama.cpp/commit/f19bf99c015d3d745143e8bb4f056e0ea015ad40)<br>2024-07-24 14:36:00<br>Build Llama SYCL Intel with static libs<br>Joe Todd  Log: [log](./log/f19bf99c015d3d745143e8bb4f056e0ea015ad40)|96.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|485/0<br>2024.1.0|
|[79167d9e49aef9caa98e13ee7ca067ec9f88b4b5](https://github.com/ggerganov/llama.cpp/commit/79167d9e49aef9caa98e13ee7ca067ec9f88b4b5)<br>2024-07-24 11:55:26<br>Re-add erroneously removed -fsycl from G<br>GML_EXTRA_LIBS<br>Joe Todd  Log: [log](./log/79167d9e49aef9caa98e13ee7ca067ec9f88b4b5)|96.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|483/0<br>2024.1.0|
|[64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e](https://github.com/ggerganov/llama.cpp/commit/64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e)<br>2024-07-23 14:58:37<br>sycl : Add support for non-release DPC++<br> & oneMKL<br>Joe Todd  Log: [log](./log/64cf50a0ed62d41e4f6c13e08a9b6b0816f46c6e)|96.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|483/0<br>2024.1.0|
|[063d99ad11f1295046610ce5b97e105849a4b573](https://github.com/ggerganov/llama.cpp/commit/063d99ad11f1295046610ce5b97e105849a4b573)<br>2024-07-23 07:43:28<br>[SYCL] fix scratch size of softmax<br>luoyu-intel  Log: [log](./log/063d99ad11f1295046610ce5b97e105849a4b573)|96.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|487/0<br>2024.1.0|
|[16bdfa42acb09175e88cf97e9d9e4e48f616d120](https://github.com/ggerganov/llama.cpp/commit/16bdfa42acb09175e88cf97e9d9e4e48f616d120)<br>2024-07-15 19:32:15<br>[SYCL] add concat through dim 1/2<br>Meng, Hengyu  Log: [log](./log/16bdfa42acb09175e88cf97e9d9e4e48f616d120)|95.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|487/0<br>2024.1.0|
|[b549a1bbefb2f1fbb8b558bac1f2ae7967e60964](https://github.com/ggerganov/llama.cpp/commit/b549a1bbefb2f1fbb8b558bac1f2ae7967e60964)<br>2024-07-12 00:52:04<br>[SYCL] fix the mul_mat_id ut issues<br>Chen Xi  Log: [log](./log/b549a1bbefb2f1fbb8b558bac1f2ae7967e60964)|95.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>main: error: unable to load model', 0)|475/0<br>2024.1.0|
|[f4444d992c16b6b9442f4770c7c3a10b19a08343](https://github.com/ggerganov/llama.cpp/commit/f4444d992c16b6b9442f4770c7c3a10b19a08343)<br>2024-07-10 16:10:49<br>[SYCL] Use multi_ptr to clean up depreca<br>ted warnings<br>AidanBeltonS  Log: [log](./log/f4444d992c16b6b9442f4770c7c3a10b19a08343)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|487/0<br>2024.1.0|
|[5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b](https://github.com/ggerganov/llama.cpp/commit/5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b)<br>2024-07-09 15:03:15<br>sycl : Reenabled mmvq path for the SYCL <br>Nvidia Backend<br>Alberto Cabrera Pérez  Log: [log](./log/5b0b8d8cfb5ddf2118f686ba6c30fab3f71b384b)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|705/0<br>2024.1.0|
|[a130eccef42b75a84da270411cefeed45c153e30](https://github.com/ggerganov/llama.cpp/commit/a130eccef42b75a84da270411cefeed45c153e30)<br>2024-07-08 21:35:17<br>labeler : updated sycl to match docs and<br> code refactor<br>Alberto Cabrera Pérez  Log: [log](./log/a130eccef42b75a84da270411cefeed45c153e30)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|705/0<br>2024.1.0|
|[2ec846d558f6385ea647f7b8e665eb249c1ebce7](https://github.com/ggerganov/llama.cpp/commit/2ec846d558f6385ea647f7b8e665eb249c1ebce7)<br>2024-07-08 14:22:41<br>sycl : fix powf call in device code<br>Alberto Cabrera Pérez  Log: [log](./log/2ec846d558f6385ea647f7b8e665eb249c1ebce7)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|705/0<br>2024.1.0|
|[3f2d538b817112ad8429341c7e8657dcd660f4d3](https://github.com/ggerganov/llama.cpp/commit/3f2d538b817112ad8429341c7e8657dcd660f4d3)<br>2024-07-08 13:51:31<br>scripts : fix sync for sycl<br>Georgi Gerganov  Log: [log](./log/3f2d538b817112ad8429341c7e8657dcd660f4d3)|95.0%<br>NA|4.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|705/0<br>2024.1.0|
|[be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d](https://github.com/ggerganov/llama.cpp/commit/be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d)<br>2024-07-05 18:08:32<br>Reorganize documentation pages<br>Xuan Son Nguyen  Log: [log](./log/be20e7f49d9e5c6d9e8d9b4871eeba3df7a1639d)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|705/0<br>2024.1.0|
|[1f3e1b66e21310ed78b964f72f19766549633f0e](https://github.com/ggerganov/llama.cpp/commit/1f3e1b66e21310ed78b964f72f19766549633f0e)<br>2024-07-05 13:23:25<br>Enabled more data types for oneMKL gemm_<br>batch<br>Ouadie EL FAROUKI  Log: [log](./log/1f3e1b66e21310ed78b964f72f19766549633f0e)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|705/0<br>2024.1.0|
|[f09b7cb609d80b8031803f89255991dc8b35db69](https://github.com/ggerganov/llama.cpp/commit/f09b7cb609d80b8031803f89255991dc8b35db69)<br>2024-07-05 10:32:29<br>rm get_work_group_size<br>Neo Zhang Jianyu  Log: [log](./log/f09b7cb609d80b8031803f89255991dc8b35db69)|95.0%<br>NA|5.33|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|561/0<br>2024.1.0|
|[a9554e20b66546b0549aebe2e1034bc8afe9d809](https://github.com/ggerganov/llama.cpp/commit/a9554e20b66546b0549aebe2e1034bc8afe9d809)<br>2024-07-05 05:06:13<br>[SYCL] Fix WARP_SIZE=16 bug of Intel GPU<br><br>luoyu-intel  Log: [log](./log/a9554e20b66546b0549aebe2e1034bc8afe9d809)|95.0%<br>NA|4.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|703/0<br>2024.1.0|
|[f619024764e72261f14d7c31d892b8fb976603b4](https://github.com/ggerganov/llama.cpp/commit/f619024764e72261f14d7c31d892b8fb976603b4)<br>2024-07-04 02:07:19<br>[SYCL] Remove unneeded semicolons<br>AidanBeltonS  Log: [log](./log/f619024764e72261f14d7c31d892b8fb976603b4)|95.0%<br>NA|5.33|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|569/0<br>2024.1.0|
|[fadde6713506d9e6c124f5680ab8c7abebe31837](https://github.com/ggerganov/llama.cpp/commit/fadde6713506d9e6c124f5680ab8c7abebe31837)<br>2024-07-03 02:55:34<br>Dequant improvements rebase<br>AidanBeltonS  Log: [log](./log/fadde6713506d9e6c124f5680ab8c7abebe31837)|95.0%<br>NA|5.32|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|569/0<br>2024.1.0|
|[07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81](https://github.com/ggerganov/llama.cpp/commit/07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81)<br>2024-07-02 12:18:10<br>Removes multiple newlines at the end of <br>files that is breaking the editorconfig <br>step of CI.<br>Clint Herron  Log: [log](./log/07a3fc0608a68c0c93a5fbfa9c58f4c9ec64cb81)|95.0%<br>NA|5.32|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|563/0<br>2024.1.0|
|[a9f3b102157ba992cfe058909b7f6e1906d2d647](https://github.com/ggerganov/llama.cpp/commit/a9f3b102157ba992cfe058909b7f6e1906d2d647)<br>2024-07-02 04:50:07<br>[SYCL] Fix win build conflict of math li<br>brary<br>luoyu-intel  Log: [log](./log/a9f3b102157ba992cfe058909b7f6e1906d2d647)|95.0%<br>NA|5.3|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|563/0<br>2024.1.0|
|[d08c20eddedb24515a3212e2de66bdff41a26b8c](https://github.com/ggerganov/llama.cpp/commit/d08c20eddedb24515a3212e2de66bdff41a26b8c)<br>2024-07-02 02:16:00<br>[SYCL] Fix the sub group size of Intel<br>luoyu-intel  Log: [log](./log/d08c20eddedb24515a3212e2de66bdff41a26b8c)|95.0%<br>NA|5.01|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: The original copy text needed sh<br>ould describe the products/ services.', <br>0)|599/0<br>2024.1.0|
|[cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846](https://github.com/ggerganov/llama.cpp/commit/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846)<br>2024-07-01 20:39:06<br>CUDA: refactor and optimize IQ MMVQ<br>Johannes Gäßler  Log: [log](./log/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846)|95.0%<br>NA|5.23|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Customize your site', 6)|543/0<br>2024.1.0|
|[197fe6c1d7bec6718ce901f0141b2725240f298c](https://github.com/ggerganov/llama.cpp/commit/197fe6c1d7bec6718ce901f0141b2725240f298c)<br>2024-07-01 19:39:06<br>[SYCL] Update SYCL-Rope op and Refactor<br>zhentaoyu  Log: [log](./log/197fe6c1d7bec6718ce901f0141b2725240f298c)|95.0%<br>NA|5.23|tg=NA<br>pp=NA|('ok', 'pass', 0)|543/0<br>2024.1.0|
|[f3f65429c44bb195a9195bfdc19a30a79709db7b](https://github.com/ggerganov/llama.cpp/commit/f3f65429c44bb195a9195bfdc19a30a79709db7b)<br>2024-06-26 18:33:02<br>llama : reorganize source code + improve<br> CMake<br>Georgi Gerganov  Log: [log](./log/f3f65429c44bb195a9195bfdc19a30a79709db7b)|100.0%<br>NA|5.23|tg=NA<br>pp=NA|('ok', 'pass', 0)|533/0<br>2024.1.0|
|[083bacce14c1aaf9976aa40e8266cdc25ac749d3](https://github.com/ggerganov/llama.cpp/commit/083bacce14c1aaf9976aa40e8266cdc25ac749d3)<br>2024-06-25 10:19:20<br>[SYCL] Re-enabled mul_mat_batched_sycl<br>Meng, Hengyu  Log: [log](./log/083bacce14c1aaf9976aa40e8266cdc25ac749d3)|95.0%<br>NA|5.21|tg=NA<br>pp=NA|('ok', 'pass', 0)|554/0<br>2024.1.0|
|[de391e4c803383bbea054b6edd016e78c024a74d](https://github.com/ggerganov/llama.cpp/commit/de391e4c803383bbea054b6edd016e78c024a74d)<br>2024-06-20 13:19:05<br>[SYCL] Fix windows build and inference<br>luoyu-intel  Log: [log](./log/de391e4c803383bbea054b6edd016e78c024a74d)|95.0%<br>NA|5.29|tg=NA<br>pp=NA|('ok', 'pass', 0)|554/0<br>2024.1.0|
|[623494a478134432fd2d7ee40135770a3340674f](https://github.com/ggerganov/llama.cpp/commit/623494a478134432fd2d7ee40135770a3340674f)<br>2024-06-19 09:11:51<br>[SYCL] refactor<br>Meng, Hengyu  Log: [log](./log/623494a478134432fd2d7ee40135770a3340674f)|95.0%<br>NA|5.28|tg=NA<br>pp=NA|('ok', 'pass', 0)|542/0<br>2024.1.0|
|[df68d4fa5dc929217d3e64d673e099d7a417b206](https://github.com/ggerganov/llama.cpp/commit/df68d4fa5dc929217d3e64d673e099d7a417b206)<br>2024-06-17 11:17:07<br>[SYCL] Update README-sycl.md for Chapter<br> "Recommended release" and "News"<br>Neo Zhang  Log: [log](./log/df68d4fa5dc929217d3e64d673e099d7a417b206)|95.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>The number of work-items in each dimensi<br>on of a work-group cannot exceed {512, 5<br>', 0)|480/0<br>2024.1.0|
|[7b2f4a7d193ef2475259bbe7656fcccfab4b1217](https://github.com/ggerganov/llama.cpp/commit/7b2f4a7d193ef2475259bbe7656fcccfab4b1217)<br>2024-06-15 14:05:10<br>[SYCL] remove global variables<br>Meng, Hengyu  Log: [log](./log/7b2f4a7d193ef2475259bbe7656fcccfab4b1217)|95.0%<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>The number of work-items in each dimensi<br>on of a work-group cannot exceed {512, 5<br>', 0)|480/0<br>2024.1.0|
|[f578b86b2123d0f92afbaa98a031df4d4464e582](https://github.com/ggerganov/llama.cpp/commit/f578b86b2123d0f92afbaa98a031df4d4464e582)<br>2024-06-13 03:11:35<br>move BLAS to a separate backend<br>slaren  Log: [log](./log/f578b86b2123d0f92afbaa98a031df4d4464e582)|95.0%<br>NA|5.25|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’4Cin2? TheCre or 2-over - components<br>', 6)|493/0<br>2024.1.0|
|[1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7](https://github.com/ggerganov/llama.cpp/commit/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7)<br>2024-06-13 00:41:52<br>`build`: rename main → llama-cli, server<br> → llama-server, llava-cli → llama-llava<br>-cli, etc...<br>Olivier Chafik  Log: [log](./log/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7)|95.0%<br>NA|5.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Custom LeDo’A—s have.-5- for the<br> classicCo:F/8 (3.archivioni andmulticol<br>', 6)|493/0<br>2024.1.0|
|[a9cae48003dfc4fe95b8f5c81682fc6e63425235](https://github.com/ggerganov/llama.cpp/commit/a9cae48003dfc4fe95b8f5c81682fc6e63425235)<br>2024-06-12 16:00:22<br>tests : add non-cont unary tests<br>Georgi Gerganov  Log: [log](./log/a9cae48003dfc4fe95b8f5c81682fc6e63425235)|95.0%<br>NA|5.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’4Cin2? TheCre or 2-over - components<br>', 6)|493/0<br>2024.1.0|
|[af4ae502ddaeb03cd5861273ca2e9a5ae4551db7](https://github.com/ggerganov/llama.cpp/commit/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7)<br>2024-06-10 02:21:31<br>use the correct SYCL context for host US<br>M allocations<br>Ben Ashbaugh  Log: [log](./log/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7)|95.0%<br>NA|5.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’4Cin2? TheCre or 2-over - components<br>', 6)|491/0<br>2024.1.0|
|[fe1e3917cfa0f9397a765cfd0aef880674d938d5](https://github.com/ggerganov/llama.cpp/commit/fe1e3917cfa0f9397a765cfd0aef880674d938d5)<br>2024-06-09 01:43:39<br>Revert "[SYCL] Update rpc-server.cpp to <br>include SYCL backend<br>slaren  Log: [log](./log/fe1e3917cfa0f9397a765cfd0aef880674d938d5)|95.0%<br>NA|5.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|493/0<br>2024.1.0|
|[d5c938cd7716b9a2ace49a43a469dfbffcff4d28](https://github.com/ggerganov/llama.cpp/commit/d5c938cd7716b9a2ace49a43a469dfbffcff4d28)<br>2024-06-07 14:28:26<br>[SYCL] fix softmax r2r result wrong issu<br>e<br>pengxin99  Log: [log](./log/d5c938cd7716b9a2ace49a43a469dfbffcff4d28)|95.0%<br>NA|5.26|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|493/0<br>2024.1.0|
|[2b3389677a833cee0880226533a1768b1a9508d2](https://github.com/ggerganov/llama.cpp/commit/2b3389677a833cee0880226533a1768b1a9508d2)<br>2024-06-05 11:29:20<br>ggml : refactor rope norm/neox<br>Georgi Gerganov  Log: [log](./log/2b3389677a833cee0880226533a1768b1a9508d2)|95.0%<br>NA|5.27|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in. on your un(, with a<br>', 6)|493/0<br>2024.1.0|
|[554c247caffed64465f372661f2826640cb10430](https://github.com/ggerganov/llama.cpp/commit/554c247caffed64465f372661f2826640cb10430)<br>2024-06-04 21:23:20<br>ggml : remove OpenCL<br>Georgi Gerganov  Log: [log](./log/554c247caffed64465f372661f2826640cb10430)|95.0%<br>NA|5.28|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make report (v has have has got <br>(pay( Big and (c gu in to The(Col U2k 2 <br>', 6)|487/0<br>2024.1.0|
