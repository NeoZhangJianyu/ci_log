# [arthw/llama.cpp](https://github.com/arthw/llama.cpp/tree/master) CI for arc770 by SYCL Backend

## Summary

Figure

![Performance](./perf.png)
## Detail

**GGUF res** is verified by script ./example/sycl/run.sh with llama2-7b-Q4 for correction

**GGUF Perf** is the performance data by script ./example/sycl/run.sh with llama2-7b-Q4

**Bench Perf** is the performance data by llama-bench with llama2-7b-Q4

|Commit Info|UT PassRate<br>Detail|GGUF Perf<br>(token/s)|Bench Perf<br>(token/s)|<div style="width:100px">GGUF res</div>|Warn/Err<br>oneAPI|
|-|-|-|-|-|-|
|[e37b33d4a4de44fb02406ea198345a9e85885dba](https://github.com/arthw/llama.cpp/commit/e37b33d4a4de44fb02406ea198345a9e85885dba)<br>2025-07-21 17:51:23<br>update for local api<br>arthw  Log: [log](./log/e37b33d4a4de44fb02406ea198345a9e85885dba)|97.0%<br>NA|29.41|tg=29.16<br>pp=523.03|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[99b36ec76585d090759839aeb9b132c64ae504f4](https://github.com/arthw/llama.cpp/commit/99b36ec76585d090759839aeb9b132c64ae504f4)<br>2025-07-18 10:23:14<br>use max work group size for device to re<br>place the magic number<br>Neo Zhang Jianyu  Log: [log](./log/99b36ec76585d090759839aeb9b132c64ae504f4)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|24/0<br>2025.0.4|
|[784783cd55c083d7acf8d830129d3eaabed35a72](https://github.com/arthw/llama.cpp/commit/784783cd55c083d7acf8d830129d3eaabed35a72)<br>2025-03-19 10:19:27<br>rm other backend ci, keep cpu, rpc, sycl<br><br>Zhang Jianyu  Log: [log](./log/784783cd55c083d7acf8d830129d3eaabed35a72)|97.0%<br>NA|54.77|tg=54.23<br>pp=802.0|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[348bc0979af65186873b63defc754f4f2df7fcf4](https://github.com/arthw/llama.cpp/commit/348bc0979af65186873b63defc754f4f2df7fcf4)<br>2025-03-18 07:27:50<br>llama: Add support for RWKV v7 architect<br>ure<br>Molly Sophia  Log: [log](./log/348bc0979af65186873b63defc754f4f2df7fcf4)|Build Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|3/2<br>2025.0.4|
|[b1972f5f7890f28c5461b66d4f2db44c2eb853e0](https://github.com/arthw/llama.cpp/commit/b1972f5f7890f28c5461b66d4f2db44c2eb853e0)<br>2025-03-18 01:51:25<br>fixed compilation warnings in ggml-sycl<br>Łukasz Ślusarczyk  Log: [log](./log/b1972f5f7890f28c5461b66d4f2db44c2eb853e0)|97.0%<br>NA|54.73|tg=54.42<br>pp=801.41|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[104d8bd5cad87f3138d40acf5fee7dfed9ba3b6d](https://github.com/arthw/llama.cpp/commit/104d8bd5cad87f3138d40acf5fee7dfed9ba3b6d)<br>2025-03-17 07:15:12<br>SYCL: set extras only on GGML_TYPE_Q4_0<br>Akarshan Biswas  Log: [log](./log/104d8bd5cad87f3138d40acf5fee7dfed9ba3b6d)|97.0%<br>NA|54.87|tg=52.65<br>pp=784.29|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[874af051a3d066f5f417a026df8f2a91bdf31ac8](https://github.com/arthw/llama.cpp/commit/874af051a3d066f5f417a026df8f2a91bdf31ac8)<br>2025-03-15 22:49:03<br>SYCL: Delete redundant plus sign and spa<br>ce<br>aubreyli  Log: [log](./log/874af051a3d066f5f417a026df8f2a91bdf31ac8)|97.0%<br>NA|53.03|tg=52.69<br>pp=800.57|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[822a6d3d9d8987b70afcabfb8ecde01f980f4a82](https://github.com/arthw/llama.cpp/commit/822a6d3d9d8987b70afcabfb8ecde01f980f4a82)<br>2025-03-15 15:19:30<br>SYCL : support non-contiguous tensors in<br> binary ops<br>fairydreaming  Log: [log](./log/822a6d3d9d8987b70afcabfb8ecde01f980f4a82)|97.0%<br>NA|52.88|tg=52.49<br>pp=799.38|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[deb2d2a40c1ace90d23d38213f785ac9a11bc731](https://github.com/arthw/llama.cpp/commit/deb2d2a40c1ace90d23d38213f785ac9a11bc731)<br>2025-03-03 15:37:22<br>SYCL: Move CPY kernels to a separate fil<br>e and add few missing kernels<br>Akarshan Biswas  Log: [log](./log/deb2d2a40c1ace90d23d38213f785ac9a11bc731)|100.0%<br>NA|54.05|tg=53.53<br>pp=801.1|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[50463a7286ccf0510505caa0db097f478bcc8c4e](https://github.com/arthw/llama.cpp/commit/50463a7286ccf0510505caa0db097f478bcc8c4e)<br>2025-02-28 05:41:47<br>ggml : upgrade init_tensor API to return<br> a ggml_status<br>William Tambellini  Log: [log](./log/50463a7286ccf0510505caa0db097f478bcc8c4e)|100.0%<br>NA|53.36|tg=53.07<br>pp=802.23|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[c5dc8e9e4edc80a162fe673017384d2894f73d36](https://github.com/arthw/llama.cpp/commit/c5dc8e9e4edc80a162fe673017384d2894f73d36)<br>2025-02-27 09:21:51<br>fix ut fault of Q4_1, Q5..<br>arthw  Log: [log](./log/c5dc8e9e4edc80a162fe673017384d2894f73d36)|100.0%<br>NA|54.22|tg=53.66<br>pp=801.03|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[7ba151d24bef8ff866074a18586b504d7de49e47](https://github.com/arthw/llama.cpp/commit/7ba151d24bef8ff866074a18586b504d7de49e47)<br>2025-02-26 22:16:33<br>add new line at end of file<br>Neo Zhang Jianyu  Log: [log](./log/7ba151d24bef8ff866074a18586b504d7de49e47)|97.0%<br>3939/3943|54.23|tg=53.68<br>pp=801.54|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[420e3b326679a9e0e9f251670daabaed7b49a3e1](https://github.com/arthw/llama.cpp/commit/420e3b326679a9e0e9f251670daabaed7b49a3e1)<br>2025-02-24 22:33:23<br>[SYCL] Optimize mul_mat for Q4_0 on Inte<br>l GPU<br>Neo Zhang Jianyu  Log: [log](./log/420e3b326679a9e0e9f251670daabaed7b49a3e1)|97.0%<br>3939/3943|54.32|tg=54.0<br>pp=802.27|('ok', 'pass', 0)|24/0<br>2025.0.4|
|[7fecf7f0b7123bb1df3028f636943d227dd95dbc](https://github.com/arthw/llama.cpp/commit/7fecf7f0b7123bb1df3028f636943d227dd95dbc)<br>2025-02-24 15:48:25<br>SYCL: Fix GGML_SYCL_DEBUG macro<br>Akarshan Biswas  Log: [log](./log/7fecf7f0b7123bb1df3028f636943d227dd95dbc)|97.0%<br>3939/3943|43.22|tg=43.19<br>pp=916.44|('ok', 'pass', 0)|36/0<br>2025.0.4|
|[edab2bd11bacddfd48315464a33f0945112cafa9](https://github.com/arthw/llama.cpp/commit/edab2bd11bacddfd48315464a33f0945112cafa9)<br>2025-02-15 16:40:57<br>repo : update links to new url<br>Georgi Gerganov  Log: [log](./log/edab2bd11bacddfd48315464a33f0945112cafa9)|97.0%<br>3500/3504|43.22|tg=43.1<br>pp=917.04|('ok', 'pass', 0)|32/0<br>2025.0.4|
|[cf7f1c12ca7ee553199ce812addeafaa5275f235](https://github.com/arthw/llama.cpp/commit/cf7f1c12ca7ee553199ce812addeafaa5275f235)<br>2025-02-07 14:57:53<br>SYCL: remove XMX info from print devices<br><br>Akarshan Biswas  Log: [log](./log/cf7f1c12ca7ee553199ce812addeafaa5275f235)|97.0%<br>3500/3504|43.15|tg=43.14<br>pp=916.78|('ok', 'pass', 0)|32/0<br>2025.0.4|
|[ee194915c8b41fbda120d1b8c8ea52880898298f](https://github.com/arthw/llama.cpp/commit/ee194915c8b41fbda120d1b8c8ea52880898298f)<br>2025-02-06 17:12:35<br>SYCL: Adjust support condition for norm <br>operators<br>Akarshan Biswas  Log: [log](./log/ee194915c8b41fbda120d1b8c8ea52880898298f)|97.0%<br>3500/3504|43.17|tg=43.14<br>pp=916.5|('ok', 'pass', 0)|32/0<br>2025.0.4|
|[6bb7538d3cdd0fc4b49a57c4dd889004e5da7373](https://github.com/arthw/llama.cpp/commit/6bb7538d3cdd0fc4b49a57c4dd889004e5da7373)<br>2025-01-28 15:26:58<br>SYCL : SOFTMAX F16 mask support and othe<br>r fixes<br>Akarshan Biswas  Log: [log](./log/6bb7538d3cdd0fc4b49a57c4dd889004e5da7373)|96.0%<br>3491/3496|43.12|tg=43.15<br>pp=915.95|('ok', 'pass', 0)|32/0<br>2025.0.4|
|[db9c9cc064d40ae5933c9280e157c3c321193245](https://github.com/arthw/llama.cpp/commit/db9c9cc064d40ae5933c9280e157c3c321193245)<br>2025-01-24 13:30:13<br>docs : Update readme to build targets fo<br>r local docker build<br>Jafar Uruç  Log: [log](./log/db9c9cc064d40ae5933c9280e157c3c321193245)|96.0%<br>3457/3461|43.14|tg=43.15<br>pp=916.51|('ok', 'pass', 0)|36/0<br>2025.0.4|
|[61259291b42f96b452ec067b724a90ca03eb545e](https://github.com/arthw/llama.cpp/commit/61259291b42f96b452ec067b724a90ca03eb545e)<br>2025-01-19 14:33:34<br>SYCL: Introducing memory host pool<br>Nicolò Scipione  Log: [log](./log/61259291b42f96b452ec067b724a90ca03eb545e)|96.0%<br>3269/3273|43.17|tg=43.16<br>pp=916.4|('ok', 'pass', 0)|36/0<br>2025.0.4|
|[b598146c9ac5f1c68cddf5e2bedad1fdc5d1a8f1](https://github.com/arthw/llama.cpp/commit/b598146c9ac5f1c68cddf5e2bedad1fdc5d1a8f1)<br>2025-01-15 08:50:17<br>SYCL: Add gated linear attention kernel<br>Akarshan Biswas  Log: [log](./log/b598146c9ac5f1c68cddf5e2bedad1fdc5d1a8f1)|96.0%<br>2216/2220|43.12|tg=43.14<br>pp=916.73|('ok', 'pass', 0)|36/0<br>2025.0.4|
|[4501233cc5ad7c289700a5860ea271421d5121ca](https://github.com/arthw/llama.cpp/commit/4501233cc5ad7c289700a5860ea271421d5121ca)<br>2025-01-12 11:32:42<br>llama : add `llama_vocab`, functions -> <br>methods, naming<br>Georgi Gerganov  Log: [log](./log/4501233cc5ad7c289700a5860ea271421d5121ca)|96.0%<br>2216/2220|43.16|tg=43.15<br>pp=916.07|('ok', 'pass', 0)|36/0<br>2025.0.4|
|[b73dbc56378fc59bfcbc69547a09c19cf2500ab0](https://github.com/arthw/llama.cpp/commit/b73dbc56378fc59bfcbc69547a09c19cf2500ab0)<br>2025-01-10 09:58:08<br>llama: add support for QRWKV6 model arch<br>itecture<br>Molly Sophia  Log: [log](./log/b73dbc56378fc59bfcbc69547a09c19cf2500ab0)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|36/0<br>2025.0.4|
|[8c87f2be19b841ee0a2769f2677a100bf767fb23](https://github.com/arthw/llama.cpp/commit/8c87f2be19b841ee0a2769f2677a100bf767fb23)<br>2025-01-10 05:43:03<br>SYCL: Refactor ggml_sycl_compute_forward<br><br>Akarshan Biswas  Log: [log](./log/8c87f2be19b841ee0a2769f2677a100bf767fb23)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|36/0<br>2025.0.4|
|[05a034b35caca012f136a6cd51019783a1a8fe17](https://github.com/arthw/llama.cpp/commit/05a034b35caca012f136a6cd51019783a1a8fe17)<br>2025-01-07 11:56:07<br>SYCL: Use get_multi_ptr instead of depre<br>cated get_pointer in wkv6<br>Akarshan Biswas  Log: [log](./log/05a034b35caca012f136a6cd51019783a1a8fe17)|96.0%<br>2212/2216|43.17|tg=43.23<br>pp=916.52|('ok', 'pass', 0)|40/0<br>2025.0.4|
|[7f97dccac994504eb2e33124393d393a830008b4](https://github.com/arthw/llama.cpp/commit/7f97dccac994504eb2e33124393d393a830008b4)<br>2024-12-23 10:39:30<br>rpc-server : add support for the SYCL ba<br>ckend<br>Radoslav Gerganov  Log: [log](./log/7f97dccac994504eb2e33124393d393a830008b4)|96.0%<br>2212/2216|43.11|tg=43.19<br>pp=915.23|('ok', 'pass', 0)|40/0<br>2025.0.4|
|[bcfe9787c97c67bba02f69cae742daf508edb37f](https://github.com/arthw/llama.cpp/commit/bcfe9787c97c67bba02f69cae742daf508edb37f)<br>2024-12-20 22:05:39<br>correct the device info format<br>arthw  Log: [log](./log/bcfe9787c97c67bba02f69cae742daf508edb37f)|93.0%<br>2212/2216|42.67|tg=42.78<br>pp=948.4|('ok', 'pass', 0)|264/0<br>2025.0.0|
|[7fed97b92243fa8d83bc0de3e24ddc4f0e2b616e](https://github.com/arthw/llama.cpp/commit/7fed97b92243fa8d83bc0de3e24ddc4f0e2b616e)<br>2024-12-20 21:01:28<br>SYCL: Migrate away from deprecated ggml_<br>tensor->backend<br>Akarshan Biswas  Log: [log](./log/7fed97b92243fa8d83bc0de3e24ddc4f0e2b616e)|96.0%<br>2212/2216|43.2|tg=43.13<br>pp=916.48|('ok', 'pass', 0)|40/0<br>2025.0.4|
|[c12caff4211ae6391609dd91aefdb952669aa0b4](https://github.com/arthw/llama.cpp/commit/c12caff4211ae6391609dd91aefdb952669aa0b4)<br>2024-12-14 20:43:46<br>llama : add Qwen2VL support + multimodal<br> RoPE<br>HimariO  Log: [log](./log/c12caff4211ae6391609dd91aefdb952669aa0b4)|93.0%<br>2212/2216|42.67|tg=42.81<br>pp=949.39|('ok', 'pass', 0)|264/0<br>2025.0.0|
|[a674ffbf6d41b626e1dfb29a7023f2c5bd1a24ef](https://github.com/arthw/llama.cpp/commit/a674ffbf6d41b626e1dfb29a7023f2c5bd1a24ef)<br>2024-12-13 12:12:15<br>SYCL: Reduce most of the compiler warnin<br>gs<br>Akarshan Biswas  Log: [log](./log/a674ffbf6d41b626e1dfb29a7023f2c5bd1a24ef)|93.0%<br>2200/2204|42.66|tg=42.78<br>pp=948.71|('ok', 'pass', 0)|264/0<br>2025.0.0|
|[d90c615041e3bdda82412b03cf0d61977a509bf4](https://github.com/arthw/llama.cpp/commit/d90c615041e3bdda82412b03cf0d61977a509bf4)<br>2024-12-07 13:37:50<br>ggml : refactor online repacking<br>Djip007  Log: [log](./log/d90c615041e3bdda82412b03cf0d61977a509bf4)|93.0%<br>2200/2204|42.71|tg=42.77<br>pp=949.17|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[e480feb741c1944fb9505e7176a82e2e0a4cf143](https://github.com/arthw/llama.cpp/commit/e480feb741c1944fb9505e7176a82e2e0a4cf143)<br>2024-12-04 08:26:37<br>clip : add sycl support<br>piDack  Log: [log](./log/e480feb741c1944fb9505e7176a82e2e0a4cf143)|93.0%<br>2196/2200|42.66|tg=42.81<br>pp=948.73|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[db892e11b4de94157682ce06f8dd2bf66d629a57](https://github.com/arthw/llama.cpp/commit/db892e11b4de94157682ce06f8dd2bf66d629a57)<br>2024-12-04 02:29:20<br>SYCL : Move to compile time oneMKL inter<br>face backend selection for NVIDIA backen<br>d<br>Nicolò Scipione  Log: [log](./log/db892e11b4de94157682ce06f8dd2bf66d629a57)|93.0%<br>2196/2200|42.66|tg=42.76<br>pp=949.29|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[00bd8917c5cfa44aa65d8bf00c352ff8dc495d0a](https://github.com/arthw/llama.cpp/commit/00bd8917c5cfa44aa65d8bf00c352ff8dc495d0a)<br>2024-11-29 12:38:45<br>sycl : offload of get_rows set to 0<br>Alberto Cabrera Pérez  Log: [log](./log/00bd8917c5cfa44aa65d8bf00c352ff8dc495d0a)|93.0%<br>1915/1919|42.7|tg=42.8<br>pp=948.57|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[a64f340ada53193628df20302ac2878afbe97e77](https://github.com/arthw/llama.cpp/commit/a64f340ada53193628df20302ac2878afbe97e77)<br>2024-11-29 09:49:43<br>sycl : Reroute permuted mul_mats through<br> oneMKL<br>Alberto Cabrera Pérez  Log: [log](./log/a64f340ada53193628df20302ac2878afbe97e77)|93.0%<br>1915/1919|42.63|tg=42.73<br>pp=903.93|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[c9dd5ab17073cf1b993d4e8bcc3cc4056cdaaeef](https://github.com/arthw/llama.cpp/commit/c9dd5ab17073cf1b993d4e8bcc3cc4056cdaaeef)<br>2024-11-25 17:31:10<br>[SYCL] Fix building Win package for oneA<br>PI 2025.0 update<br>Neo Zhang Jianyu  Log: [log](./log/c9dd5ab17073cf1b993d4e8bcc3cc4056cdaaeef)|93.0%<br>NA|42.66|tg=42.71<br>pp=904.64|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[fa4365c6f1697084ecbe87778177e46fbc8d9559](https://github.com/arthw/llama.cpp/commit/fa4365c6f1697084ecbe87778177e46fbc8d9559)<br>2024-11-25 15:13:39<br>ggml : add support for dynamic loading o<br>f backends<br>Diego Devesa  Log: [log](./log/fa4365c6f1697084ecbe87778177e46fbc8d9559)|93.0%<br>NA|42.65|tg=42.73<br>pp=918.67|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[68b25ede0c67a92ea5f7beb8d08be4ffa664ec74](https://github.com/arthw/llama.cpp/commit/68b25ede0c67a92ea5f7beb8d08be4ffa664ec74)<br>2024-11-20 13:54:25<br>update rel to 4040<br>Neo Zhang Jianyu  Log: [log](./log/68b25ede0c67a92ea5f7beb8d08be4ffa664ec74)|93.0%<br>NA|42.66|tg=42.79<br>pp=905.23|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[9a59aa2e6bba59feda3e6a8d22bcfa1181516206](https://github.com/arthw/llama.cpp/commit/9a59aa2e6bba59feda3e6a8d22bcfa1181516206)<br>2024-11-19 09:02:23<br>sycl : Add option to set the SYCL archit<br>ecture for all targets<br>Romain Biessy  Log: [log](./log/9a59aa2e6bba59feda3e6a8d22bcfa1181516206)|93.0%<br>NA|42.65|tg=42.76<br>pp=903.83|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[a97920143e2dc05e9919dabdb3de091dddec0d02](https://github.com/arthw/llama.cpp/commit/a97920143e2dc05e9919dabdb3de091dddec0d02)<br>2024-11-19 08:20:52<br>fix for windows building<br>arthw  Log: [log](./log/a97920143e2dc05e9919dabdb3de091dddec0d02)|93.0%<br>NA|41.27|tg=42.73<br>pp=906.04|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[74b246bc63633bbd6e649172f1a525085793968c](https://github.com/arthw/llama.cpp/commit/74b246bc63633bbd6e649172f1a525085793968c)<br>2024-11-19 00:50:04<br>sycl: Revert MUL_MAT_OP support changes<br>Alberto Cabrera Pérez  Log: [log](./log/74b246bc63633bbd6e649172f1a525085793968c)|93.0%<br>NA|42.65|tg=42.78<br>pp=904.68|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[7e98ad63bd1f5f77db49495a29836a638d5b08d1](https://github.com/arthw/llama.cpp/commit/7e98ad63bd1f5f77db49495a29836a638d5b08d1)<br>2024-11-18 15:18:04<br>fix error<br>arthw  Log: [log](./log/7e98ad63bd1f5f77db49495a29836a638d5b08d1)|93.0%<br>1603/1607|41.34|tg=42.77<br>pp=951.76|('ok', 'pass', 0)|536/0<br>2025.0.0|
|[71ee846eabeaa74f25273335f6a48599a23fe581](https://github.com/arthw/llama.cpp/commit/71ee846eabeaa74f25273335f6a48599a23fe581)<br>2024-11-18 14:22:50<br>restore context to 4096 for perf test st<br>andard<br>arthw  Log: [log](./log/71ee846eabeaa74f25273335f6a48599a23fe581)|93.0%<br>1597/1601|41.27|tg=42.71<br>pp=951.07|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[6b559cc88205d379ee838122cc53bd2993dc7006](https://github.com/arthw/llama.cpp/commit/6b559cc88205d379ee838122cc53bd2993dc7006)<br>2024-11-15 12:10:45<br>sycl: Update Intel docker images to use <br>DPC++ 2025.0<br>Romain Biessy  Log: [log](./log/6b559cc88205d379ee838122cc53bd2993dc7006)|93.0%<br>NA|41.29|tg=42.77<br>pp=906.23|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[e0dc41a443fb42adb695d9e691be8aefde1212cd](https://github.com/arthw/llama.cpp/commit/e0dc41a443fb42adb695d9e691be8aefde1212cd)<br>2024-11-15 04:09:12<br>sycl: Use syclcompat::dp4a<br>Romain Biessy  Log: [log](./log/e0dc41a443fb42adb695d9e691be8aefde1212cd)|93.0%<br>NA|41.29|tg=42.72<br>pp=906.44|('ok', 'pass', 0)|628/0<br>2025.0.0|
|[b3abcd3a44b6078c333f073356ee2f05d5fb76ca](https://github.com/arthw/llama.cpp/commit/b3abcd3a44b6078c333f073356ee2f05d5fb76ca)<br>2024-11-14 18:04:35<br>ggml : build backends as libraries<br>Diego Devesa  Log: [log](./log/b3abcd3a44b6078c333f073356ee2f05d5fb76ca)|93.0%<br>NA|41.34|tg=42.71<br>pp=906.13|('ok', 'pass', 0)|644/0<br>2025.0.0|
|[4c7310ded88a4de290a0a97621ef8b2a235287d7](https://github.com/arthw/llama.cpp/commit/4c7310ded88a4de290a0a97621ef8b2a235287d7)<br>2024-11-07 18:19:10<br>Optimize RWKV6 Operator Naming and Imple<br>ment Multi-core CPU/ SYCL Acceleration<br>Zhiyuan Li  Log: [log](./log/4c7310ded88a4de290a0a97621ef8b2a235287d7)|93.0%<br>NA|41.33|tg=42.65<br>pp=905.63|('ok', 'pass', 0)|638/0<br>2025.0.0|
|[99255721763e472628dbbc2be25da42ba6a5dd7f](https://github.com/arthw/llama.cpp/commit/99255721763e472628dbbc2be25da42ba6a5dd7f)<br>2024-10-30 02:01:23<br>llama : refactor model loader with backe<br>nd registry<br>Diego Devesa  Log: [log](./log/99255721763e472628dbbc2be25da42ba6a5dd7f)|93.0%<br>NA|41.32|tg=42.72<br>pp=943.9|('ok', 'pass', 0)|538/0<br>2025.0.0|
|[a5f5aad986e216bf5e3ee6a459e459486dd28849](https://github.com/arthw/llama.cpp/commit/a5f5aad986e216bf5e3ee6a459e459486dd28849)<br>2024-10-24 21:23:33<br>ci : fix cmake flags for SYCL<br>Georgi Gerganov  Log: [log](./log/a5f5aad986e216bf5e3ee6a459e459486dd28849)|93.0%<br>NA|41.31|tg=42.7<br>pp=952.83|('ok', 'pass', 0)|536/0<br>2025.0.0|
|[f2b7df5b78789de5bee247d00c7f613448379363](https://github.com/arthw/llama.cpp/commit/f2b7df5b78789de5bee247d00c7f613448379363)<br>2024-10-21 14:26:09<br>fix mul_mat_vec_q and *_vec_q error<br>Neo Zhang Jianyu  Log: [log](./log/f2b7df5b78789de5bee247d00c7f613448379363)|Build Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|11/20<br>2025.0.0|
|[ccb5cbcb4b0b00a438232c311a6046252f8861ea](https://github.com/arthw/llama.cpp/commit/ccb5cbcb4b0b00a438232c311a6046252f8861ea)<br>2024-10-18 06:46:16<br>[SYCL] Add SYCL Backend registry, device<br> and Event Interfaces<br>Ouadie EL FAROUKI  Log: [log](./log/ccb5cbcb4b0b00a438232c311a6046252f8861ea)|93.0%<br>1603/1607|41.32|tg=42.68<br>pp=950.73|('ok', 'pass', 0)|536/0<br>2025.0.0|
|[9ccecbac5d241de7a7d72d341df9415ce3b67c2a](https://github.com/arthw/llama.cpp/commit/9ccecbac5d241de7a7d72d341df9415ce3b67c2a)<br>2024-10-03 07:50:44<br>Fixed dequant precision issues in Q4_1 a<br>nd Q5_1<br>Ouadie EL FAROUKI  Log: [log](./log/9ccecbac5d241de7a7d72d341df9415ce3b67c2a)|96.0%<br>NA|41.34|tg=42.75<br>pp=952.65|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[230f88ac27b377ea6f863980e2af0990e78dc03a](https://github.com/arthw/llama.cpp/commit/230f88ac27b377ea6f863980e2af0990e78dc03a)<br>2024-10-03 01:49:47<br>ggml-backend : add device and backend re<br>g interfaces<br>Diego Devesa  Log: [log](./log/230f88ac27b377ea6f863980e2af0990e78dc03a)|96.0%<br>NA|41.32|tg=42.75<br>pp=953.41|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[8f7e0876fa473fdd63dd31eb5f9f4c49a22077e3](https://github.com/arthw/llama.cpp/commit/8f7e0876fa473fdd63dd31eb5f9f4c49a22077e3)<br>2024-10-02 13:57:18<br>[SYCL] Initial cmake support of SYCL for<br> AMD GPUs<br>Alberto Cabrera Pérez  Log: [log](./log/8f7e0876fa473fdd63dd31eb5f9f4c49a22077e3)|93.0%<br>1601/1605|41.31|tg=42.74<br>pp=953.07|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[5b9803ee14bd14a2a7579b5d4e4f7c9e9d2586aa](https://github.com/arthw/llama.cpp/commit/5b9803ee14bd14a2a7579b5d4e4f7c9e9d2586aa)<br>2024-09-26 17:38:31<br>[SYCL] add missed dll file in package<br>Neo Zhang Jianyu  Log: [log](./log/5b9803ee14bd14a2a7579b5d4e4f7c9e9d2586aa)|93.0%<br>1601/1605|41.26|tg=42.73<br>pp=952.15|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[45b9f19fa248ba09783496276e444699f92c174a](https://github.com/arthw/llama.cpp/commit/45b9f19fa248ba09783496276e444699f92c174a)<br>2024-09-23 08:58:06<br>Revert "[SYCL] fallback mmvq<br>Akarshan Biswas  Log: [log](./log/45b9f19fa248ba09783496276e444699f92c174a)|93.0%<br>1601/1605|41.3|tg=42.72<br>pp=949.54|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[50d253c1c513f4a537155664e4374bd7e159aedd](https://github.com/arthw/llama.cpp/commit/50d253c1c513f4a537155664e4374bd7e159aedd)<br>2024-09-20 20:12:52<br>ggml : fix builds<br>Georgi Gerganov  Log: [log](./log/50d253c1c513f4a537155664e4374bd7e159aedd)|93.0%<br>1597/1601|41.31|tg=42.74<br>pp=954.25|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[d4d42566debb6aeb05a8eb7d7aa2f976acd26ec8](https://github.com/arthw/llama.cpp/commit/d4d42566debb6aeb05a8eb7d7aa2f976acd26ec8)<br>2024-09-20 19:04:44<br>ggml/examples: add backend support for n<br>umerical optimization<br>Johannes Gäßler  Log: [log](./log/d4d42566debb6aeb05a8eb7d7aa2f976acd26ec8)|Build Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|76/3<br>2025.0.0|
|[6e0564c286a3bfc90d4abb6dbb658e9c70db81d9](https://github.com/arthw/llama.cpp/commit/6e0564c286a3bfc90d4abb6dbb658e9c70db81d9)<br>2024-09-18 08:30:31<br>[SYCL]set context default value to avoid<br> memory issue, update guide<br>Neo Zhang Jianyu  Log: [log](./log/6e0564c286a3bfc90d4abb6dbb658e9c70db81d9)|93.0%<br>1438/1442|41.32|tg=42.72<br>pp=952.43|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1:', 0)|534/0<br>2025.0.0|
|[74e41abc0e89395c568991df641349a74a6e8e5b](https://github.com/arthw/llama.cpp/commit/74e41abc0e89395c568991df641349a74a6e8e5b)<br>2024-09-15 18:55:52<br>cmake : correct order of sycl flags<br>Michael Podvitskiy  Log: [log](./log/74e41abc0e89395c568991df641349a74a6e8e5b)|92.0%<br>1438/1442|41.34|tg=42.71<br>pp=951.04|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[f86e8db62950f1bd93c274a41d6dfba9fac28f8c](https://github.com/arthw/llama.cpp/commit/f86e8db62950f1bd93c274a41d6dfba9fac28f8c)<br>2024-09-15 09:06:38<br>cmake : try to fix sycl+intel build<br>Michael Podvitskiy  Log: [log](./log/f86e8db62950f1bd93c274a41d6dfba9fac28f8c)|92.0%<br>1438/1442|41.33|tg=42.7<br>pp=952.82|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[299e70d39cb457b435f8881c12e479517b37f43b](https://github.com/arthw/llama.cpp/commit/299e70d39cb457b435f8881c12e479517b37f43b)<br>2024-09-12 17:44:17<br>enhance run script to be easy to change <br>the parameters<br>Neo Zhang Jianyu  Log: [log](./log/299e70d39cb457b435f8881c12e479517b37f43b)|92.0%<br>1438/1442|41.33|tg=42.74<br>pp=948.77|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[4aa7e80b7c4f1c81289725f28e98e716bcd15670](https://github.com/arthw/llama.cpp/commit/4aa7e80b7c4f1c81289725f28e98e716bcd15670)<br>2024-09-12 14:23:49<br>ggml : hide ggml_object, ggml_cgraph, gg<br>ml_hash_set<br>Georgi Gerganov  Log: [log](./log/4aa7e80b7c4f1c81289725f28e98e716bcd15670)|92.0%<br>1438/1442|41.37|tg=42.7<br>pp=947.05|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[7823459807682b5d299059eb725574a9ae60711c](https://github.com/arthw/llama.cpp/commit/7823459807682b5d299059eb725574a9ae60711c)<br>2024-09-11 01:53:42<br>sycl : update support conditions<br>Alberto Cabrera Pérez  Log: [log](./log/7823459807682b5d299059eb725574a9ae60711c)|92.0%<br>1438/1442|41.31|tg=NA<br>pp=NA|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[dd8df932a30a6d79558b87f27531be50ffef96b1](https://github.com/arthw/llama.cpp/commit/dd8df932a30a6d79558b87f27531be50ffef96b1)<br>2024-09-08 19:05:29<br>[SYCL] add check malloc result on device<br><br>Neo Zhang Jianyu  Log: [log](./log/dd8df932a30a6d79558b87f27531be50ffef96b1)|92.0%<br>NA|41.28|tg=NA<br>pp=NA|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[1085098fd47606ae881c712e34c178f01ad07084](https://github.com/arthw/llama.cpp/commit/1085098fd47606ae881c712e34c178f01ad07084)<br>2024-08-30 20:10:01<br>Correct typo run_llama2.sh > run-llama2.<br>sh<br>蕭澧邦  Log: [log](./log/1085098fd47606ae881c712e34c178f01ad07084)|92.0%<br>1417/1421|41.25|tg=NA<br>pp=NA|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[bc65fcf2b7098793689e6892815dfc03a3f3e03f](https://github.com/arthw/llama.cpp/commit/bc65fcf2b7098793689e6892815dfc03a3f3e03f)<br>2024-08-22 19:39:47<br>[SYCL] Add a space to supress a cmake wa<br>rning<br>Akarshan Biswas  Log: [log](./log/bc65fcf2b7098793689e6892815dfc03a3f3e03f)|92.0%<br>1338/1342|41.29|tg=NA<br>pp=NA|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[88ed956ae969c0875246517cb757394c0192755d](https://github.com/arthw/llama.cpp/commit/88ed956ae969c0875246517cb757394c0192755d)<br>2024-08-22 12:50:10<br>[SYCL] Add oneDNN primitive support<br>luoyu-intel  Log: [log](./log/88ed956ae969c0875246517cb757394c0192755d)|92.0%<br>1338/1342|41.32|tg=NA<br>pp=NA|('ok', 'pass', 0)|534/0<br>2025.0.0|
|[20ae2d8331ac563ec3f61b2f246018441fdfe9be](https://github.com/arthw/llama.cpp/commit/20ae2d8331ac563ec3f61b2f246018441fdfe9be)<br>2024-08-20 23:50:17<br>[SYCL] fallback mmvq<br>Meng, Hengyu  Log: [log](./log/20ae2d8331ac563ec3f61b2f246018441fdfe9be)|92.0%<br>1338/1342|41.3|tg=NA<br>pp=NA|('ok', 'pass', 0)|516/0<br>2025.0.0|
|[5fcebd877e2372f5b4ce3a1cc635a8ce215983fa](https://github.com/arthw/llama.cpp/commit/5fcebd877e2372f5b4ce3a1cc635a8ce215983fa)<br>2024-08-20 23:06:51<br>[SYCL] Fix SYCL `im2col` and `convert` O<br>verflow with Large Dims<br>zhentaoyu  Log: [log](./log/5fcebd877e2372f5b4ce3a1cc635a8ce215983fa)|92.0%<br>1338/1342|41.31|tg=NA<br>pp=NA|('ok', 'pass', 0)|516/0<br>2025.0.0|
|[7e935f3b64d17ff50637f0c7ce6b126250a90d8c](https://github.com/arthw/llama.cpp/commit/7e935f3b64d17ff50637f0c7ce6b126250a90d8c)<br>2024-08-13 21:13:15<br>ggml : move rope type enum to ggml.h<br>Daniel Bevenius  Log: [log](./log/7e935f3b64d17ff50637f0c7ce6b126250a90d8c)|92.0%<br>1338/1342|41.28|tg=NA<br>pp=NA|('ok', 'pass', 0)|502/0<br>2025.0.0|
|[ee55b946a670ad1441d03f31c340c4c339aa04c4](https://github.com/arthw/llama.cpp/commit/ee55b946a670ad1441d03f31c340c4c339aa04c4)<br>2024-08-11 16:37:43<br>update guide<br>Neo Zhang  Log: [log](./log/ee55b946a670ad1441d03f31c340c4c339aa04c4)|92.0%<br>1338/1342|41.29|tg=NA<br>pp=NA|('ok', 'pass', 0)|502/0<br>2025.0.0|
|[75a32668b0d8d3e5f1c0fe62ed8e24b8d635a362](https://github.com/arthw/llama.cpp/commit/75a32668b0d8d3e5f1c0fe62ed8e24b8d635a362)<br>2024-08-07 23:22:50<br>fix error<br>arthw  Log: [log](./log/75a32668b0d8d3e5f1c0fe62ed8e24b8d635a362)|92.0%<br>1338/1342|42.91|tg=NA<br>pp=NA|('ok', 'pass', 0)|504/0<br>2024.2.1|
|[ef4b1efcb9754626ec8821ef65bb16dc24998d9d](https://github.com/arthw/llama.cpp/commit/ef4b1efcb9754626ec8821ef65bb16dc24998d9d)<br>2024-08-07 11:25:36<br>[SYCL] Updated SYCL device filtering<br>Ouadie EL FAROUKI  Log: [log](./log/ef4b1efcb9754626ec8821ef65bb16dc24998d9d)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|476/0<br>2024.2.1|
|[924ddb54d0ed737f7899a6cbf3ad5d67b21a90b6](https://github.com/arthw/llama.cpp/commit/924ddb54d0ed737f7899a6cbf3ad5d67b21a90b6)<br>2024-08-06 15:26:46<br>ggml : add epsilon as a parameter for gr<br>oup_norm<br>Molly Sophia  Log: [log](./log/924ddb54d0ed737f7899a6cbf3ad5d67b21a90b6)|Execute_Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Error to run gguf', 0)|476/0<br>2024.2.1|
|[11c713b84415b93542dcb388cdc2b353c21c499c](https://github.com/arthw/llama.cpp/commit/11c713b84415b93542dcb388cdc2b353c21c499c)<br>2024-08-02 01:55:17<br>[SYCL] Fixing wrong VDR iq4nl value<br>Ouadie EL FAROUKI  Log: [log](./log/11c713b84415b93542dcb388cdc2b353c21c499c)|92.0%<br>1347/1351|42.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|504/0<br>2024.2.1|
|[345606c4b9f21678d0d2875b64d76c204ffb35c3](https://github.com/arthw/llama.cpp/commit/345606c4b9f21678d0d2875b64d76c204ffb35c3)<br>2024-08-01 14:43:08<br>fix link<br>arthw  Log: [log](./log/345606c4b9f21678d0d2875b64d76c204ffb35c3)|92.0%<br>1332/1334|42.93|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[7e63e58ab1acd81dc31d4b938529b40a366cbe6d](https://github.com/arthw/llama.cpp/commit/7e63e58ab1acd81dc31d4b938529b40a366cbe6d)<br>2024-08-01 14:20:41<br>update guide<br>arthw  Log: [log](./log/7e63e58ab1acd81dc31d4b938529b40a366cbe6d)|92.0%<br>1332/1334|42.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[f1bc5ad852d3007864bfca5c8898554a970fc1e6](https://github.com/arthw/llama.cpp/commit/f1bc5ad852d3007864bfca5c8898554a970fc1e6)<br>2024-08-01 13:14:58<br>add final newline<br>arthw  Log: [log](./log/f1bc5ad852d3007864bfca5c8898554a970fc1e6)|92.0%<br>1332/1334|42.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[4d71c98544c9150d974878867e1277a57d94ecb2](https://github.com/arthw/llama.cpp/commit/4d71c98544c9150d974878867e1277a57d94ecb2)<br>2024-08-01 12:52:06<br>mv dpct/helper.hpp to dpct.hpp<br>arthw  Log: [log](./log/4d71c98544c9150d974878867e1277a57d94ecb2)|92.0%<br>1332/1334|42.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[254a750249f74e838e744eedd8607f05fe9707d7](https://github.com/arthw/llama.cpp/commit/254a750249f74e838e744eedd8607f05fe9707d7)<br>2024-08-01 12:48:18<br>rename device_infos to infos<br>arthw  Log: [log](./log/254a750249f74e838e744eedd8607f05fe9707d7)|92.0%<br>1332/1334|42.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[6211ac040886495c44ad2ddee80204c9bcd6721a](https://github.com/arthw/llama.cpp/commit/6211ac040886495c44ad2ddee80204c9bcd6721a)<br>2024-08-01 12:42:11<br>simple code for loop<br>arthw  Log: [log](./log/6211ac040886495c44ad2ddee80204c9bcd6721a)|92.0%<br>1332/1334|42.96|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[1947c1200e1f5fd40ca8606454fe097efd3505aa](https://github.com/arthw/llama.cpp/commit/1947c1200e1f5fd40ca8606454fe097efd3505aa)<br>2024-08-01 11:21:16<br>support set main gpu<br>arthw  Log: [log](./log/1947c1200e1f5fd40ca8606454fe097efd3505aa)|92.0%<br>1332/1334|42.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.1|
|[d5380f3af20cf5dd8d8a95854767891f29c5a4d1](https://github.com/arthw/llama.cpp/commit/d5380f3af20cf5dd8d8a95854767891f29c5a4d1)<br>2024-07-30 23:49:34<br>refactor device in sycl_device, restore <br>ctx in create_queue<br>arthw  Log: [log](./log/d5380f3af20cf5dd8d8a95854767891f29c5a4d1)|92.0%<br>1332/1334|42.93|tg=NA<br>pp=NA|('ok', 'pass', 0)|472/0<br>2024.2.1|
|[e1256c69e3d63d539b8a31c2d0f83ba24aad2a95](https://github.com/arthw/llama.cpp/commit/e1256c69e3d63d539b8a31c2d0f83ba24aad2a95)<br>2024-07-30 14:56:51<br>[SYCL] Add `TIMESTEP_EMBEDDING` OP<br>zhentaoyu  Log: [log](./log/e1256c69e3d63d539b8a31c2d0f83ba24aad2a95)|92.0%<br>1332/1334|42.94|tg=NA<br>pp=NA|('ok', 'pass', 0)|504/0<br>2024.2.1|
|[faaebf16a14e7417b2a76342ddd1ebb1e3e52f50](https://github.com/arthw/llama.cpp/commit/faaebf16a14e7417b2a76342ddd1ebb1e3e52f50)<br>2024-07-29 10:50:27<br>[SYCL] add conv support<br>Meng, Hengyu  Log: [log](./log/faaebf16a14e7417b2a76342ddd1ebb1e3e52f50)|92.0%<br>1332/1334|42.93|tg=NA<br>pp=NA|('ok', 'pass', 0)|488/0<br>2024.2.1|
|[e702f2ff117a165dea685937dd4afb4c5306ec54](https://github.com/arthw/llama.cpp/commit/e702f2ff117a165dea685937dd4afb4c5306ec54)<br>2024-07-27 04:41:55<br>ggml : reduce hash table reset cost<br>slaren  Log: [log](./log/e702f2ff117a165dea685937dd4afb4c5306ec54)|92.0%<br>1332/1334|42.95|tg=NA<br>pp=NA|('ok', 'pass', 0)|478/0<br>2024.2.1|
|[0aeae29190ccc052bdab49d6034dc96d9c51c99f](https://github.com/arthw/llama.cpp/commit/0aeae29190ccc052bdab49d6034dc96d9c51c99f)<br>2024-07-24 14:36:00<br>Build Llama SYCL Intel with static libs<br>Joe Todd  Log: [log](./log/0aeae29190ccc052bdab49d6034dc96d9c51c99f)|92.0%<br>1332/1334|42.8|tg=NA<br>pp=NA|('ok', 'pass', 0)|482/0<br>2024.2.1|
|[146da8b6c635f817a78480ff71cceff8ed51ea5a](https://github.com/arthw/llama.cpp/commit/146da8b6c635f817a78480ff71cceff8ed51ea5a)<br>2024-07-24 11:55:26<br>Re-add erroneously removed -fsycl from G<br>GML_EXTRA_LIBS<br>Joe Todd  Log: [log](./log/146da8b6c635f817a78480ff71cceff8ed51ea5a)|92.0%<br>1332/1334|42.75|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[e2d7ec46fc0b64762fbf7b22d6e24b589b741438](https://github.com/arthw/llama.cpp/commit/e2d7ec46fc0b64762fbf7b22d6e24b589b741438)<br>2024-07-23 14:58:37<br>sycl : Add support for non-release DPC++<br> & oneMKL<br>Joe Todd  Log: [log](./log/e2d7ec46fc0b64762fbf7b22d6e24b589b741438)|92.0%<br>1332/1334|42.78|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.2.1|
|[a9c03e482701d00291401eca929de66f08280a92](https://github.com/arthw/llama.cpp/commit/a9c03e482701d00291401eca929de66f08280a92)<br>2024-07-23 07:43:28<br>[SYCL] fix scratch size of softmax<br>luoyu-intel  Log: [log](./log/a9c03e482701d00291401eca929de66f08280a92)|92.0%<br>1332/1334|42.59|tg=NA<br>pp=NA|('ok', 'pass', 0)|482/0<br>2024.2.1|
|[88db0dc6be323da7b2cd31f82752d9e552d56825](https://github.com/arthw/llama.cpp/commit/88db0dc6be323da7b2cd31f82752d9e552d56825)<br>2024-07-15 19:32:15<br>[SYCL] add concat through dim 1/2<br>Meng, Hengyu  Log: [log](./log/88db0dc6be323da7b2cd31f82752d9e552d56825)|91.0%<br>1279/1281|42.76|tg=NA<br>pp=NA|('ok', 'pass', 0)|482/0<br>2024.2.1|
|[a364ec78f3ab2c240269ff370265815357753012](https://github.com/arthw/llama.cpp/commit/a364ec78f3ab2c240269ff370265815357753012)<br>2024-07-14 11:07:56<br>fix UT of concat<br>arthw  Log: [log](./log/a364ec78f3ab2c240269ff370265815357753012)|91.0%<br>1279/1281|42.73|tg=NA<br>pp=NA|('ok', 'pass', 0)|474/0<br>2024.2.0|
|[e700d37f68b5473390a3aa39f2c63aaa5f0d6eab](https://github.com/arthw/llama.cpp/commit/e700d37f68b5473390a3aa39f2c63aaa5f0d6eab)<br>2024-07-14 01:02:58<br>mv softmax to separated file<br>Neo Zhang  Log: [log](./log/e700d37f68b5473390a3aa39f2c63aaa5f0d6eab)|91.0%<br>NA|42.77|tg=NA<br>pp=NA|('ok', 'pass', 0)|472/0<br>2024.2.0|
|[a4c8edcb67be8a496c27b67aa9d37690d9519e5e](https://github.com/arthw/llama.cpp/commit/a4c8edcb67be8a496c27b67aa9d37690d9519e5e)<br>2024-07-14 00:15:55<br>fix for multiple cards<br>Neo Zhang  Log: [log](./log/a4c8edcb67be8a496c27b67aa9d37690d9519e5e)|91.0%<br>NA|42.71|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[74e3185cfd51d39a4738b631db5ced23eea7f1c6](https://github.com/arthw/llama.cpp/commit/74e3185cfd51d39a4738b631db5ced23eea7f1c6)<br>2024-07-13 16:02:15<br>fix editorconfig check format issue<br>arthw  Log: [log](./log/74e3185cfd51d39a4738b631db5ced23eea7f1c6)|91.0%<br>NA|42.75|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[4cd9e48670c7009099f4d900a5f3461cfb802755](https://github.com/arthw/llama.cpp/commit/4cd9e48670c7009099f4d900a5f3461cfb802755)<br>2024-07-13 14:43:57<br>cherry-pick b549a1bbefb2f1fbb8b558bac1f2<br>ae7967e60964,<br>arthw  Log: [log](./log/4cd9e48670c7009099f4d900a5f3461cfb802755)|91.0%<br>NA|42.72|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[fa700d1a84e9f41763f63acb3084541910e545b8](https://github.com/arthw/llama.cpp/commit/fa700d1a84e9f41763f63acb3084541910e545b8)<br>2024-07-12 00:52:04<br>[SYCL] fix the mul_mat_id ut issues<br>Chen Xi  Log: [log](./log/fa700d1a84e9f41763f63acb3084541910e545b8)|Build Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 29: <br>./build/bin/llama-cli: No such file or d<br>', 0)|53/2<br>2024.2.0|
|[35b1aff5cfd4f5dbf0d60a2084c995dd22f7eb2a](https://github.com/arthw/llama.cpp/commit/35b1aff5cfd4f5dbf0d60a2084c995dd22f7eb2a)<br>2024-07-10 16:10:49<br>[SYCL] Use multi_ptr to clean up depreca<br>ted warnings<br>AidanBeltonS  Log: [log](./log/35b1aff5cfd4f5dbf0d60a2084c995dd22f7eb2a)|Build Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 29: <br>./build/bin/llama-cli: No such file or d<br>', 0)|53/2<br>2024.2.0|
|[7a8fa37316f2765c9fc09422ce3939d1e5b79777](https://github.com/arthw/llama.cpp/commit/7a8fa37316f2765c9fc09422ce3939d1e5b79777)<br>2024-07-08 21:35:17<br>labeler : updated sycl to match docs and<br> code refactor<br>Alberto Cabrera Pérez  Log: [log](./log/7a8fa37316f2765c9fc09422ce3939d1e5b79777)|91.0%<br>NA|42.7|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[a7d77816921f8f1eb75a0ed79b245d86e71e6ff6](https://github.com/arthw/llama.cpp/commit/a7d77816921f8f1eb75a0ed79b245d86e71e6ff6)<br>2024-07-08 14:22:41<br>sycl : fix powf call in device code<br>Alberto Cabrera Pérez  Log: [log](./log/a7d77816921f8f1eb75a0ed79b245d86e71e6ff6)|91.0%<br>NA|42.73|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[86d41e6e1c84be041736d339e5f643cd05cf1b70](https://github.com/arthw/llama.cpp/commit/86d41e6e1c84be041736d339e5f643cd05cf1b70)<br>2024-07-08 13:51:31<br>scripts : fix sync for sycl<br>Georgi Gerganov  Log: [log](./log/86d41e6e1c84be041736d339e5f643cd05cf1b70)|91.0%<br>NA|42.73|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[16ab65b7b9e1ed8cc774c9d09d05bbc109a05a57](https://github.com/arthw/llama.cpp/commit/16ab65b7b9e1ed8cc774c9d09d05bbc109a05a57)<br>2024-07-05 18:08:32<br>Reorganize documentation pages<br>Xuan Son Nguyen  Log: [log](./log/16ab65b7b9e1ed8cc774c9d09d05bbc109a05a57)|91.0%<br>NA|42.75|tg=NA<br>pp=NA|('ok', 'pass', 0)|686/0<br>2024.2.0|
|[fdef7d606ef4864ceb5f51a576c0ecddec2cce2a](https://github.com/arthw/llama.cpp/commit/fdef7d606ef4864ceb5f51a576c0ecddec2cce2a)<br>2024-07-04 11:55:23<br>replace get_work_group_size<br>Neo Zhang  Log: [log](./log/fdef7d606ef4864ceb5f51a576c0ecddec2cce2a)|91.0%<br>NA|41.14|tg=NA<br>pp=NA|('ok', 'pass', 0)|556/0<br>2024.2.0|
|[249347995825713ad03b9cda3a036851f2e95033](https://github.com/arthw/llama.cpp/commit/249347995825713ad03b9cda3a036851f2e95033)<br>2024-07-04 08:28:58<br>skip UT for BF16<br>Neo Zhang  Log: [log](./log/249347995825713ad03b9cda3a036851f2e95033)|91.0%<br>NA|41.13|tg=NA<br>pp=NA|('ok', 'pass', 0)|564/0<br>2024.2.0|
|[9c593619f363fda422375b386674d558fa48d437](https://github.com/arthw/llama.cpp/commit/9c593619f363fda422375b386674d558fa48d437)<br>2024-07-03 11:20:54<br>fix multiple gpu, add device choose mode<br>, update the guide for usages<br>Neo Zhang  Log: [log](./log/9c593619f363fda422375b386674d558fa48d437)|91.0%<br>NA|40.05|tg=NA<br>pp=NA|('ok', 'pass', 0)|571/0<br>2024.1.0|
|[51be86243892833c9779ae903d5b54241ec2507a](https://github.com/arthw/llama.cpp/commit/51be86243892833c9779ae903d5b54241ec2507a)<br>2024-07-03 02:55:34<br>Dequant improvements rebase<br>AidanBeltonS  Log: [log](./log/51be86243892833c9779ae903d5b54241ec2507a)|91.0%<br>NA|40.06|tg=NA<br>pp=NA|('ok', 'pass', 0)|577/0<br>2024.1.0|
|[044995e2d1fbc21ca275be66a9cb580034124502](https://github.com/arthw/llama.cpp/commit/044995e2d1fbc21ca275be66a9cb580034124502)<br>2024-07-02 12:18:10<br>Removes multiple newlines at the end of <br>files that is breaking the editorconfig <br>step of CI.<br>Clint Herron  Log: [log](./log/044995e2d1fbc21ca275be66a9cb580034124502)|91.0%<br>NA|40.06|tg=NA<br>pp=NA|('ok', 'pass', 0)|571/0<br>2024.1.0|
|[a9f3b102157ba992cfe058909b7f6e1906d2d647](https://github.com/arthw/llama.cpp/commit/a9f3b102157ba992cfe058909b7f6e1906d2d647)<br>2024-07-02 04:50:07<br>[SYCL] Fix win build conflict of math li<br>brary<br>luoyu-intel  Log: [log](./log/a9f3b102157ba992cfe058909b7f6e1906d2d647)|91.0%<br>NA|41.12|tg=NA<br>pp=NA|('ok', 'pass', 0)|550/0<br>2024.2.0|
|[d08c20eddedb24515a3212e2de66bdff41a26b8c](https://github.com/arthw/llama.cpp/commit/d08c20eddedb24515a3212e2de66bdff41a26b8c)<br>2024-07-02 02:16:00<br>[SYCL] Fix the sub group size of Intel<br>luoyu-intel  Log: [log](./log/d08c20eddedb24515a3212e2de66bdff41a26b8c)|91.0%<br>NA|43.39|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>Step 1: The original copy text needed sh<br>ould describe the products/ services.', <br>0)|599/0<br>2024.1.0|
|[cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846](https://github.com/arthw/llama.cpp/commit/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846)<br>2024-07-01 20:39:06<br>CUDA: refactor and optimize IQ MMVQ<br>Johannes Gäßler  Log: [log](./log/cb5fad4c6c2cbef92e9b8b63449e1cb7664e4846)|91.0%<br>NA|40.09|tg=NA<br>pp=NA|('ok', 'pass', 0)|543/0<br>2024.1.0|
|[197fe6c1d7bec6718ce901f0141b2725240f298c](https://github.com/arthw/llama.cpp/commit/197fe6c1d7bec6718ce901f0141b2725240f298c)<br>2024-07-01 19:39:06<br>[SYCL] Update SYCL-Rope op and Refactor<br>zhentaoyu  Log: [log](./log/197fe6c1d7bec6718ce901f0141b2725240f298c)|91.0%<br>NA|40.08|tg=NA<br>pp=NA|('ok', 'pass', 0)|543/0<br>2024.1.0|
|[f3f65429c44bb195a9195bfdc19a30a79709db7b](https://github.com/arthw/llama.cpp/commit/f3f65429c44bb195a9195bfdc19a30a79709db7b)<br>2024-06-26 18:33:02<br>llama : reorganize source code + improve<br> CMake<br>Georgi Gerganov  Log: [log](./log/f3f65429c44bb195a9195bfdc19a30a79709db7b)|95.0%<br>NA|40.09|tg=NA<br>pp=NA|('ok', 'pass', 0)|533/0<br>2024.1.0|
|[083bacce14c1aaf9976aa40e8266cdc25ac749d3](https://github.com/arthw/llama.cpp/commit/083bacce14c1aaf9976aa40e8266cdc25ac749d3)<br>2024-06-25 10:19:20<br>[SYCL] Re-enabled mul_mat_batched_sycl<br>Meng, Hengyu  Log: [log](./log/083bacce14c1aaf9976aa40e8266cdc25ac749d3)|91.0%<br>NA|40.17|tg=NA<br>pp=NA|('ok', 'pass', 0)|554/0<br>2024.1.0|
|[de391e4c803383bbea054b6edd016e78c024a74d](https://github.com/arthw/llama.cpp/commit/de391e4c803383bbea054b6edd016e78c024a74d)<br>2024-06-20 13:19:05<br>[SYCL] Fix windows build and inference<br>luoyu-intel  Log: [log](./log/de391e4c803383bbea054b6edd016e78c024a74d)|91.0%<br>NA|40.09|tg=NA<br>pp=NA|('ok', 'pass', 0)|554/0<br>2024.1.0|
|[de2763118fd5b6ea89702cc9981349e0556b0c3d](https://github.com/arthw/llama.cpp/commit/de2763118fd5b6ea89702cc9981349e0556b0c3d)<br>2024-06-19 22:54:15<br>fix to support multiple GPUs, fix set si<br>ngle device, unify id/device_id/device_i<br>ndex<br>Jianyu Zhang  Log: [log](./log/de2763118fd5b6ea89702cc9981349e0556b0c3d)|Build Err<br>NA|NA|tg=NA<br>pp=NA|('err', 'diff in line 0:<br>exp=Step 1: Get Domain and Hosting<br>./examples/sycl/run-llama2.sh: line 29: <br>./build/bin/llama-cli: No such file or d<br>', 0)|13/6<br>2024.1.0|
|[623494a478134432fd2d7ee40135770a3340674f](https://github.com/arthw/llama.cpp/commit/623494a478134432fd2d7ee40135770a3340674f)<br>2024-06-19 09:11:51<br>[SYCL] refactor<br>Meng, Hengyu  Log: [log](./log/623494a478134432fd2d7ee40135770a3340674f)|91.0%<br>NA|40.09|tg=NA<br>pp=NA|('ok', 'pass', 0)|542/0<br>2024.1.0|
|[df68d4fa5dc929217d3e64d673e099d7a417b206](https://github.com/arthw/llama.cpp/commit/df68d4fa5dc929217d3e64d673e099d7a417b206)<br>2024-06-17 11:17:07<br>[SYCL] Update README-sycl.md for Chapter<br> "Recommended release" and "News"<br>Neo Zhang  Log: [log](./log/df68d4fa5dc929217d3e64d673e099d7a417b206)|91.0%<br>NA|40.08|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.1.0|
|[7b2f4a7d193ef2475259bbe7656fcccfab4b1217](https://github.com/arthw/llama.cpp/commit/7b2f4a7d193ef2475259bbe7656fcccfab4b1217)<br>2024-06-15 14:05:10<br>[SYCL] remove global variables<br>Meng, Hengyu  Log: [log](./log/7b2f4a7d193ef2475259bbe7656fcccfab4b1217)|91.0%<br>NA|40.09|tg=NA<br>pp=NA|('ok', 'pass', 0)|480/0<br>2024.1.0|
|[f578b86b2123d0f92afbaa98a031df4d4464e582](https://github.com/arthw/llama.cpp/commit/f578b86b2123d0f92afbaa98a031df4d4464e582)<br>2024-06-13 03:11:35<br>move BLAS to a separate backend<br>slaren  Log: [log](./log/f578b86b2123d0f92afbaa98a031df4d4464e582)|91.0%<br>NA|29.65|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|493/0<br>2024.1.0|
|[1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7](https://github.com/arthw/llama.cpp/commit/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7)<br>2024-06-13 00:41:52<br>`build`: rename main → llama-cli, server<br> → llama-server, llava-cli → llama-llava<br>-cli, etc...<br>Olivier Chafik  Log: [log](./log/1c641e6aac5c18b964e7b32d9dbbb4bf5301d0d7)|91.0%<br>NA|29.73|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|493/0<br>2024.1.0|
|[a9cae48003dfc4fe95b8f5c81682fc6e63425235](https://github.com/arthw/llama.cpp/commit/a9cae48003dfc4fe95b8f5c81682fc6e63425235)<br>2024-06-12 16:00:22<br>tests : add non-cont unary tests<br>Georgi Gerganov  Log: [log](./log/a9cae48003dfc4fe95b8f5c81682fc6e63425235)|91.0%<br>NA|29.69|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|493/0<br>2024.1.0|
|[af4ae502ddaeb03cd5861273ca2e9a5ae4551db7](https://github.com/arthw/llama.cpp/commit/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7)<br>2024-06-10 02:21:31<br>use the correct SYCL context for host US<br>M allocations<br>Ben Ashbaugh  Log: [log](./log/af4ae502ddaeb03cd5861273ca2e9a5ae4551db7)|91.0%<br>NA|29.7|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|493/0<br>2024.1.0|
|[fe1e3917cfa0f9397a765cfd0aef880674d938d5](https://github.com/arthw/llama.cpp/commit/fe1e3917cfa0f9397a765cfd0aef880674d938d5)<br>2024-06-09 01:43:39<br>Revert "[SYCL] Update rpc-server.cpp to <br>include SYCL backend<br>slaren  Log: [log](./log/fe1e3917cfa0f9397a765cfd0aef880674d938d5)|91.0%<br>NA|30.37|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orszomen, he jump -major30 <br>atau, OldC and 2 in.O(men, Int 1unker, b<br>', 6)|463/0<br>2024.2.0|
|[d5c938cd7716b9a2ace49a43a469dfbffcff4d28](https://github.com/arthw/llama.cpp/commit/d5c938cd7716b9a2ace49a43a469dfbffcff4d28)<br>2024-06-07 14:28:26<br>[SYCL] fix softmax r2r result wrong issu<br>e<br>pengxin99  Log: [log](./log/d5c938cd7716b9a2ace49a43a469dfbffcff4d28)|91.0%<br>NA|29.64|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|493/0<br>2024.1.0|
|[2b3389677a833cee0880226533a1768b1a9508d2](https://github.com/arthw/llama.cpp/commit/2b3389677a833cee0880226533a1768b1a9508d2)<br>2024-06-05 11:29:20<br>ggml : refactor rope norm/neox<br>Georgi Gerganov  Log: [log](./log/2b3389677a833cee0880226533a1768b1a9508d2)|91.0%<br>NA|29.73|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make,orsz onседа atir Byett, 1./<br>doV’3ar/F(, knowledgejyl onop5all', 6)|493/0<br>2024.1.0|
|[554c247caffed64465f372661f2826640cb10430](https://github.com/arthw/llama.cpp/commit/554c247caffed64465f372661f2826640cb10430)<br>2024-06-04 21:23:20<br>ggml : remove OpenCL<br>Georgi Gerganov  Log: [log](./log/554c247caffed64465f372661f2826640cb10430)|91.0%<br>NA|29.97|tg=NA<br>pp=NA|('err', 'diff in line 6:<br>exp=Step 7: Make the site visible<br>Step 7: Make report (v has have has got <br>(pay( Big and (c gu in to The(Col U2 R,2<br>', 6)|487/0<br>2024.1.0|
|[9422c5e34bbd302493b77a8f6d546154a1f4fe82](https://github.com/arthw/llama.cpp/commit/9422c5e34bbd302493b77a8f6d546154a1f4fe82)<br>2024-06-02 19:13:54<br>[SYCL] Update rpc-server.cpp to include <br>SYCL backend<br>nickp27  Log: [log](./log/9422c5e34bbd302493b77a8f6d546154a1f4fe82)|91.0%<br>NA|30.69|tg=NA<br>pp=NA|('ok', 'pass', 0)|457/0<br>2024.2.0|
