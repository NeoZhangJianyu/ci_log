{"author": "Georgi Gerganov <ggerganov@gmail.com>", "date": "2025-01-12 11:32:42", "title": "llama : add `llama_vocab`, functions -> methods, naming", "pr_id": "11110", "files": ["common/common.cpp", "common/common.h", "common/sampling.cpp", "common/speculative.cpp", "examples/batched-bench/batched-bench.cpp", "examples/batched.swift/Sources/main.swift", "examples/batched/batched.cpp", "examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp", "examples/cvector-generator/cvector-generator.cpp", "examples/embedding/embedding.cpp", "examples/eval-callback/eval-callback.cpp", "examples/export-lora/export-lora.cpp", "examples/gritlm/gritlm.cpp", "examples/imatrix/imatrix.cpp", "examples/infill/infill.cpp", "examples/llama-bench/llama-bench.cpp", "examples/llama.android/llama/src/main/cpp/llama-android.cpp", "examples/llama.swiftui/llama.cpp.swift/LibLlama.swift", "examples/llava/llava-cli.cpp", "examples/llava/llava.cpp", "examples/llava/minicpmv-cli.cpp", "examples/llava/qwen2vl-cli.cpp", "examples/lookahead/lookahead.cpp", "examples/lookup/lookup.cpp", "examples/main/main.cpp", "examples/parallel/parallel.cpp", "examples/passkey/passkey.cpp", "examples/perplexity/perplexity.cpp", "examples/quantize-stats/quantize-stats.cpp", "examples/retrieval/retrieval.cpp", "examples/run/run.cpp", "examples/save-load-state/save-load-state.cpp", "examples/server/server.cpp", "examples/server/utils.hpp", "examples/simple-chat/simple-chat.cpp", "examples/simple/simple.cpp", "examples/speculative-simple/speculative-simple.cpp", "examples/speculative/speculative.cpp", "examples/tokenize/tokenize.cpp", "examples/tts/tts.cpp", "ggml/src/ggml-sycl/ggml-sycl.cpp", "include/llama-cpp.h", "include/llama.h", "src/llama-adapter.cpp", "src/llama-adapter.h", "src/llama-arch.cpp", "src/llama-arch.h", "src/llama-context.cpp", "src/llama-context.h", "src/llama-grammar.cpp", "src/llama-hparams.h", "src/llama-kv-cache.cpp", "src/llama-mmap.cpp", "src/llama-model-loader.cpp", "src/llama-model-loader.h", "src/llama-model.cpp", "src/llama-model.h", "src/llama-quant.cpp", "src/llama-sampling.cpp", "src/llama-sampling.h", "src/llama-vocab.cpp", "src/llama-vocab.h", "src/llama.cpp", "tests/test-autorelease.cpp", "tests/test-chat-template.cpp", "tests/test-tokenizer-0.cpp", "tests/test-tokenizer-1-bpe.cpp", "tests/test-tokenizer-1-spm.cpp", "tests/test-tokenizer-random.py"]}