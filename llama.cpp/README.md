# llama.cpp CI for SYCL Backend

This CI system is developed and maintained by NeoZhangJianyu. If you have any issue, please contact to: [zhang.jianyu@outlook.com](zhang.jianyu@outlook.com).

## Repo CI

|Repo|Hardware|CI|Figure|
|-|-|-|-|
|arthw/llama.cpp|i5-1250P-iGPU|[CI Log](./arthw-llama.cpp/i5-1250P-iGPU/README.md)|![Performance](./arthw-llama.cpp/i5-1250P-iGPU/perf.png)|
|arthw/llama.cpp|arc770|[CI Log](./arthw-llama.cpp/arc770/README.md)|![Performance](./arthw-llama.cpp/arc770/perf.png)|
|ggerganov/llama.cpp|arc|[CI Log](./ggerganov-llama.cpp/arc/README.md)|![Performance](./ggerganov-llama.cpp/arc/perf.png)|
|ggerganov/llama.cpp|i5-1250P-iGPU|[CI Log](./ggerganov-llama.cpp/i5-1250P-iGPU/README.md)|![Performance](./ggerganov-llama.cpp/i5-1250P-iGPU/perf.png)|
|ggerganov/llama.cpp|arc770|[CI Log](./ggerganov-llama.cpp/arc770/README.md)|![Performance](./ggerganov-llama.cpp/arc770/perf.png)|
